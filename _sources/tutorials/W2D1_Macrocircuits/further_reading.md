# Suggested further readings 

## Tutorial 1: Depth vs Width

- [Exponential expressivity in deep neural networks through transient chaos](https://papers.nips.cc/paper_files/paper/2016/hash/148510031349642de5ca0c544f31b2ef-Abstract.html)

## Tutorial 2: Double descent

- [Double Descent: A Visual Introduction](https://mlu-explain.github.io/double-descent/)
- [Double Descent: A Mathematical Explanation](https://mlu-explain.github.io/double-descent2/)
- [Deep Double Descent: Where Bigger Models and More Data Hurt](https://arxiv.org/abs/1912.02292)
- [A Farewell to the Bias-Variance Tradeoff? An Overview of the Theory of Overparameterized Machine Learning](https://arxiv.org/abs/2109.02355)

## Tutorial 3: Modularity

- [Inductive biases of neural networks for generalization in spatial navigation](https://www.biorxiv.org/content/10.1101/2022.12.07.519515v1)