
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="Docutils 0.18.1: http://docutils.sourceforge.net/" name="generator"/>
<title>Tutorial 1: Generalization in AI — NeuroAI (instructor's version)</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css">
<link href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" rel="stylesheet" type="text/css">
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94" rel="preload"/>
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
<script>let toggleHintShow = 'Click to show';</script>
<script>let toggleHintHide = 'Click to hide';</script>
<script>let toggleOpenOnPrint = 'true';</script>
<script src="../../../_static/togglebutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
<script src="../../../_static/design-tabs.js"></script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script type="application/vnd.jupyter.widget-state+json">{"state": {"fe6f9b714266470eb89291e1a8b86ca6": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ab62606d65294415afcc5446e1416b17": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_fe6f9b714266470eb89291e1a8b86ca6", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "If you want to download the slides: https://osf.io/download/x4pa5/\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.IFrame at 0x7f4b2409e580>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://mfr.ca-1.osf.io/render?url=https://osf.io/x4pa5/?direct%26mode=render%26action=download%26mode=render\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}], "tabbable": null, "tooltip": null}}, "534b879995b64918931ab0d0dfdf3a73": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "809f64fd0e6c4c219afb55379d663c71": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "4dd0d9bff0fa467f83c993fb9a224bfa": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_534b879995b64918931ab0d0dfdf3a73", "max": 4165.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_809f64fd0e6c4c219afb55379d663c71", "tabbable": null, "tooltip": null, "value": 4165.0}}, "a012146822f84b848ecaa587a5813446": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "45922134cfc24bc1bd4cc87264748f7d": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "402c5890a8d341108118a1c2623fa640": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_a012146822f84b848ecaa587a5813446", "placeholder": "\u200b", "style": "IPY_MODEL_45922134cfc24bc1bd4cc87264748f7d", "tabbable": null, "tooltip": null, "value": "config.json:\u2007100%"}}, "93f9c1e4dac6483a8cdfe108545c77a8": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f9ca0c08c2eb4285948fd7cfa839531d": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "4693737e46be4481b2da8f3ca3434ee1": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_93f9c1e4dac6483a8cdfe108545c77a8", "placeholder": "\u200b", "style": "IPY_MODEL_f9ca0c08c2eb4285948fd7cfa839531d", "tabbable": null, "tooltip": null, "value": "\u20074.17k/4.17k\u2007[00:00&lt;00:00,\u2007458kB/s]"}}, "dd1a1878cfef474689ee5a85d03e1709": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "55d0ace60eb342848eb4ce1a4682baf5": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_402c5890a8d341108118a1c2623fa640", "IPY_MODEL_4dd0d9bff0fa467f83c993fb9a224bfa", "IPY_MODEL_4693737e46be4481b2da8f3ca3434ee1"], "layout": "IPY_MODEL_dd1a1878cfef474689ee5a85d03e1709", "tabbable": null, "tooltip": null}}, "ee180fadea4644718211ddaa8e10734e": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "12e53ccd153d44cd820d5534123ea122": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "c39218588e4c4398aee56a7a15422b9e": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_ee180fadea4644718211ddaa8e10734e", "max": 1333384464.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_12e53ccd153d44cd820d5534123ea122", "tabbable": null, "tooltip": null, "value": 1333384464.0}}, "9613119385b346fb8a3d822397590a01": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "873afe76fc0f47928b29caf9f3e8bd27": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "67f7ecca6e5b40eca2d75eab9fb2819c": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_9613119385b346fb8a3d822397590a01", "placeholder": "\u200b", "style": "IPY_MODEL_873afe76fc0f47928b29caf9f3e8bd27", "tabbable": null, "tooltip": null, "value": "model.safetensors:\u2007100%"}}, "6d139cbedd63408da607fd6d059cdc0a": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1b57f72b88ac463db7c1ba69c4148956": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "d370fe01c19c406982b0f26b99e9a0b7": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_6d139cbedd63408da607fd6d059cdc0a", "placeholder": "\u200b", "style": "IPY_MODEL_1b57f72b88ac463db7c1ba69c4148956", "tabbable": null, "tooltip": null, "value": "\u20071.33G/1.33G\u2007[00:05&lt;00:00,\u2007245MB/s]"}}, "6391ef29c7ba415a810c2e26ab177d35": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "14fe32e2533749f4b6cefff1635e9641": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_67f7ecca6e5b40eca2d75eab9fb2819c", "IPY_MODEL_c39218588e4c4398aee56a7a15422b9e", "IPY_MODEL_d370fe01c19c406982b0f26b99e9a0b7"], "layout": "IPY_MODEL_6391ef29c7ba415a810c2e26ab177d35", "tabbable": null, "tooltip": null}}, "04da9f1447b7408ba01b1962aef29d9d": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "3a6a6361cd934cdb830a767e78a058cc": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "e95a44c6d2b84383a15615a332113da1": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_04da9f1447b7408ba01b1962aef29d9d", "max": 190.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_3a6a6361cd934cdb830a767e78a058cc", "tabbable": null, "tooltip": null, "value": 190.0}}, "111bed793f524dfe853fe8c0ce240332": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "7775b55f8e7141b5b0e6c6cde3894fc9": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "4be15b394ee74838a6be40fdb8d60dc4": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_111bed793f524dfe853fe8c0ce240332", "placeholder": "\u200b", "style": "IPY_MODEL_7775b55f8e7141b5b0e6c6cde3894fc9", "tabbable": null, "tooltip": null, "value": "generation_config.json:\u2007100%"}}, "73bde50005744dfaac12e87d3fcfa7ca": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1d0e9892ba484d47b298bf157facbe7c": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "e50f1184f40a421dad35de873ba7242b": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_73bde50005744dfaac12e87d3fcfa7ca", "placeholder": "\u200b", "style": "IPY_MODEL_1d0e9892ba484d47b298bf157facbe7c", "tabbable": null, "tooltip": null, "value": "\u2007190/190\u2007[00:00&lt;00:00,\u200722.9kB/s]"}}, "d613412e536147d09be2fba732552586": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "06740588aae74308af8df6e20c15625f": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_4be15b394ee74838a6be40fdb8d60dc4", "IPY_MODEL_e95a44c6d2b84383a15615a332113da1", "IPY_MODEL_e50f1184f40a421dad35de873ba7242b"], "layout": "IPY_MODEL_d613412e536147d09be2fba732552586", "tabbable": null, "tooltip": null}}, "a29ee2a1bcfa446baf36f91775b31e30": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "13c2e6a15385401d8986bd3364cdcb36": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "87ab3317cf7547e9a637502a979c4386": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_a29ee2a1bcfa446baf36f91775b31e30", "max": 224.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_13c2e6a15385401d8986bd3364cdcb36", "tabbable": null, "tooltip": null, "value": 224.0}}, "b61a8c922c10480f9845053b7037d68f": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1c134b272219410c95be5f0516ced886": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "5f288efba4cd423f80a29d89c7a5eec8": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_b61a8c922c10480f9845053b7037d68f", "placeholder": "\u200b", "style": "IPY_MODEL_1c134b272219410c95be5f0516ced886", "tabbable": null, "tooltip": null, "value": "preprocessor_config.json:\u2007100%"}}, "2f4c4a37976848a0a88a5d4db5276946": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a46b9a4b225f4802890192d16b48ba46": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "3ed0317a45e34b8facad3ecf9169b3cb": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_2f4c4a37976848a0a88a5d4db5276946", "placeholder": "\u200b", "style": "IPY_MODEL_a46b9a4b225f4802890192d16b48ba46", "tabbable": null, "tooltip": null, "value": "\u2007224/224\u2007[00:00&lt;00:00,\u200726.0kB/s]"}}, "c78c5fea4ea748deae86b225b3d57f18": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1e5eb724ceae4cacb8af6f1397184c53": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_5f288efba4cd423f80a29d89c7a5eec8", "IPY_MODEL_87ab3317cf7547e9a637502a979c4386", "IPY_MODEL_3ed0317a45e34b8facad3ecf9169b3cb"], "layout": "IPY_MODEL_c78c5fea4ea748deae86b225b3d57f18", "tabbable": null, "tooltip": null}}, "93be661d381649d1b893041d5d721853": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e49b0526479b4d838ec19013a06f403d": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "8a5ef7108285426eb733b49af58435a2": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_93be661d381649d1b893041d5d721853", "max": 1118.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_e49b0526479b4d838ec19013a06f403d", "tabbable": null, "tooltip": null, "value": 1118.0}}, "f5410c87ccc940be9dc35ba722e14e7a": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "6d7b04b817064da8bc2d6bab89a7d754": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "99777d8c38504df6aab266d0ef525b4a": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_f5410c87ccc940be9dc35ba722e14e7a", "placeholder": "\u200b", "style": "IPY_MODEL_6d7b04b817064da8bc2d6bab89a7d754", "tabbable": null, "tooltip": null, "value": "tokenizer_config.json:\u2007100%"}}, "fa72ce5a43304471881ae03c07e4038d": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "4b7228945dcc4e4bb75ef9ebce4254c5": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "9fda97d25e3b46fca9304b8c46842da7": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_fa72ce5a43304471881ae03c07e4038d", "placeholder": "\u200b", "style": "IPY_MODEL_4b7228945dcc4e4bb75ef9ebce4254c5", "tabbable": null, "tooltip": null, "value": "\u20071.12k/1.12k\u2007[00:00&lt;00:00,\u2007147kB/s]"}}, "77e80e0a5eac488d8c39acde9b59163c": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "522dec5b990e4a088e4a4efd42fb84f0": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_99777d8c38504df6aab266d0ef525b4a", "IPY_MODEL_8a5ef7108285426eb733b49af58435a2", "IPY_MODEL_9fda97d25e3b46fca9304b8c46842da7"], "layout": "IPY_MODEL_77e80e0a5eac488d8c39acde9b59163c", "tabbable": null, "tooltip": null}}, "b5dfa9e0d8b64d5ca81427dfdac114a1": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "956202624b9b4d369ae97c61b351c12b": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "4ff43dec37d74d589118cac5b9dd22d7": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_b5dfa9e0d8b64d5ca81427dfdac114a1", "max": 898822.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_956202624b9b4d369ae97c61b351c12b", "tabbable": null, "tooltip": null, "value": 898822.0}}, "7c70214b01b646d2b1eeb4a687af6f36": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5295b4c8e57e46bba84f2df9b0c371b0": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "dbe638a2b5974cacaedca18ca3a691c1": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_7c70214b01b646d2b1eeb4a687af6f36", "placeholder": "\u200b", "style": "IPY_MODEL_5295b4c8e57e46bba84f2df9b0c371b0", "tabbable": null, "tooltip": null, "value": "vocab.json:\u2007100%"}}, "286f28a3df0c44b3a00e374865aaca9b": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "eceb12199288401798e67b4ac0b7a3c5": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "002e505d39f0428d954ae04935f5f07d": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_286f28a3df0c44b3a00e374865aaca9b", "placeholder": "\u200b", "style": "IPY_MODEL_eceb12199288401798e67b4ac0b7a3c5", "tabbable": null, "tooltip": null, "value": "\u2007899k/899k\u2007[00:00&lt;00:00,\u200720.9MB/s]"}}, "005847d8d2614c01b704cf901eb431d4": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ee4277371fc348acb92f8deef0266df1": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_dbe638a2b5974cacaedca18ca3a691c1", "IPY_MODEL_4ff43dec37d74d589118cac5b9dd22d7", "IPY_MODEL_002e505d39f0428d954ae04935f5f07d"], "layout": "IPY_MODEL_005847d8d2614c01b704cf901eb431d4", "tabbable": null, "tooltip": null}}, "5cfe5a0f88524bd68a8cdac04123c8f8": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f5e5dd52476c43f89330a6ac9d52665b": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "d4523f33d76d4ba9ace21b5f5af7c3ad": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_5cfe5a0f88524bd68a8cdac04123c8f8", "max": 456318.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_f5e5dd52476c43f89330a6ac9d52665b", "tabbable": null, "tooltip": null, "value": 456318.0}}, "9aa4b1bf508b4e29abf00b705ead963d": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "fb417da924374073a8288d651ebc88c2": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "8c211c2d736d4f588d7b5a27db69eb04": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_9aa4b1bf508b4e29abf00b705ead963d", "placeholder": "\u200b", "style": "IPY_MODEL_fb417da924374073a8288d651ebc88c2", "tabbable": null, "tooltip": null, "value": "merges.txt:\u2007100%"}}, "eae0581eff784f49839f575416ff3cf5": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c737505721964bac90664c02370f42f1": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "eea90b66079f4c4fb8121f849c938a9a": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_eae0581eff784f49839f575416ff3cf5", "placeholder": "\u200b", "style": "IPY_MODEL_c737505721964bac90664c02370f42f1", "tabbable": null, "tooltip": null, "value": "\u2007456k/456k\u2007[00:00&lt;00:00,\u200733.4MB/s]"}}, "c7f35fc5c7c14b3aa9b64dfa78a73408": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "0db7397058444059810c850f3f6b4602": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_8c211c2d736d4f588d7b5a27db69eb04", "IPY_MODEL_d4523f33d76d4ba9ace21b5f5af7c3ad", "IPY_MODEL_eea90b66079f4c4fb8121f849c938a9a"], "layout": "IPY_MODEL_c7f35fc5c7c14b3aa9b64dfa78a73408", "tabbable": null, "tooltip": null}}, "9a6d4d75e58240f1b940bc26e38a61aa": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "0411c3fa6a3a424b81714e77715c7921": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "c9ee84eecdd043c78f6d85b81d7eb51c": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_9a6d4d75e58240f1b940bc26e38a61aa", "max": 772.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_0411c3fa6a3a424b81714e77715c7921", "tabbable": null, "tooltip": null, "value": 772.0}}, "cfb88aac584b4e619e7e12997ab25bcd": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "102084292c854ec8a3689b7a35657f49": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "c21cc7f24c5a4ec1988e4679c02513b4": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_cfb88aac584b4e619e7e12997ab25bcd", "placeholder": "\u200b", "style": "IPY_MODEL_102084292c854ec8a3689b7a35657f49", "tabbable": null, "tooltip": null, "value": "special_tokens_map.json:\u2007100%"}}, "affe2c1a0c9d4f5a8fbcacc1c1cce608": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9403b5df55e843528d94a52905d4e315": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "22eeeb0789a0452684bc7bd987658438": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_affe2c1a0c9d4f5a8fbcacc1c1cce608", "placeholder": "\u200b", "style": "IPY_MODEL_9403b5df55e843528d94a52905d4e315", "tabbable": null, "tooltip": null, "value": "\u2007772/772\u2007[00:00&lt;00:00,\u2007120kB/s]"}}, "52a0c4589bd740489570a19ccb5f0dff": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "96e858ba796a4dc0b6193553f3df1124": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_c21cc7f24c5a4ec1988e4679c02513b4", "IPY_MODEL_c9ee84eecdd043c78f6d85b81d7eb51c", "IPY_MODEL_22eeeb0789a0452684bc7bd987658438"], "layout": "IPY_MODEL_52a0c4589bd740489570a19ccb5f0dff", "tabbable": null, "tooltip": null}}}, "version_major": 2, "version_minor": 0}</script>
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script crossorigin="anonymous" data-jupyter-widgets-cdn="https://cdn.jsdelivr.net/npm/" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@1.0.6/dist/embed-amd.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/W1D1_Generalization/instructor/W1D1_Tutorial1';</script>
<link href="../../../_static/ai-logo.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index">
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W1D1_Tutorial2.html" rel="next" title="Tutorial 2: Generalization in Neuroscience"/>
<link href="W1D1_Intro.html" rel="prev" title="Intro"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></link></link></link></link></link></link></link></head>
<body data-default-mode="" data-offset="180" data-spy="scroll" data-target="#bd-toc-nav">
<a class="skip-link" href="#main-content">Skip to main content</a>
<input class="sidebar-toggle" id="__primary" name="__primary" type="checkbox"/>
<label class="overlay overlay-primary" for="__primary"></label>
<input class="sidebar-toggle" id="__secondary" name="__secondary" type="checkbox"/>
<label class="overlay overlay-secondary" for="__secondary"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
</div>
<nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
<label class="sidebar-toggle primary-toggle" for="__primary">
<span class="fa-solid fa-bars"></span>
</label>
<div id="navbar-start">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/ai-logo.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/ai-logo.png"/>
</a>
</div>
<div class="col-lg-9 navbar-header-items">
<div class="mr-auto" id="navbar-center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Generalization (W1D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D2_ComparingTasks/chapter_title.html">
                        Comparing Tasks (W1D2)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/chapter_title.html">
                        Comparing Artificial And Biological Networks (W1D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D5_Microcircuits/chapter_title.html">
                        Microcircuits (W1D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_Macrocircuits/chapter_title.html">
                        Macrocircuits (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_NeuroSymbolicMethods/chapter_title.html">
                        Neuro Symbolic Methods (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D3_Microlearning/chapter_title.html">
                        Microlearning (W2D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D4_Macrolearning/chapter_title.html">
                        Macrolearning (W2D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D5_Mysteries/chapter_title.html">
                        Mysteries (W2D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Project materials
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/impact_talks.html">
                        Impact Talks
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/mentorship_program.html">
                        Mentorship Program
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_features.html">
                        Career Features
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_panels.html">
                        Career Panels
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div id="navbar-end">
<div class="navbar-end-item navbar-persistent--container">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="navbar-persistent--mobile">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<label class="sidebar-toggle secondary-toggle" for="__secondary">
<span class="fa-solid fa-outdent"></span>
</label>
</div>
</nav>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Generalization (W1D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D2_ComparingTasks/chapter_title.html">
                        Comparing Tasks (W1D2)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/chapter_title.html">
                        Comparing Artificial And Biological Networks (W1D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D5_Microcircuits/chapter_title.html">
                        Microcircuits (W1D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_Macrocircuits/chapter_title.html">
                        Macrocircuits (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_NeuroSymbolicMethods/chapter_title.html">
                        Neuro Symbolic Methods (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D3_Microlearning/chapter_title.html">
                        Microlearning (W2D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D4_Macrolearning/chapter_title.html">
                        Macrolearning (W2D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D5_Mysteries/chapter_title.html">
                        Mysteries (W2D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Project materials
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/impact_talks.html">
                        Impact Talks
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/mentorship_program.html">
                        Mentorship Program
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_features.html">
                        Career Features
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_panels.html">
                        Career Panels
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="sidebar-start-items sidebar-primary__section">
<div class="sidebar-start-items__item">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/ai-logo.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/ai-logo.png"/>
</a>
</div>
<div class="sidebar-start-items__item">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="sidebar-start-items__item"><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item navbar-nav active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Schedule/schedule_intro.html">Schedule</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/daily_schedules.html">General schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/shared_calendars.html">Shared calendars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/timezone_widget.html">Timezone widget</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../TechnicalHelp/tech_intro.html">Technical Help</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">Using jupyterbook</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">Using Google Colab</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">Using Kaggle</a></li>
</ul>
</input></li>
<li class="toctree-l2"><a class="reference internal" href="../../TechnicalHelp/Discord.html">Using discord</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">Quick links and policies</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Foundations</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../chapter_title.html">Generalization (W1D1)</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="W1D1_Intro.html">Intro</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Tutorial 1: Generalization in AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="W1D1_Tutorial2.html">Tutorial 2: Generalization in Neuroscience</a></li>
<li class="toctree-l2"><a class="reference internal" href="W1D1_Tutorial3.html">Tutorial 3: Generalization in Cognitive Science</a></li>
</ul>
</input></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D2_ComparingTasks/chapter_title.html">Comparing Tasks (W1D2)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/instructor/W1D2_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/instructor/W1D2_Tutorial1.html">Tutorial 1: Task definition, application, relations and impacts on generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/instructor/W1D2_Tutorial2.html">Tutorial 2: Contrastive learning for object recognition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/instructor/W1D2_Tutorial3.html">Tutorial 3: Reinforcement learning across temporal scales</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/chapter_title.html">Comparing Artificial And Biological Networks (W1D3)</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/instructor/W1D3_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/instructor/W1D3_Tutorial1.html">Tutorial 1: Generalization and representational geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/instructor/W1D3_Tutorial2.html">Tutorial 2: Computation as transformation of representational geometries</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/instructor/W1D3_Tutorial3.html">Tutorial 3: Representational geometry &amp; noise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/instructor/W1D3_Tutorial4.html">Tutorial 4: Statistical inference on representational geometries</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Architectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D5_Microcircuits/chapter_title.html">Microcircuits (W1D5)</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/instructor/W1D5_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/instructor/W1D5_Tutorial1.html">Tutorial 1: Sparsity and Sparse Coding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/instructor/W1D5_Tutorial2.html">Tutorial 2: Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/instructor/W1D5_Tutorial3.html">Tutorial 3: Attention</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D1_Macrocircuits/chapter_title.html">Macrocircuits (W2D1)</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/instructor/W2D1_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/instructor/W2D1_Tutorial1.html">Tutorial 1: Depth vs Width</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/chapter_title.html">Neuro Symbolic Methods (W2D2)</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/instructor/W2D2_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/instructor/W2D2_Tutorial1.html">Tutorial 1: Basic operations of vector symbolic algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/instructor/W2D2_Tutorial2.html">Tutorial 2: Learning with structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/instructor/W2D2_Tutorial3.html">Tutorial 3: Representations in continuous space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/further_reading.html">Suggested further readings</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D3_Microlearning/chapter_title.html">Microlearning (W2D3)</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/instructor/W2D3_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/instructor/W2D3_Tutorial1.html">Tutorial 1: Microlearning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D4_Macrolearning/chapter_title.html">Macrolearning (W2D4)</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/instructor/W2D4_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/instructor/W2D4_Tutorial1.html">Tutorial 1: The problem of changing data distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/instructor/W2D4_Tutorial2.html">Tutorial 2: Continual learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/instructor/W2D4_Tutorial3.html">Tutorial 3: Meta-learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/instructor/W2D4_Tutorial4.html">Tutorial 4: Biological meta reinforcement learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/instructor/W2D4_Tutorial5.html">Tutorial 5: Replay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/further_reading.html">Suggested further readings</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Mysteries</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D5_Mysteries/chapter_title.html">Mysteries (W2D5)</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/instructor/W2D5_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/instructor/W2D5_Tutorial1.html">Tutorial 1: Consciousness</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/instructor/W2D5_Tutorial2.html">Tutorial 2: Ethics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/instructor/W2D5_Outro.html">Outro</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project Booklet</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/docs/project_guidance.html">Daily guide for projects</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../projects/docs/datasets_overview.html">Project materials</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/Macrocircuits.html">Macrocircuits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/Microlearning.html">Microlearning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/ComparingNetworks.html">Comparing Networks</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Professional Development</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/impact_talks.html">Impact Talks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/mentorship_program.html">Professional developemnt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/career_features.html">Career Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/career_panels.html">Career Panels</a></li>
</ul>
</div>
</nav>
</div>
</div>
<div class="sidebar-end-items sidebar-primary__section">
<div class="sidebar-end-items__item">
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content">
<div class="sbt-scroll-pixel-helper"></div>
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="sidebar-toggle primary-toggle btn btn-sm" data-placement="right" data-toggle="tooltip" for="__primary" title="Toggle primary sidebar">
<span class="fa-solid fa-bars"></span>
</label>
</div>
<div class="header-article__right">
<div class="dropdown dropdown-launch-buttons">
<button aria-expanded="false" aria-label="Launch interactive content" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-rocket"></i>
</button>
<ul class="dropdown-menu">
</ul>
</div>
<button class="btn btn-sm" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="btn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="dropdown dropdown-repository-buttons">
<button aria-expanded="false" aria-label="Source repositories" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fab fa-github"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/neuromatch/instructor-neuroai-course-content" target="_blank" title="Source repository">
<span class="btn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="btn__text-container">repository</span>
</a>

<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/neuromatch/instructor-neuroai-course-content/issues/new?title=Issue%20on%20page%20%2Ftutorials/W1D1_Generalization/instructor/W1D1_Tutorial1.html&amp;body=Your%20issue%20content%20here." target="_blank" title="Open an issue">
<span class="btn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="btn__text-container">open issue</span>
</a>

</li></li></ul>
</div>
<div class="dropdown dropdown-download-buttons">
<button aria-expanded="false" aria-label="Download this page" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-download"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W1D1_Generalization/instructor/W1D1_Tutorial1.ipynb" target="_blank" title="Download source file">
<span class="btn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="btn__text-container">.ipynb</span>
</a>

<li>
<button class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="btn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="btn__text-container">.pdf</span>
</button>

</li></li></ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" data-placement="left" data-toggle="tooltip" for="__secondary" title="Toggle secondary sidebar">
<span class="fa-solid fa-list"></span>
</label>
</div>
</div>
</div>
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 1: Generalization in AI</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 1: Generalization in AI
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-and-import-feedback-gadget">
     Install and import feedback gadget
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
       Install and import feedback gadget
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#import-dependencies">
       Import dependencies
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
       Figure settings
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
       Plotting functions
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-retrieval">
     Data Retrieval
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-motivation-building-a-handwriting-recognition-app-with-ai">
   Section 1: Motivation: building a handwriting recognition app with AI
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-1-trocr">
     Interactive demo 1: TrOCR
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#discussion-point">
       Discussion point
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-measuring-out-of-distribution-generalization-in-trocr">
   Section 2: Measuring out-of-distribution generalization in TrOCR
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-1">
     Think! 1
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-activity-1-measuring-out-of-distribution-generalization">
     Coding activity 1: measuring out-of-distribution generalization
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#run-this-cell-to-visualize-dataset">
       Run this cell to visualize dataset.
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#code-exercise-1-1-calculate-cer-and-wer">
       Code exercise 1.1: calculate CER and WER
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#code-exercise-1-2-calculate-cer-and-wer-across-all-subjects">
       Code exercise 1.2: calculate CER and WER across all subjects
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#code-exercise-1-3-measure-ood-generalization">
       Code exercise 1.3: measure OOD generalization
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#discussion">
     Discussion
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-dissecting-trocr">
   Section 3: Dissecting TrOCR
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-a-recap-of-transformers">
     Section 3.1: A recap of transformers
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-2-the-encoder-and-decoder">
     Section 3.2: The encoder and decoder
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#code-exercise-3-1-understanding-the-inputs-and-outputs-of-the-decoder">
       Code exercise 3.1: Understanding the inputs and outputs of the decoder
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-the-magic-in-the-data">
   Section 4: The magic in the data
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-1-text-and-video-replacing-hours-of-text-measurement-exercise">
     Section 4.1: text and video replacing hours of text measurement exercise
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#submit-your-feedback">
       Submit your feedback
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-2-generalization-via-augmentation">
     Section 4.2: Generalization via augmentation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id4">
       Submit your feedback
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-3-generalization-via-synthetic-data">
     Section 4.3: Generalization via synthetic data
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id5">
       Discussion point
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id6">
         Submit your feedback
        </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-4-1-generating-handwriting-style-data">
       Interactive demo 4.1: Generating handwriting style data
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id7">
         Submit your feedback
        </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<article class="bd-article" role="main">
<p><a href="https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/student/W1D1_Tutorial1.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W1D1_Generalization/student/W1D1_Tutorial1.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-1-generalization-in-ai">
<h1>Tutorial 1: Generalization in AI<a class="headerlink" href="#tutorial-1-generalization-in-ai" title="Permalink to this heading">#</a></h1>
<p><strong>Week 1, Day 1: Generalization</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Samuele Bolotta &amp; Patrick Mineault</p>
<p><strong>Content reviewers:</strong> Samuele Bolotta, Lily Chamakura, RyeongKyung Yoon, Yizhou Chen, Ruiyi Zhang, Aakash Agrawal, Alish Dipani, Hossein Rezaei, Yousef Ghanbari, Mostafa Abdollahi</p>
<p><strong>Production editors:</strong> Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk</p>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing of tutorial: [insert estimated duration of the whole tutorial in minutes]</em></p>
<p>This tutorial will introduce you to generalization in the context of modern AI systems. We’ll look at a particular system trained for handwriting recognition–TrOCR. We’ll review what makes that model tick–the transformer architecture–and explore what goes on into training and finetuning large-scale models. We’ll look at how augmentations can bake in particular inductive biases in transformers. Finally, we’ll have a bonus section on scaling laws.</p>
<p>Our learning objectives for today are:</p>
<ol class="arabic simple">
<li><p>Identify and articulate common objectives pursued by developers of operational AI systems, such as:</p></li>
</ol>
<ul class="simple">
<li><p>OOD robustness; latency; Size, Weight, Power, and Cost (SWaP-C)</p></li>
<li><p>Explainability and understanding</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Explain at least three strategies for enhancing the generalization capabilities of AI systems, including the contemporary trend of training generic large-scale models on extensive datasets, commonly referred to as the “bitter lesson.”</p></li>
<li><p>Gain practical experience with the fundamentals of deep learning and PyTorch.</p></li>
</ol>
<p><strong>Important note</strong>: this tutorial leverages GPU acceleration. Using a GPU runtime in colab will make the the tutorial run 10x faster.</p>
<p>Let’s get started.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "ab62606d65294415afcc5446e1416b17"}</script></div>
</div>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h1>
<section id="install-and-import-feedback-gadget">
<h2>Install and import feedback gadget<a class="headerlink" href="#install-and-import-feedback-gadget" title="Permalink to this heading">#</a></h2>
<section id="id1">
<h3>Install and import feedback gadget<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install and import feedback gadget</span>

<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>vibecheck<span class="w"> </span>Pillow<span class="w"> </span>matplotlib<span class="w"> </span>torch<span class="w"> </span>torchvision<span class="w"> </span>transformers<span class="w"> </span>gradio<span class="w"> </span>protobuf<span class="w"> </span>sentencepiece<span class="w"> </span>gradio<span class="w"> </span>torchmetrics<span class="w"> </span>--quiet

<span class="kn">from</span> <span class="nn">vibecheck</span> <span class="kn">import</span> <span class="n">DatatopsContentReviewContainer</span>
<span class="k">def</span> <span class="nf">content_review</span><span class="p">(</span><span class="n">notebook_section</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">DatatopsContentReviewContainer</span><span class="p">(</span>
        <span class="s2">""</span><span class="p">,</span>  <span class="c1"># No text prompt - leave this as is</span>
        <span class="n">notebook_section</span><span class="p">,</span>
        <span class="p">{</span>
        <span class="s2">"url"</span><span class="p">:</span> <span class="s2">"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab"</span><span class="p">,</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"sciencematch_sm"</span><span class="p">,</span> <span class="c1"># change the name of the course : neuromatch_dl, climatematch_ct, etc</span>
        <span class="s2">"user_key"</span><span class="p">:</span> <span class="s2">"y1x3mpx5"</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>

<span class="n">feedback_prefix</span> <span class="o">=</span> <span class="s2">"W1D1_T1"</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class="-Color -Color-Yellow">WARNING: typer 0.12.3 does not provide the extra 'all'</span>

</pre></div>
</div>
</div>
</div>
</section>
<section id="import-dependencies">
<h3>Import dependencies<a class="headerlink" href="#import-dependencies" title="Permalink to this heading">#</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
</section>
</section>
<section id="figure-settings">
<h2>Figure Settings<a class="headerlink" href="#figure-settings" title="Permalink to this heading">#</a></h2>
<section id="id2">
<h3>Figure settings<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>
<span class="c1"># @markdown</span>

<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">'matplotlib.font_manager'</span><span class="p">)</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">True</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="plotting-functions">
<h2>Plotting Functions<a class="headerlink" href="#plotting-functions" title="Permalink to this heading">#</a></h2>
<section id="id3">
<h3>Plotting functions<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting functions</span>

<span class="k">def</span> <span class="nf">display_image</span><span class="p">(</span><span class="n">image_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Display an image from a given file path.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - image_path (str): The path to the image file.</span>
<span class="sd">    """</span>
    <span class="c1"># Open the image</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">image</span><span class="o">.</span><span class="n">mode</span> <span class="o">!=</span> <span class="s1">'RGB'</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">'RGB'</span><span class="p">)</span>

    <span class="c1"># Display the image</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>  <span class="c1"># Turn off the axis</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">display_transformed_images</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">transformations</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Apply a list of transformations to an image and display them.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - image (Tensor): The input image as a tensor.</span>
<span class="sd">    - transformations (list): A list of torchvision transformations to apply.</span>
<span class="sd">    """</span>
    <span class="c1"># Convert tensor image to PIL Image for display</span>
    <span class="n">pil_image</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">()(</span><span class="n">image</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">transformations</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">pil_image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Original'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">transform</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">transformations</span><span class="p">):</span>
        <span class="c1"># Apply transformation if it's not the placeholder</span>
        <span class="k">if</span> <span class="n">transform</span> <span class="o">!=</span> <span class="s2">"Custom ElasticTransform Placeholder"</span><span class="p">:</span>
            <span class="n">transformed_image</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
            <span class="c1"># Convert transformed tensor image to PIL Image for display</span>
            <span class="n">display_image</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">()(</span><span class="n">transformed_image</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">display_image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">transform</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">'ElasticTransform Placeholder'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">display_original_and_transformed_images</span><span class="p">(</span><span class="n">original_tensor</span><span class="p">,</span> <span class="n">transformed_tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Display the original and transformed images side by side.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - original_tensor (Tensor): The original image as a tensor.</span>
<span class="sd">    - transformed_tensor (Tensor): The transformed image as a tensor.</span>
<span class="sd">    """</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="c1"># Display original image</span>
    <span class="n">original_image</span> <span class="o">=</span> <span class="n">original_tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># Convert from (C, H, W) to (H, W, C)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">original_image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Original'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>

    <span class="c1"># Display transformed image</span>
    <span class="n">transformed_image</span> <span class="o">=</span> <span class="n">transformed_tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># Convert from (C, H, W) to (H, W, C)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">transformed_image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Transformed'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">display_generated_images</span><span class="p">(</span><span class="n">generator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Display images generated from strings.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - generator (GeneratorFromStrings): A generator that produces images from strings.</span>
<span class="sd">    """</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">text_img</span><span class="p">,</span> <span class="n">lbl</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">strings</span><span class="p">)</span> <span class="o">*</span> <span class="n">generator</span><span class="o">.</span><span class="n">count</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">strings</span><span class="p">),</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">text_img</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Example </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="c1"># Function to generate an image with text</span>
<span class="k">def</span> <span class="nf">generate_image</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">font_path</span><span class="p">,</span> <span class="n">space_width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">skewing_angle</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Generate an image with text.</span>

<span class="sd">    Args:</span>
<span class="sd">        text (str): Text to be rendered in the image.</span>
<span class="sd">        font_path (str): Path to the font file.</span>
<span class="sd">        space_width (int): Space width between characters.</span>
<span class="sd">        skewing_angle (int): Angle to skew the text image.</span>
<span class="sd">    """</span>
    <span class="n">image_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">350</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
    <span class="n">background_color</span> <span class="o">=</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
    <span class="n">speckle_threshold</span> <span class="o">=</span> <span class="mf">0.05</span>
    <span class="n">speckle_color</span> <span class="o">=</span> <span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
    <span class="n">background</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">64</span> <span class="o">+</span> <span class="mi">191</span>
    <span class="n">background</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">background</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
    <span class="n">background</span><span class="p">[:,</span> <span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">IMG</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">background</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'uint8'</span><span class="p">),</span> <span class="s1">'RGBA'</span><span class="p">)</span>
    <span class="n">image2</span> <span class="o">=</span> <span class="n">IMG</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="s1">'RGBA'</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">draw</span> <span class="o">=</span> <span class="n">ImageDraw</span><span class="o">.</span><span class="n">Draw</span><span class="p">(</span><span class="n">image2</span><span class="p">)</span>
    <span class="n">font</span> <span class="o">=</span> <span class="n">ImageFont</span><span class="o">.</span><span class="n">truetype</span><span class="p">(</span><span class="n">font_path</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">36</span><span class="p">)</span>
    <span class="n">text_size</span> <span class="o">=</span> <span class="n">draw</span><span class="o">.</span><span class="n">textlength</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">font</span><span class="o">=</span><span class="n">font</span><span class="p">)</span>
    <span class="n">text_position</span> <span class="o">=</span> <span class="p">((</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">text_size</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">font</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">draw</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">text_position</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">font</span><span class="o">=</span><span class="n">font</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">spacing</span><span class="o">=</span><span class="n">space_width</span><span class="p">)</span>
    <span class="n">image2</span> <span class="o">=</span> <span class="n">image2</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">skewing_angle</span><span class="p">)</span>
    <span class="n">image</span><span class="o">.</span><span class="n">paste</span><span class="p">(</span><span class="n">image2</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">image2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image</span>

<span class="c1"># Function to generate images for multiple strings</span>
<span class="k">def</span> <span class="nf">image_generator</span><span class="p">(</span><span class="n">strings</span><span class="p">,</span> <span class="n">font_path</span><span class="p">,</span> <span class="n">space_width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">skewing_angle</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Generate images for multiple strings.</span>

<span class="sd">    Args:</span>
<span class="sd">        strings (list): List of strings to generate images for.</span>
<span class="sd">        font_path (str): Path to the font file.</span>
<span class="sd">        space_width (int): Space width between characters.</span>
<span class="sd">        skewing_angle (int): Angle to skew the text image.</span>
<span class="sd">    """</span>
    <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">strings</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">generate_image</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">font_path</span><span class="p">,</span> <span class="n">space_width</span><span class="p">,</span> <span class="n">skewing_angle</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="data-retrieval">
<h2>Data Retrieval<a class="headerlink" href="#data-retrieval" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">download_file</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">expected_md5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Downloads a file from the given URL and saves it locally.</span>
<span class="sd">    Verifies the integrity of the file using an MD5 checksum.</span>

<span class="sd">    Args:</span>
<span class="sd">    - fname (str): The local filename/path to save the downloaded file.</span>
<span class="sd">    - url (str): The URL from which to download the file.</span>
<span class="sd">    - expected_md5 (str): The expected MD5 checksum to verify the integrity of the downloaded data.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">fname</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
            <span class="n">r</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>  <span class="c1"># Raises an HTTPError for bad responses</span>
        <span class="k">except</span> <span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">ConnectionError</span><span class="p">,</span> <span class="n">requests</span><span class="o">.</span><span class="n">HTTPError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"!!! Failed to download </span><span class="si">{</span><span class="n">fname</span><span class="si">}</span><span class="s2"> due to: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2"> !!!"</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span> <span class="o">==</span> <span class="n">expected_md5</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fid</span><span class="p">:</span>
                <span class="n">fid</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">fname</span><span class="si">}</span><span class="s2"> has been downloaded successfully."</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"!!! Data download appears corrupted !!!"</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">extract_zip</span><span class="p">(</span><span class="n">zip_fname</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s1">'.'</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Extracts a ZIP file to the specified folder.</span>

<span class="sd">    Args:</span>
<span class="sd">    - zip_fname (str): The filename/path of the ZIP file to be extracted.</span>
<span class="sd">    - folder (str): Destination folder where the ZIP contents will be extracted.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">is_zipfile</span><span class="p">(</span><span class="n">zip_fname</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">zip_fname</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
            <span class="n">zip_ref</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Extracted </span><span class="si">{</span><span class="n">zip_fname</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">folder</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Skipped extraction for </span><span class="si">{</span><span class="n">zip_fname</span><span class="si">}</span><span class="s2"> as it is not a zip file."</span><span class="p">)</span>

<span class="c1"># Define the list of files to download, including both ZIP files and other file types</span>
<span class="n">file_info</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">"Dancing_Script.zip"</span><span class="p">,</span> <span class="s2">"https://osf.io/32yed/download"</span><span class="p">,</span> <span class="s2">"d59bd3201b58a37d0d3b4cd0b0ec7400"</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"lines.zip"</span><span class="p">,</span> <span class="s2">"https://osf.io/8a753/download"</span><span class="p">,</span> <span class="s2">"6815ed3987f8eb2fd3bc7678c11f2e9e"</span><span class="p">,</span> <span class="s1">'lines'</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"transcripts.csv"</span><span class="p">,</span> <span class="s2">"https://osf.io/9hgr8/download"</span><span class="p">,</span> <span class="s2">"d81d9ade10db55603cc893345debfaa2"</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"neuroai_hello_world.png"</span><span class="p">,</span> <span class="s2">"https://osf.io/zg4w5/download"</span><span class="p">,</span> <span class="s2">"f08b81e47f2fe66b5f25b2ccc204c780"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>  <span class="c1"># New image file</span>
<span class="p">]</span>


<span class="c1"># Process the downloads and extractions</span>
<span class="k">for</span> <span class="n">fname</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">expected_md5</span><span class="p">,</span> <span class="n">folder</span> <span class="ow">in</span> <span class="n">file_info</span><span class="p">:</span>
    <span class="n">download_file</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">expected_md5</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">folder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">extract_zip</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">folder</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dancing_Script.zip has been downloaded successfully.
Extracted Dancing_Script.zip to ..
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>lines.zip has been downloaded successfully.
Extracted lines.zip to lines.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>transcripts.csv has been downloaded successfully.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>neuroai_hello_world.png has been downloaded successfully.
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="section-1-motivation-building-a-handwriting-recognition-app-with-ai">
<h1>Section 1: Motivation: building a handwriting recognition app with AI<a class="headerlink" href="#section-1-motivation-building-a-handwriting-recognition-app-with-ai" title="Permalink to this heading">#</a></h1>
<p>Let’s put ourselves into the mindset of an AI developer who wants to build a note app featuring handwriting recognition.</p>
<p><img alt="Picture which shows W1D1 goal." src="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/static/W1D1_goal.png?raw=true"/></p>
<p>Our intrepid goes on HuggingFace and finds a suitable model: <a class="reference external" href="https://huggingface.co/docs/transformers/en/model_doc/trocr">TrOCR</a>! It’s a Transformer-based model that performs Optical Character Recognition and handwriting transcription. Several checkpoints are available, finetuned for different downstream applications like handwriting transcription and printed character recognition. Our relieved developer draws a deep sigh: they don’t have to start from scratch.</p>
<p><img alt="Picture which shows trocr architecture." src="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/static/trocr_architecture.png?raw=true"/></p>
<p>In this tutorial, we’ll look at the design considerations that go into training and deploying a model like TrOCR, what goes on inside the model’s transformers, and how it achieves good–or sometimes not-so-good–out-of-distribution generalization. While the NeuroAI course as a whole will explore new ideas at the frontier of neuroscience and AI, we’ll first want to understand one of the bread-and-butter building blocks used in industrial AI: the transformer.</p>
<p>Let’s try out this model ourselves!</p>
<section id="interactive-demo-1-trocr">
<h2>Interactive demo 1: TrOCR<a class="headerlink" href="#interactive-demo-1-trocr" title="Permalink to this heading">#</a></h2>
<p>We load a pretrained TrOCR checkpoint from HuggingFace.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the pre-trained TrOCR model and processor</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">VisionEncoderDecoderModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"microsoft/trocr-base-handwritten"</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">TrOCRProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"microsoft/trocr-base-handwritten"</span><span class="p">,</span> <span class="n">use_fast</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "55d0ace60eb342848eb4ce1a4682baf5"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "14fe32e2533749f4b6cefff1635e9641"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "06740588aae74308af8df6e20c15625f"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "1e5eb724ceae4cacb8af6f1397184c53"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "522dec5b990e4a088e4a4efd42fb84f0"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "ee4277371fc348acb92f8deef0266df1"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "0db7397058444059810c850f3f6b4602"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "96e858ba796a4dc0b6193553f3df1124"}</script></div>
</div>
<p>We write a callback function that calls the preloaded model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the function to recognize text from an image</span>
<span class="k">def</span> <span class="nf">recognize_text</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    This function takes an image as input and uses a pre-trained language model to generate text from the image.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - processor: The processor to use</span>
<span class="sd">    - model: The model to use</span>
<span class="sd">    - image (PIL Image or Tensor): The input image containing text to be recognized.</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - text (str): The recognized text extracted from the input image.</span>
<span class="sd">    """</span>
    <span class="n">pixel_values</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">pixel_values</span>
    <span class="n">generated_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">pixel_values</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated_ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">text</span>
</pre></div>
</div>
</div>
</div>
<p>We build a simple interface in gradio to try out the model interactively.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a Gradio interface</span>
<span class="n">interface</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">Interface</span><span class="p">(</span>
    <span class="n">fn</span><span class="o">=</span><span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">recognize_text</span><span class="p">,</span> <span class="n">processor</span><span class="p">,</span> <span class="n">model</span><span class="p">),</span>
    <span class="n">inputs</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"pil"</span><span class="p">),</span>
    <span class="n">outputs</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">Textbox</span><span class="p">(),</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Interactive demo: TrOCR"</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">"Demo for Microsoft’s TrOCR, an encoder-decoder model for OCR on single-text line images."</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Launch the interface</span>
<span class="n">interface</span><span class="o">.</span><span class="n">launch</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
</pre></div>
</div>
<div class="output text_html"><div><iframe allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" allowfullscreen="" frameborder="0" height="500" src="http://127.0.0.1:7860/" width="100%"></iframe></div></div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<p>Go ahead and try some example text to see how it works. You can use images from the internet, or scan your own handwriting. Just make sure that the text fits on one line.</p>
<p><img alt="Picture which shows sample 0." src="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/static/sample_0.png?raw=true"/></p>
<p><img alt="Picture which shows sample 1." src="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/static/sample_1.png?raw=true"/></p>
<p><img alt="Picture which shows sample 2." src="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/static/sample_2.png?raw=true"/></p>
<p><img alt="Picture which shows sample 3." src="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/static/sample_3.png?raw=true"/></p>
<section id="discussion-point">
<h3>Discussion point<a class="headerlink" href="#discussion-point" title="Permalink to this heading">#</a></h3>
<p>How effective is the model’s performance? Does it exhibit generalization beyond its training vocabulary?</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="section-2-measuring-out-of-distribution-generalization-in-trocr">
<h1>Section 2: Measuring out-of-distribution generalization in TrOCR<a class="headerlink" href="#section-2-measuring-out-of-distribution-generalization-in-trocr" title="Permalink to this heading">#</a></h1>
<p>How well does TrOCR work in practice? Our developer needs to know!</p>
<p>Something you will see a lot of in machine learning papers are tables filled with benchmarks. The tables in the <a class="reference external" href="https://arxiv.org/abs/2109.10282">TrOCR official paper</a> include measures of performance on different benchmark datasets, including IAM, <a class="reference external" href="https://fki.tic.heia-fr.ch/databases/iam-handwriting-database">a handwriting database assembled in 1999</a>. The base and large model variants (334M and 558M parameters) display <strong>character error rates (CER) of 3.42 and 2.89, respectively</strong>.</p>
<p>“Wow!”, our developer thinks, “That’s probably good enough for my notes app! Guess I can go ahead and deploy it”.</p>
<section id="think-1">
<h2>Think! 1<a class="headerlink" href="#think-1" title="Permalink to this heading">#</a></h2>
<p>What are some reasons why the character error rate measured on IAM might be too optimistic?</p>
</section>
<section id="coding-activity-1-measuring-out-of-distribution-generalization">
<h2>Coding activity 1: measuring out-of-distribution generalization<a class="headerlink" href="#coding-activity-1-measuring-out-of-distribution-generalization" title="Permalink to this heading">#</a></h2>
<p>Our developer reads through the fine print in the paper and realizes that the TrOCR is both <em>trained</em> on IAM and <em>tested</em> on IAM, on a different set of subjects. To be clear, the train and test splits <em>are</em> distinct; but samples come from the same underlying distribution. Our developer realizes that the reported error rates might be too optimistic:</p>
<ul class="simple">
<li><p>IAM was recorded on a tablet. Our developer wants to be able to recognize lines of text handwritten on paper.</p></li>
<li><p>IAM is 25 years old. Maybe people write differently now compared to in the past. Do they even write in cursive anymore?</p></li>
<li><p>The sentences in IAM are based on a widely published corpus. Maybe TrOCR has memorized that corpus.</p></li>
</ul>
<p>The more the developer thinks about it, the more they realize that the paper is really estimating <em>in-distribution generalization</em>. However, what they care about is how well the model will work when it’s deployed <em>in the wild</em>, which is closer to <strong>out-of-distribution generalization</strong>.</p>
<p>In this coding activity, you’ll measure out-of-distribution generalization on a small subset of the CVL database:</p>
<blockquote>
<div><p>Kleber, F., Fiel, S., Diem, M., &amp; Sablatnig, R. (2018). CVL Database - An Off-line Database for Writer Retrieval, Writer Identification and Word Spotting [Data set]. Zenodo. https://doi.org/10.5281/zenodo.1492267</p>
</div></blockquote>
<p>Let’s first have a look at this new out-of-distribution dataset.</p>
<section id="run-this-cell-to-visualize-dataset">
<h3>Run this cell to visualize dataset.<a class="headerlink" href="#run-this-cell-to-visualize-dataset" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Run this cell to visualize dataset.</span>
<span class="k">def</span> <span class="nf">get_images_and_transcripts</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">subject</span><span class="p">):</span>
    <span class="n">df_</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">subject</span> <span class="o">==</span> <span class="n">subject</span><span class="p">]</span>
    <span class="n">transcripts</span> <span class="o">=</span> <span class="n">df_</span><span class="o">.</span><span class="n">transcript</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="c1"># Load the corresponding images</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df_</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
        <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">IMG</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">filename</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">images</span><span class="p">,</span> <span class="n">transcripts</span>

<span class="k">def</span> <span class="nf">visualize_images_and_transcripts</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">transcripts</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
        <span class="n">display</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">transcript</span> <span class="ow">in</span> <span class="n">transcripts</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">transcript</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'transcripts.csv'</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'filename'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"lines/</span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">subject</span><span class="si">:</span><span class="s2">04</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">line</span><span class="si">}</span><span class="s2">.jpg"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>obs</th>
<th>subject</th>
<th>line</th>
<th>transcript</th>
<th>filename</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>0</td>
<td>52</td>
<td>1</td>
<td>imagine a vast sheet of paper on which</td>
<td>lines/0052-1.jpg</td>
</tr>
<tr>
<th>1</th>
<td>1</td>
<td>52</td>
<td>2</td>
<td>straight lines triangles squares pentagons</td>
<td>lines/0052-2.jpg</td>
</tr>
<tr>
<th>2</th>
<td>2</td>
<td>52</td>
<td>3</td>
<td>hexagons and other figures instead of remaining</td>
<td>lines/0052-3.jpg</td>
</tr>
<tr>
<th>3</th>
<td>3</td>
<td>52</td>
<td>4</td>
<td>fixed in their places move freely about on or</td>
<td>lines/0052-4.jpg</td>
</tr>
<tr>
<th>4</th>
<td>4</td>
<td>52</td>
<td>5</td>
<td>in the surface but without the power of rising</td>
<td>lines/0052-5.jpg</td>
</tr>
<tr>
<th>...</th>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<th>89</th>
<td>5</td>
<td>79</td>
<td>6</td>
<td>much like shadows only hard and with luminous ...</td>
<td>lines/0079-6.jpg</td>
</tr>
<tr>
<th>90</th>
<td>6</td>
<td>79</td>
<td>7</td>
<td>and you will then have a pretty correct notion...</td>
<td>lines/0079-7.jpg</td>
</tr>
<tr>
<th>91</th>
<td>7</td>
<td>79</td>
<td>8</td>
<td>country and countrymen alas a few years ago</td>
<td>lines/0079-8.jpg</td>
</tr>
<tr>
<th>92</th>
<td>8</td>
<td>79</td>
<td>9</td>
<td>i should have said my universe but now my mind</td>
<td>lines/0079-9.jpg</td>
</tr>
<tr>
<th>93</th>
<td>9</td>
<td>79</td>
<td>10</td>
<td>has been opened to higher views of things</td>
<td>lines/0079-10.jpg</td>
</tr>
</tbody>
</table>
<p>94 rows × 5 columns</p>
</div></div></div>
</div>
<p>This is a small test set with 94 lines sampled from 10 different subjects. Let’s have a look at the data from subject 54.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">images</span><span class="p">,</span> <span class="n">true_transcripts</span> <span class="o">=</span> <span class="n">get_images_and_transcripts</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="mi">52</span><span class="p">)</span>
<span class="n">visualize_images_and_transcripts</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">true_transcripts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/451a92aa43a9883fc8618bac3ac85a57d839e921fa5d971240ae8d305366c9ab.png" src="../../../_images/451a92aa43a9883fc8618bac3ac85a57d839e921fa5d971240ae8d305366c9ab.png"/>
<img alt="../../../_images/1cb6e1c4dd508cd58db3414e22a4042712df80e0bfdee35ea337900b2f43e1e7.png" src="../../../_images/1cb6e1c4dd508cd58db3414e22a4042712df80e0bfdee35ea337900b2f43e1e7.png"/>
<img alt="../../../_images/ec857255d866d0128d23b0f48b32c61dff54a5e825b84fea3011caca167ada41.png" src="../../../_images/ec857255d866d0128d23b0f48b32c61dff54a5e825b84fea3011caca167ada41.png"/>
<img alt="../../../_images/1fe7cbf693e34c3c86f79e0d627899f3de326f783c6579b915a4c53e10251cc1.png" src="../../../_images/1fe7cbf693e34c3c86f79e0d627899f3de326f783c6579b915a4c53e10251cc1.png"/>
<img alt="../../../_images/a6846333534664c579eb4e3c188b22c64bb1efcd20f18b9d69312b30fd9b3c80.png" src="../../../_images/a6846333534664c579eb4e3c188b22c64bb1efcd20f18b9d69312b30fd9b3c80.png"/>
<img alt="../../../_images/5cd08068751a2d3133c3bd74b5398209ec2f651effdf02492f84f6e8884d6909.png" src="../../../_images/5cd08068751a2d3133c3bd74b5398209ec2f651effdf02492f84f6e8884d6909.png"/>
<img alt="../../../_images/69d1aa29ae2632275b2bba138a74e0dd3515f8da35c908844f125da5d30c9959.png" src="../../../_images/69d1aa29ae2632275b2bba138a74e0dd3515f8da35c908844f125da5d30c9959.png"/>
<img alt="../../../_images/dcf75f86c4da64ef4c8a06d853ac1b0dee012c3f2203cc2470f1bd098ae8b9b3.png" src="../../../_images/dcf75f86c4da64ef4c8a06d853ac1b0dee012c3f2203cc2470f1bd098ae8b9b3.png"/>
<img alt="../../../_images/bb8267ed0daabede11e39766d51a87ef1f8a373995055d9408edde6a21ef6007.png" src="../../../_images/bb8267ed0daabede11e39766d51a87ef1f8a373995055d9408edde6a21ef6007.png"/>
<img alt="../../../_images/730f7166010e496ae86fe3442f61eccedf5a1096b904687d889afc8ab2324161.png" src="../../../_images/730f7166010e496ae86fe3442f61eccedf5a1096b904687d889afc8ab2324161.png"/>
<img alt="../../../_images/55104621360699ff7ad4942c4cd02a4a64efd7cee42f76813276ee5ee093aab8.png" src="../../../_images/55104621360699ff7ad4942c4cd02a4a64efd7cee42f76813276ee5ee093aab8.png"/>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>imagine a vast sheet of paper on which
straight lines triangles squares pentagons
hexagons and other figures instead of remaining
fixed in their places move freely about on or
in the surface but without the power of rising
above or sinking below it very much like shadows
only hard and with luminous edges and you
will then have a pretty correct notion of my
country and countrymen alas a few years ago
i should have said my universe but now my
mind has been opened to higher views of things
</pre></div>
</div>
</div>
</div>
<p>The text is transcribed from a passage in the novel <a class="reference external" href="https://en.wikipedia.org/wiki/Flatland">Flatland by Edwin Abbott Abbott</a>. How well does the model recognize the text? Run this cell to find out.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transcribe_images</span><span class="p">(</span><span class="n">all_images</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">processor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Transcribe a batch of images using an OCR model.</span>

<span class="sd">    Args:</span>
<span class="sd">        all_images: a list of PIL images.</span>
<span class="sd">        model: the model to do image-to-token ids</span>
<span class="sd">        processor: the processor which maps token ids to text</span>

<span class="sd">    Returns:</span>
<span class="sd">        a list of the transcribed text.</span>
<span class="sd">    """</span>
    <span class="n">pixel_values</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">all_images</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">pixel_values</span>
    <span class="n">generated_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">pixel_values</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="n">decoded_text</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated_ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">decoded_text</span>

<span class="n">transcribed_text</span> <span class="o">=</span> <span class="n">transcribe_images</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">processor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">transcribed_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>['Imagine a vast sheet of paper on which', 'Straight Lines, Triangles, Squares, Pentagon,', 'Hexagens, and other figures, instead of remaining', 'fixed in their places, more freely about, on or', 'in the surface, but without the power of rising', 'above or sinking below it, very much like shadow', 'only had and with luminous edges - and you', 'will then have a pretty carpet notion of my', 'country and countrymen. Also, a fine years ago,', 'I should have said " my unisence ", but now my', 'mind has been opened to higher views of things.']
</pre></div>
</div>
</div>
</div>
</section>
<section id="code-exercise-1-1-calculate-cer-and-wer">
<h3>Code exercise 1.1: calculate CER and WER<a class="headerlink" href="#code-exercise-1-1-calculate-cer-and-wer" title="Permalink to this heading">#</a></h3>
<p>The model is not perfect but it performs far better than chance. Let’s measure the character and word error rates on this subject’s data. Fill in missing code to measure character and word error rates on this dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">clean_string</span><span class="p">(</span><span class="n">input_string</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Clean string prior to comparison</span>

<span class="sd">    Args:</span>
<span class="sd">        input_string (str): the input string</span>

<span class="sd">    Returns:</span>
<span class="sd">        (str) a cleaned string, lowercase, alphabetical characters only, no double spaces</span>
<span class="sd">    """</span>

    <span class="c1"># Convert all characters to lowercase</span>
    <span class="n">lowercase_string</span> <span class="o">=</span> <span class="n">input_string</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="c1"># Remove non-alphabetic characters</span>
    <span class="n">alpha_string</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'[^a-z\s]'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">lowercase_string</span><span class="p">)</span>

    <span class="c1"># Remove double spaces and start and end spaces</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">alpha_string</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">calculate_mismatch</span><span class="p">(</span><span class="n">estimated_text</span><span class="p">,</span> <span class="n">reference_text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Calculate mismatch (character and word error rates) between estimated and true text.</span>

<span class="sd">    Args:</span>
<span class="sd">        estimated_text: a list of strings</span>
<span class="sd">        reference_text: a list of strings</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tuple, (CER and WER)</span>
<span class="sd">    """</span>
    <span class="c1"># Lowercase the text and remove special characters for the comparison</span>
    <span class="n">estimated_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">clean_string</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">estimated_text</span><span class="p">]</span>
    <span class="n">reference_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">clean_string</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">reference_text</span><span class="p">]</span>

    <span class="c1">############################################################</span>
    <span class="c1"># Fill in this code to calculate character error rate and word error rate.</span>
    <span class="c1"># Hint: have a look at the torchmetrics documentation for the proper</span>
    <span class="c1"># metrics.</span>
    <span class="c1">#</span>
    <span class="c1"># https://lightning.ai/docs/torchmetrics/stable/</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student has to fill in these lines"</span><span class="p">)</span>
    <span class="c1">############################################################</span>

    <span class="c1"># Calculate the character error rate and word error rates. They should be</span>
    <span class="c1"># raw floats, not tensors.</span>
    <span class="n">cer</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">wer</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">cer</span><span class="p">,</span> <span class="n">wer</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="k">def</span> <span class="nf">clean_string</span><span class="p">(</span><span class="n">input_string</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Clean string prior to comparison</span>

<span class="sd">    Args:</span>
<span class="sd">        input_string (str): the input string</span>

<span class="sd">    Returns:</span>
<span class="sd">        (str) a cleaned string, lowercase, alphabetical characters only, no double spaces</span>
<span class="sd">    """</span>

    <span class="c1"># Convert all characters to lowercase</span>
    <span class="n">lowercase_string</span> <span class="o">=</span> <span class="n">input_string</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="c1"># Remove non-alphabetic characters</span>
    <span class="n">alpha_string</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'[^a-z\s]'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">lowercase_string</span><span class="p">)</span>

    <span class="c1"># Remove double spaces and start and end spaces</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\s+'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">alpha_string</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">calculate_mismatch</span><span class="p">(</span><span class="n">estimated_text</span><span class="p">,</span> <span class="n">reference_text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Calculate mismatch (character and word error rates) between estimated and true text.</span>

<span class="sd">    Args:</span>
<span class="sd">        estimated_text: a list of strings</span>
<span class="sd">        reference_text: a list of strings</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tuple, (CER and WER)</span>
<span class="sd">    """</span>
    <span class="c1"># Lowercase the text and remove special characters for the comparison</span>
    <span class="n">estimated_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">clean_string</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">estimated_text</span><span class="p">]</span>
    <span class="n">reference_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">clean_string</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">reference_text</span><span class="p">]</span>

    <span class="c1"># Calculate the character error rate and word error rates. They should be</span>
    <span class="c1"># raw floats, not tensors.</span>
    <span class="n">cer</span> <span class="o">=</span> <span class="n">fm</span><span class="o">.</span><span class="n">char_error_rate</span><span class="p">(</span><span class="n">estimated_text</span><span class="p">,</span> <span class="n">reference_text</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">wer</span> <span class="o">=</span> <span class="n">fm</span><span class="o">.</span><span class="n">word_error_rate</span><span class="p">(</span><span class="n">estimated_text</span><span class="p">,</span> <span class="n">reference_text</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">cer</span><span class="p">,</span> <span class="n">wer</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cer</span><span class="p">,</span> <span class="n">wer</span> <span class="o">=</span> <span class="n">calculate_mismatch</span><span class="p">(</span><span class="n">transcribed_text</span><span class="p">,</span> <span class="n">true_transcripts</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cer</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
<span class="n">cer</span><span class="p">,</span> <span class="n">wer</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.03326403349637985, 0.10000000149011612)
</pre></div>
</div>
</div>
</div>
<p>For this particular subject, the character error rate is 3.3%, while the word error rate is 10%. Not bad, and in line with the results in the paper.</p>
</section>
<section id="code-exercise-1-2-calculate-cer-and-wer-across-all-subjects">
<h3>Code exercise 1.2: calculate CER and WER across all subjects<a class="headerlink" href="#code-exercise-1-2-calculate-cer-and-wer-across-all-subjects" title="Permalink to this heading">#</a></h3>
<p>Let’s measure the same metric, this time across all subjects.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_all_mismatch</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">processor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Calculate CER and WER for all subjects in a dataset</span>

<span class="sd">    Args:</span>
<span class="sd">        df: a dataframe containing information about images and transcripts</span>
<span class="sd">        model: an image-to-text model</span>
<span class="sd">        processor: a processor object</span>

<span class="sd">    Returns:</span>
<span class="sd">        a list of dictionaries containing a per-subject breakdown of the</span>
<span class="sd">        results</span>
<span class="sd">    """</span>
    <span class="n">subjects</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">subject</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Calculate CER and WER for all subjects</span>
    <span class="k">for</span> <span class="n">subject</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">subjects</span><span class="p">):</span>
        <span class="c1">############################################################</span>
        <span class="c1"># Fill in the section to calculate the cer and wer for a</span>
        <span class="c1"># single subject. Look up at other sections to see how it's</span>
        <span class="c1"># done.</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise"</span><span class="p">)</span>
        <span class="c1">############################################################</span>

        <span class="c1"># Load images and labels for a given subject</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">true_transcripts</span> <span class="o">=</span> <span class="o">...</span>

        <span class="c1"># Transcribe the images to text</span>
        <span class="n">transcribed_text</span> <span class="o">=</span> <span class="o">...</span>

        <span class="c1"># Calculate the CER and WER</span>
        <span class="n">cer</span><span class="p">,</span> <span class="n">wer</span> <span class="o">=</span> <span class="o">...</span>

        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">'subject'</span><span class="p">:</span> <span class="n">subject</span><span class="p">,</span>
            <span class="s1">'cer'</span><span class="p">:</span> <span class="n">cer</span><span class="p">,</span>
            <span class="s1">'wer'</span><span class="p">:</span> <span class="n">wer</span><span class="p">,</span>
        <span class="p">})</span>
    <span class="k">return</span> <span class="n">results</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">calculate_all_mismatch</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">processor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Calculate CER and WER for all subjects in a dataset</span>

<span class="sd">    Args:</span>
<span class="sd">        df: a dataframe containing information about images and transcripts</span>
<span class="sd">        model: an image-to-text model</span>
<span class="sd">        processor: a processor object</span>

<span class="sd">    Returns:</span>
<span class="sd">        a list of dictionaries containing a per-subject breakdown of the</span>
<span class="sd">        results</span>
<span class="sd">    """</span>
    <span class="n">subjects</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">subject</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Calculate CER and WER for all subjects</span>
    <span class="k">for</span> <span class="n">subject</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">subjects</span><span class="p">):</span>
        <span class="c1"># Load images and labels for a given subject</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">true_transcripts</span> <span class="o">=</span> <span class="n">get_images_and_transcripts</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">subject</span><span class="p">)</span>

        <span class="c1"># Transcribe the images to text</span>
        <span class="n">transcribed_text</span> <span class="o">=</span> <span class="n">transcribe_images</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">processor</span><span class="p">)</span>

        <span class="c1"># Calculate the CER and WER</span>
        <span class="n">cer</span><span class="p">,</span> <span class="n">wer</span> <span class="o">=</span> <span class="n">calculate_mismatch</span><span class="p">(</span><span class="n">transcribed_text</span><span class="p">,</span> <span class="n">true_transcripts</span><span class="p">)</span>

        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">'subject'</span><span class="p">:</span> <span class="n">subject</span><span class="p">,</span>
            <span class="s1">'cer'</span><span class="p">:</span> <span class="n">cer</span><span class="p">,</span>
            <span class="s1">'wer'</span><span class="p">:</span> <span class="n">wer</span><span class="p">,</span>
        <span class="p">})</span>
    <span class="k">return</span> <span class="n">results</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">calculate_all_mismatch</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">processor</span><span class="p">)</span>
<span class="n">df_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">df_results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>subject</th>
<th>cer</th>
<th>wer</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>52</td>
<td>0.033264</td>
<td>0.100000</td>
</tr>
<tr>
<th>1</th>
<td>57</td>
<td>0.122153</td>
<td>0.233333</td>
</tr>
<tr>
<th>2</th>
<td>58</td>
<td>0.028926</td>
<td>0.077778</td>
</tr>
<tr>
<th>3</th>
<td>59</td>
<td>0.066116</td>
<td>0.144444</td>
</tr>
<tr>
<th>4</th>
<td>74</td>
<td>0.062370</td>
<td>0.155556</td>
</tr>
<tr>
<th>5</th>
<td>75</td>
<td>0.082474</td>
<td>0.188889</td>
</tr>
<tr>
<th>6</th>
<td>76</td>
<td>0.039337</td>
<td>0.122222</td>
</tr>
<tr>
<th>7</th>
<td>77</td>
<td>0.041494</td>
<td>0.111111</td>
</tr>
<tr>
<th>8</th>
<td>78</td>
<td>0.083160</td>
<td>0.177778</td>
</tr>
<tr>
<th>9</th>
<td>79</td>
<td>0.026971</td>
<td>0.100000</td>
</tr>
</tbody>
</table>
</div></div></div>
</div>
<p>Not all subjects are as easy to transcribe as subject 52! Let’s check out subject 57, who has high CER and WER.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"A subject that's harder to read"</span><span class="p">)</span>
<span class="n">images</span><span class="p">,</span> <span class="n">true_transcripts</span> <span class="o">=</span> <span class="n">get_images_and_transcripts</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="mi">57</span><span class="p">)</span>
<span class="n">visualize_images_and_transcripts</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">true_transcripts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>A subject that's harder to read
</pre></div>
</div>
<img alt="../../../_images/0391f622706363265615ae2854dc9c53168613c23f034d6e3a9ea749c57d16f0.png" src="../../../_images/0391f622706363265615ae2854dc9c53168613c23f034d6e3a9ea749c57d16f0.png"/>
<img alt="../../../_images/cea7d97cdc0501d9b7128a5d43e2008b2f784504140ead900c65a30415b7c535.png" src="../../../_images/cea7d97cdc0501d9b7128a5d43e2008b2f784504140ead900c65a30415b7c535.png"/>
<img alt="../../../_images/5745bd5fcb33dd1f2b6cb47ccaceadfcc853d2aec0bb7c0219f95b415dcf9447.png" src="../../../_images/5745bd5fcb33dd1f2b6cb47ccaceadfcc853d2aec0bb7c0219f95b415dcf9447.png"/>
<img alt="../../../_images/7ab840d3077f1a717ba28c927298806a07a61b3fc02a930f8e08b18df0b4d6b1.png" src="../../../_images/7ab840d3077f1a717ba28c927298806a07a61b3fc02a930f8e08b18df0b4d6b1.png"/>
<img alt="../../../_images/0d2d0e215151813f24504655c45a535572a7c52268a1afb986489f8ab2a8cb9f.png" src="../../../_images/0d2d0e215151813f24504655c45a535572a7c52268a1afb986489f8ab2a8cb9f.png"/>
<img alt="../../../_images/a5c242c8d552f827d47449d94f00189134e805af747cfc5b9a9bfbefdaf36d50.png" src="../../../_images/a5c242c8d552f827d47449d94f00189134e805af747cfc5b9a9bfbefdaf36d50.png"/>
<img alt="../../../_images/085f190bca08939c37a5daacdd85870e808c4756d1381da437fe55c4c18c3389.png" src="../../../_images/085f190bca08939c37a5daacdd85870e808c4756d1381da437fe55c4c18c3389.png"/>
<img alt="../../../_images/c719e1842e7dddc133b227b2820fe64b40368d4dfbfd0f368aac9b29f6298d8e.png" src="../../../_images/c719e1842e7dddc133b227b2820fe64b40368d4dfbfd0f368aac9b29f6298d8e.png"/>
<img alt="../../../_images/9d5efef5cc6889fe343e9d116c3f747d81bbd76ef02b9fca0213894eb7ff39cd.png" src="../../../_images/9d5efef5cc6889fe343e9d116c3f747d81bbd76ef02b9fca0213894eb7ff39cd.png"/>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>imagine a vast sheet of paper on which straight lines
triangles squares pentagons hexagons and other figures instead of remaining
fixed in their places move freely about on or in the surface but without
the power of rising above or sinking below it very much like
shadows only hard and with luminous edges and you will then
have a pretty correct notion of my country and countrymen
alas a few years ago i should have said
my universe but now my mind has been opened to higher
views of things
</pre></div>
</div>
</div>
</div>
<p>Indeed, this text seems harder to read.</p>
</section>
<section id="code-exercise-1-3-measure-ood-generalization">
<h3>Code exercise 1.3: measure OOD generalization<a class="headerlink" href="#code-exercise-1-3-measure-ood-generalization" title="Permalink to this heading">#</a></h3>
<p>What we’ve done thus far is to measure the empirical loss–the character error rate–for each subject. The empirical loss is defined as:</p>
<div class="math notranslate nohighlight">
\[R^e(\theta) = \mathbb{E}^e[ L(y, f(x, \theta)) ] \]</div>
<p>Here:</p>
<ul class="simple">
<li><p>The environment <span class="math notranslate nohighlight">\(e\)</span> is the training distribution</p></li>
<li><p><span class="math notranslate nohighlight">\(R^e(\theta)\)</span> is the empirical risk in an environment</p></li>
<li><p><span class="math notranslate nohighlight">\(\theta\)</span> are the learned parameters of the TrOCR model</p></li>
<li><p><span class="math notranslate nohighlight">\(x\)</span> is the conditioning data, that is, the images</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the function approximated by the TrOCR model, which maps images to probabilities of certain tokens</p></li>
<li><p><span class="math notranslate nohighlight">\(L\)</span> is the loss (or metric–not necessarily differentiable) for a single line of text, the character error rate (CER)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}^e\)</span> is the expectation taken over all the samples</p></li>
</ul>
<p>A single environment <span class="math notranslate nohighlight">\(e\)</span> corresponds to a single subject. The out-of-distribution generalization is instead given by:</p>
<div class="math notranslate nohighlight">
\[R^{OOD} = \max_{e \in \mathcal{E}_{all}} R^e(\theta) \]</div>
<p>It’s the worst-case empirical loss over the out-of-distribution environments <span class="math notranslate nohighlight">\({e \in \mathcal{E}_{all}}\)</span> we wish to deploy on. In other words, the character error rate for the subject with the most difficult-to-read handwriting.</p>
<p>Intuitively, our AI developer’s vision of robustness might be: my note transcription app is robust and generalizes if it works well even when someone has illegible handwriting. The app is only as good as how well it works in the worst-case scenario. Let’s measure that.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_mean_max_cer</span><span class="p">(</span><span class="n">df_results</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Calculate the mean character-error-rate across subjects as</span>
<span class="sd">    well as the maximum (that is, the OOD risk).</span>

<span class="sd">    Args:</span>
<span class="sd">        df_results: a dataframe containing results</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tuple, (mean_cer, max_cer)</span>
<span class="sd">    """</span>
    <span class="c1">############################################################</span>
    <span class="c1"># Fill in the section to calculate the mean and max cer</span>
    <span class="c1"># across subjects.</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise"</span><span class="p">)</span>
    <span class="c1">############################################################</span>

    <span class="c1"># Calculate the mean CER across test subjects.</span>
    <span class="n">mean_subjects</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Calculate the max CER across test subjects.</span>
    <span class="n">max_subjects</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">return</span> <span class="n">mean_subjects</span><span class="p">,</span> <span class="n">max_subjects</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">calculate_mean_max_cer</span><span class="p">(</span><span class="n">df_results</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Calculate the mean character-error-rate across subjects as</span>
<span class="sd">    well as the maximum (that is, the OOD risk).</span>

<span class="sd">    Args:</span>
<span class="sd">        df_results: a dataframe containing results</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tuple, (mean_cer, max_cer)</span>
<span class="sd">    """</span>
    <span class="c1"># Calculate the mean CER across test subjects.</span>
    <span class="n">mean_subjects</span> <span class="o">=</span> <span class="n">df_results</span><span class="o">.</span><span class="n">cer</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="c1"># Calculate the max CER across test subjects.</span>
    <span class="n">max_subjects</span> <span class="o">=</span> <span class="n">df_results</span><span class="o">.</span><span class="n">cer</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">mean_subjects</span><span class="p">,</span> <span class="n">max_subjects</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_subjects</span><span class="p">,</span> <span class="n">max_subjects</span> <span class="o">=</span> <span class="n">calculate_mean_max_cer</span><span class="p">(</span><span class="n">df_results</span><span class="p">)</span>
<span class="n">mean_subjects</span><span class="p">,</span> <span class="n">max_subjects</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.058626513369381426, 0.12215320765972137)
</pre></div>
</div>
</div>
</div>
<p>We see that:</p>
<ul class="simple">
<li><p>when measured on this (admittedly small) out-of-distribution dataset, the average character error rate is about 5.8%, larger than the 3.4% reported for IAM</p></li>
<li><p>the out-of-distribution character error rate is 12%</p></li>
</ul>
<p>Whether that’s good enough for our AI developer depends on the use case.</p>
</section>
</section>
<section id="discussion">
<h2>Discussion<a class="headerlink" href="#discussion" title="Permalink to this heading">#</a></h2>
<p>Numbers in tables filled with benchmarks don’t tell the whole story: often, we care about OOD robustness. Our developer benchmarked the TrOCR model for their use case and found a worst-case character error rate above 10%. Whether or not that’s acceptable is a judgment call, and it’s not the only metric the developer might care about. They might also need to meet other constraints:</p>
<ul class="simple">
<li><p>Memory, FLOPs, latency, cost of inference: the deployment environment might not be able to support very large-scale models because of memory or compute constraints, or those would run too slowly for the use case. Cloud inference might not be practical with limited internet access.</p></li>
<li><p>SWaP-C: if the model is embodied in a physical device, the Size, Weight, Power and Cost of that device will ultimately be important.</p></li>
<li><p>Latency of development: a bespoke model developed from scratch might take a long time to develop; our busy developer might prefer to adapt a pretrained, sub-optimal architecture than using a custom architecture</p></li>
<li><p>Cost of upkeep: machine learning systems can be notoriously difficult to keep running. Our developer might prefer to use a suboptimal system managed by somebody else than taking on the burden of dealing with the upkeep themselves.</p></li>
</ul>
<p>Our intrepid developer wants to ship this app soon! They decide on a strategy: the model is good enough to get started. They’ll deploy the model as is, but they’ll have an option in the app to report errors. They’ll then label <em>those</em> errors and fine-tune the model. Before that though, they want to understand what’s inside the model.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="section-3-dissecting-trocr">
<h1>Section 3: Dissecting TrOCR<a class="headerlink" href="#section-3-dissecting-trocr" title="Permalink to this heading">#</a></h1>
<p>TrOCR (transformer-based optical character recognition) is a model that performs printed optical character recognition and handwriting transcription on the basis of two transformers. But what’s inside of it?</p>
<p><img alt="Picture which shows trocr architecture." src="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/static/trocr_architecture.png?raw=true"/></p>
<p>TrOCR uses two transformers in an encoder-decoder architecture:</p>
<ol class="arabic simple">
<li><p>An encoder, a vision transformer (ViT), maps 16x16 patches of the image to individual tokens</p></li>
<li><p>A decoder, a text transformer, maps previously decoded text and the encoder hidden state to the next token in the sequence to be decoded. This is known as causal language modelling.</p></li>
</ol>
<section id="section-3-1-a-recap-of-transformers">
<h2>Section 3.1: A recap of transformers<a class="headerlink" href="#section-3-1-a-recap-of-transformers" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://deeplearning.neuromatch.io/tutorials/W2D5_AttentionAndTransformers/student/W2D5_Tutorial1.html">We covered transformers in W2D5 of the DL course</a>. Let’s quickly recap transformers. Transformers are a class of deep learning architectures that have become dominant in natural language processing (NLP) since their introduction in the paper “Attention is All You Need” by Vaswani et al. in 2017. Their success in natural language processing has led to their application across other domains, including computer vision, which is the case with TrOCR.</p>
<p><img alt="Picture which shows one layer transformer." src="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/static/transformer_one_layer.png?raw=true"/></p>
<p><em>Illustration from Alammar, J (2018). The Illustrated Transformer. Retrieved from https://jalammar.github.io/illustrated-transformer/</em></p>
<p>Transformers are built on self-attention, allowing them to weigh the importance of different parts of the input data differently. This has proven useful for tasks that require an understanding of context, such as language translation, text summarization, and, as we will see, optical character recognition. Some key components of transformers are:</p>
<ul class="simple">
<li><p>Tokenization: the input sequence (e.g. sentence) is split into different components (e.g. word pieces). Each component, or token, is embedded into a fixed dimensional space. In natural language processing, tokenization is done via a lookup table: every word piece is mapped to a fixed-dimensional vector. <a class="reference external" href="https://deeplearning.neuromatch.io/tutorials/W3D1_TimeSeriesAndNaturalLanguageProcessing/student/W3D1_Tutorial2.html?highlight=word2vec#tokenizers">See W3D1 of the DL course for a refresher on tokenization</a>.</p></li>
<li><p>Self-attention: A self-attention mechanism allows the tokens in the sequence to interact to form new representations. Specifically, queries and keys are derived from tokens; an inner product between queries and keys, followed by a softmax, forms the attention matrix. The attention matrix is multiplied by the value matrix to obtain a new representation.</p></li>
<li><p>Positional encoding: Positional encoding is added to the input to give the model information about the position of each token within the sequence. Unlike RNNs or CNNs, transformers do not process data in order–without position encoding, they are permutation invariant. We’ll dig deeper into what this implies in the section on the inductive biases of transformers.</p></li>
<li><p>Layer Normalization and Residual Connections are used within the transformer architecture to stabilize the learning process and improve the model’s ability to learn deep representations.</p></li>
</ul>
<p>One of the key advantages of transformers over previous architectures is a high degree of parallelism, which allows one to train larger, more capable models. Let’s inspect the training data of TrOCR.</p>
</section>
<section id="section-3-2-the-encoder-and-decoder">
<h2>Section 3.2: The encoder and decoder<a class="headerlink" href="#section-3-2-the-encoder-and-decoder" title="Permalink to this heading">#</a></h2>
<p>Let’s dig in more specifically into the <strong>encoder</strong> inside of TrOCR. It’s a visual transformer (ViT), an adaptation of transformers for problems in vision. It proceeds as follows:</p>
<ol class="arabic simple">
<li><p>It takes a raw image and resizes it to 384x384</p></li>
<li><p>It chops it up into 16x16 patches</p></li>
<li><p>It embeds each patch inside a fixed dimensional space, adding positional embeddings</p></li>
<li><p>It passes the patches through self-attention layers.</p></li>
<li><p>It ends up <span class="math notranslate nohighlight">\(577=(384/16)^2+1\)</span> total embedded tokens. For the base model, the tokens have an embedding size of 768.</p></li>
</ol>
<p>Let’s see the structure of the encoder:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ViTModel(
  (embeddings): ViTEmbeddings(
    (patch_embeddings): ViTPatchEmbeddings(
      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    )
    (dropout): Dropout(p=0.0, inplace=False)
  )
  (encoder): ViTEncoder(
    (layer): ModuleList(
      (0-11): 12 x ViTLayer(
        (attention): ViTAttention(
          (attention): ViTSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=False)
            (key): Linear(in_features=768, out_features=768, bias=False)
            (value): Linear(in_features=768, out_features=768, bias=False)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (output): ViTSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
        )
        (intermediate): ViTIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (intermediate_act_fn): GELUActivation()
        )
        (output): ViTOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      )
    )
  )
  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
  (pooler): ViTPooler(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (activation): Tanh()
  )
)
</pre></div>
</div>
</div>
</div>
<section id="code-exercise-3-1-understanding-the-inputs-and-outputs-of-the-decoder">
<h3>Code exercise 3.1: Understanding the inputs and outputs of the decoder<a class="headerlink" href="#code-exercise-3-1-understanding-the-inputs-and-outputs-of-the-decoder" title="Permalink to this heading">#</a></h3>
<p>Let’s make sure we understand how the encoder operates by giving it a sample input and checking that its output is the expected shape.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">inspect_decoder</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Inspect decoder to verify that it processes inputs in the expected way.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: the TrOCR model</span>
<span class="sd">    """</span>
    <span class="c1">##################################################################</span>
    <span class="c1"># Feed the encoder an input and measure the output to understand</span>
    <span class="c1"># the role of the vision encoder.</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise"</span><span class="p">)</span>
    <span class="c1">#</span>
    <span class="c1">##################################################################</span>
    <span class="c1"># Create an empty tensor (batch size of 1) to feed it to the encoder.</span>
    <span class="c1"># Remember that images should have 3 channels and have size 384x384</span>
    <span class="c1"># Recall that images are fed in pytorch with tensors of shape</span>
    <span class="c1"># batch x channels x height x width</span>
    <span class="n">single_input</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Run the input through the encoder.</span>
    <span class="n">output</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Measure the number of hidden tokens which are the output of the encoder</span>
    <span class="n">hidden_shape</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">'last_hidden_state'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">assert</span> <span class="n">hidden_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">assert</span> <span class="n">hidden_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">577</span>
    <span class="k">assert</span> <span class="n">hidden_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">768</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="k">def</span> <span class="nf">inspect_decoder</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Inspect decoder to verify that it processes inputs in the expected way.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: the TrOCR model</span>
<span class="sd">    """</span>
    <span class="c1"># Create an empty tensor (batch size of 1) to feed it to the encoder.</span>
    <span class="c1"># Remember that images should have 3 channels and have size 384x384</span>
    <span class="c1"># Recall that images are fed in pytorch with tensors of shape</span>
    <span class="c1"># batch x channels x height x width</span>
    <span class="n">single_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">384</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Run the input through the encoder.</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">single_input</span><span class="p">)</span>

    <span class="c1"># Measure the number of hidden tokens which are the output of the encoder</span>
    <span class="n">hidden_shape</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">'last_hidden_state'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">assert</span> <span class="n">hidden_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">assert</span> <span class="n">hidden_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">577</span>
    <span class="k">assert</span> <span class="n">hidden_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">768</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inspect_decoder</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The vision transformer acts much like a conventional encoder transformer in sequence-to-sequence tasks: it maps the input sequence to a hidden representation. This hidden representation is then attended during decoding using cross-attention.</p>
<p>We can locate the cross-attention in the decoder, as its keys and values have dimensionality 768 (same as the encoder) and its queries are of dimension 1024 (like the rest of the decoder).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">decoder</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TrOCRForCausalLM(
  (model): TrOCRDecoderWrapper(
    (decoder): TrOCRDecoder(
      (embed_tokens): Embedding(50265, 1024, padding_idx=1)
      (embed_positions): TrOCRLearnedPositionalEmbedding(514, 1024)
      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0-11): 12 x TrOCRDecoderLayer(
          (self_attn): TrOCRAttention(
            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (activation_fn): GELUActivation()
          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (encoder_attn): TrOCRAttention(
            (k_proj): Linear(in_features=768, out_features=1024, bias=True)
            (v_proj): Linear(in_features=768, out_features=1024, bias=True)
            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (output_projection): Linear(in_features=1024, out_features=50265, bias=False)
)
</pre></div>
</div>
</div>
</div>
<p>TL;DR: there’s nothing magic going on: there are two relatively large-scale transformers which are wired in the conventional encoder-decoder architecture. The transformers themselves are generic and have relatively weak built-in inductive biases. What allows the model to generalize beyond its training data?</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="section-4-the-magic-in-the-data">
<h1>Section 4: The magic in the data<a class="headerlink" href="#section-4-the-magic-in-the-data" title="Permalink to this heading">#</a></h1>
<p>It’s straightforward to write down the encoder-decoder transformer used by TrOCR–it’s conceptually quite similar to the original transformer as outlined in Vaswani et al. (2017). What makes the model tick (and potentially break) is a good training pipeline to ensure good OOD generalization. It’s worth taking a look at the TrOCR paper to see the many different sources of data which are used to train the model:</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://huggingface.co/docs/transformers/en/model_doc/beit">The encoder is pretrained on masked image modelling on ImageNet-22k</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1907.11692">The decoder is pretrained on masked language modelling on 160GB of raw text</a></p></li>
<li><p>The entire model is trained end-to-end on 648M text lines found in 2M PDF pages on the internet, with the fonts randomly swapped</p></li>
<li><p>The model is then fine-tuned end-to-end on the IAM handwriting dataset, with heavy augmentation</p></li>
</ol>
<p>Let’s look at a few of these pieces in turn.</p>
<section id="section-4-1-text-and-video-replacing-hours-of-text-measurement-exercise">
<h2>Section 4.1: text and video replacing hours of text measurement exercise<a class="headerlink" href="#section-4-1-text-and-video-replacing-hours-of-text-measurement-exercise" title="Permalink to this heading">#</a></h2>
<p>In this section, we take a look at …</p>
<section id="submit-your-feedback">
<h3>Submit your feedback<a class="headerlink" href="#submit-your-feedback" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1">#content_review(f"{feedback_prefix}_Calculate_Writing_Time_Exercise")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="section-4-2-generalization-via-augmentation">
<h2>Section 4.2: Generalization via augmentation<a class="headerlink" href="#section-4-2-generalization-via-augmentation" title="Permalink to this heading">#</a></h2>
<p>Another important part of the training recipe for this model is the use of multiple augmentations of the data. When data is not abundant, this can improve generalization. Thus, we take an expressive model with few built-in inductive biases, and through demonstrations, let it learn invariances and equivariances in the data, encouraging generalization.</p>
<p>By applying various transformations to images and displaying the results, you can visually understand how augmentation works and its impact on model performance. Let’s look at parts of the TrOCR recipe.</p>
<p>Let’s start with loading and visualizing our chosen image.</p>
<p><img alt="Picture which shows neuroai_hello_world." src="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D1_Generalization/static/neuroai_hello_world.png?raw=true"/></p>
<p>Now, we will apply a few transformations to this image. You can play around with the input values!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert PIL Image to Tensor</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">IMG</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"neuroai_hello_world.png"</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()(</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># Define each transformation separately</span>
<span class="c1"># RandomAffine: applies rotations, translations, scaling. Here, rotates by up to ±15 degrees,</span>
<span class="n">affine</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomAffine</span><span class="p">(</span><span class="n">degrees</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">translate</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">))</span>

<span class="c1"># ElasticTransform: applies elastic distortions to the image. The 'alpha' parameter controls</span>
<span class="c1"># the intensity of the distortion.</span>
<span class="n">elastic</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ElasticTransform</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">25.0</span><span class="p">)</span>

<span class="c1"># RandomPerspective: applies random perspective transformations with a specified distortion scale.</span>
<span class="n">perspective</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomPerspective</span><span class="p">(</span><span class="n">distortion_scale</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># RandomErasing: randomly erases a rectangle area in the image.</span>
<span class="n">erasing</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomErasing</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.3</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="s1">'random'</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># GaussianBlur: applies gaussian blur with specified kernel size and sigma range.</span>
<span class="n">gaussian_blur</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">sigma</span><span class="o">=</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s now combine them in a single list and display the images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># A list of all transformations for iteration</span>
<span class="n">transformations</span> <span class="o">=</span> <span class="p">[</span><span class="n">affine</span><span class="p">,</span> <span class="n">elastic</span><span class="p">,</span> <span class="n">perspective</span><span class="p">,</span> <span class="n">erasing</span><span class="p">,</span> <span class="n">gaussian_blur</span><span class="p">]</span>

<span class="c1"># Display</span>
<span class="n">display_transformed_images</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">transformations</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/2261e020fe329a69219185878272a3c55e8b266cbe23c56ae4571cf0147ac103.png" src="../../../_images/2261e020fe329a69219185878272a3c55e8b266cbe23c56ae4571cf0147ac103.png"/>
</div>
</div>
<p>The transformations applied to the model include:</p>
<ol class="arabic simple">
<li><p>Original: the baseline image without any modifications.</p></li>
<li><p>RandomAffine: applies random affine transformations to the image, which include translation, scaling, rotation, and shearing. This helps the model become invariant to such transformations in the input data.</p></li>
<li><p>ElasticTransform: introduces random elastic deformations, simulating non-linear transformations that might occur naturally. It is useful for tasks where we expect such distortions, like medical image analysis.</p></li>
<li><p>RandomPerspective: changes the perspective from which the image is viewed, simulating the effect of viewing the object from different angles.</p></li>
<li><p>RandomErasing: randomly removes parts of the image and fills it with some arbitrary pixel values. It can make the model robust against occlusions in the input data.</p></li>
<li><p>GaussianBlur: applies a Gaussian blur to the image, smoothing it. This can help the model be better with out-of-focus images.</p></li>
</ol>
<p>All of these augmentations, which are part of this models’ training recipe, help prevent overfitting and improving the generalization of the model to new, unseen images. We can compose these to create new challenging training images:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Combine all the transformations</span>
<span class="n">all_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">affine</span><span class="p">,</span>
    <span class="n">elastic</span><span class="p">,</span>
    <span class="n">perspective</span><span class="p">,</span>
    <span class="n">erasing</span><span class="p">,</span>
    <span class="n">gaussian_blur</span>
<span class="p">])</span>

<span class="c1"># Apply combined transformation</span>
<span class="n">augmented_image_tensor</span> <span class="o">=</span> <span class="n">all_transforms</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="n">display_original_and_transformed_images</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">augmented_image_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/c0c69d8e7a25f6a91a934e19295cc58e571992ffd7c905cab6f8bb0cfe69844d.png" src="../../../_images/c0c69d8e7a25f6a91a934e19295cc58e571992ffd7c905cab6f8bb0cfe69844d.png"/>
</div>
</div>
<p>Now, all those trasnformations are being applied simultaneously.</p>
<section id="id4">
<h3>Submit your feedback<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1">#content_review(f"{feedback_prefix}_Augmentation_Exercise")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="section-4-3-generalization-via-synthetic-data">
<h2>Section 4.3: Generalization via synthetic data<a class="headerlink" href="#section-4-3-generalization-via-synthetic-data" title="Permalink to this heading">#</a></h2>
<p>When augmentation is not enough, we can further improve generalization by training on synthetic data. This allows us to stretch our data even further. Data augmentation creates variations of existing data without changing its inherent properties, while synthetic data generation creates entirely new data that mimics the characteristics of real data.</p>
<p>As it turns out, generating new text is tractable–text can be rendered in a wide range of cursive fonts to simulate real data. Here, we’ll showcase this idea by defining strings and create a generator to generate a synthetic version of the input data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define strings</span>
<span class="n">strings</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Hello world'</span><span class="p">,</span> <span class="s1">'This is the first tutorial'</span><span class="p">,</span> <span class="s1">'For Neuromatch NeuroAI'</span><span class="p">]</span>

<span class="c1"># Specify font path</span>
<span class="n">font_path</span> <span class="o">=</span> <span class="s2">"DancingScript-VariableFont_wght.ttf"</span>  <span class="c1"># Ensure this path is correct</span>

<span class="c1"># Example usage</span>
<span class="n">strings</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Hello world'</span><span class="p">,</span> <span class="s1">'This is the first tutorial'</span><span class="p">,</span> <span class="s1">'For Neuromatch NeuroAI'</span><span class="p">]</span>
<span class="n">font_path</span> <span class="o">=</span> <span class="s2">"DancingScript-VariableFont_wght.ttf"</span>  <span class="c1"># Ensure this path is correct</span>

<span class="c1"># Create a generator with the specified parameters</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">image_generator</span><span class="p">(</span><span class="n">strings</span><span class="p">,</span> <span class="n">font_path</span><span class="p">,</span> <span class="n">space_width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">skewing_angle</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">generator</span><span class="p">:</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Example </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
  <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/6f4137cd22a59d06529856796937b77fc733880263e8595753c8ac298fdde474.png" src="../../../_images/6f4137cd22a59d06529856796937b77fc733880263e8595753c8ac298fdde474.png"/>
<img alt="../../../_images/09f594e0740693d9a9b2eede7318e36df7682c87f2ec2a7bc2926acea1b723f0.png" src="../../../_images/09f594e0740693d9a9b2eede7318e36df7682c87f2ec2a7bc2926acea1b723f0.png"/>
<img alt="../../../_images/0f2ec41a8bd8845ebff7278160f22aaa98fcc81c94c33ad904a78aa70cf64c20.png" src="../../../_images/0f2ec41a8bd8845ebff7278160f22aaa98fcc81c94c33ad904a78aa70cf64c20.png"/>
</div>
</div>
<section id="id5">
<h3>Discussion point<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<p>What does this type of synthetic data capture that wouldn’t be easy to capture through data augmentation?</p>
<section id="id6">
<h4>Submit your feedback<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h4>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1">#content_review(f"{feedback_prefix}_Discussion_Synthetic_Exercise")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="interactive-demo-4-1-generating-handwriting-style-data">
<h3>Interactive demo 4.1: Generating handwriting style data<a class="headerlink" href="#interactive-demo-4-1-generating-handwriting-style-data" title="Permalink to this heading">#</a></h3>
<p>We can take this idea further and generate handwriting style data. We will use an embedded calligrapher.ai model to generate new snippets of writing data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">IFrame</span><span class="p">(</span><span class="s2">"https://www.calligrapher.ai/"</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">600</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe allowfullscreen="" frameborder="0" height="600" src="https://www.calligrapher.ai/" width="800"></iframe>
</div></div>
</div>
<section id="id7">
<h4>Submit your feedback<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h4>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1">#content_review(f"{feedback_prefix}_Generate_Handwriting_Exercise")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="conclusion">
<h1>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this heading">#</a></h1>
<p>We train models to minimize a loss function. Oftentimes, however, what we care about is something different, like how well the model will generalize when it’s deployed. Our intrepid developer got a rude awakening in comparing the OOD robustness of the model to its empirical loss on the train set: the character error rate was several times larger than expected. Motivated by other factors, like engineering complexity, our developer decided to move forward and deploy a handwriting transcription system, hoping it could be fine-tuned based on user data later.</p>
<p>There’s a lot that goes into the training of robust AI models that generalize well. Generic high-capacity models with weak inductive biases, like transformers, are trained on large-scale data. Pretraining, augmentations and synthetic data can all be part of the recipe for learning good inductive biases that might be hard to express mathematically. Because large-scale models can often require significant compute to train, in practice, models that have been trained for other purposes are adapted and re-used, preventing the need to learn from scratch. These models embody what’s known as <a class="reference external" href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">“the bitter lesson”</a>: general methods that leverage computation are ultimately the most effective, and by a large margin.</p>
</section>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tutorials/W1D1_Generalization/instructor"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</article>
<footer class="bd-footer-article">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W1D1_Intro.html" id="prev-link" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Intro</p>
</div>
</a>
<a class="right-next" href="W1D1_Tutorial2.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Tutorial 2: Generalization in Neuroscience</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="toc-item">
<div class="tocsection onthispage">
<i class="fa-solid fa-list"></i> On this page
</div>
<nav class="page-toc" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 1: Generalization in AI
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-and-import-feedback-gadget">
     Install and import feedback gadget
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
       Install and import feedback gadget
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#import-dependencies">
       Import dependencies
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
       Figure settings
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
       Plotting functions
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-retrieval">
     Data Retrieval
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-motivation-building-a-handwriting-recognition-app-with-ai">
   Section 1: Motivation: building a handwriting recognition app with AI
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-1-trocr">
     Interactive demo 1: TrOCR
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#discussion-point">
       Discussion point
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-measuring-out-of-distribution-generalization-in-trocr">
   Section 2: Measuring out-of-distribution generalization in TrOCR
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-1">
     Think! 1
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-activity-1-measuring-out-of-distribution-generalization">
     Coding activity 1: measuring out-of-distribution generalization
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#run-this-cell-to-visualize-dataset">
       Run this cell to visualize dataset.
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#code-exercise-1-1-calculate-cer-and-wer">
       Code exercise 1.1: calculate CER and WER
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#code-exercise-1-2-calculate-cer-and-wer-across-all-subjects">
       Code exercise 1.2: calculate CER and WER across all subjects
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#code-exercise-1-3-measure-ood-generalization">
       Code exercise 1.3: measure OOD generalization
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#discussion">
     Discussion
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-dissecting-trocr">
   Section 3: Dissecting TrOCR
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-a-recap-of-transformers">
     Section 3.1: A recap of transformers
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-2-the-encoder-and-decoder">
     Section 3.2: The encoder and decoder
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#code-exercise-3-1-understanding-the-inputs-and-outputs-of-the-decoder">
       Code exercise 3.1: Understanding the inputs and outputs of the decoder
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-the-magic-in-the-data">
   Section 4: The magic in the data
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-1-text-and-video-replacing-hours-of-text-measurement-exercise">
     Section 4.1: text and video replacing hours of text measurement exercise
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#submit-your-feedback">
       Submit your feedback
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-2-generalization-via-augmentation">
     Section 4.2: Generalization via augmentation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id4">
       Submit your feedback
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-3-generalization-via-synthetic-data">
     Section 4.3: Generalization via synthetic data
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id5">
       Discussion point
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id6">
         Submit your feedback
        </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-4-1-generating-handwriting-style-data">
       Interactive demo 4.1: Generating handwriting style data
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id7">
         Submit your feedback
        </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<footer class="bd-footer-content">
<div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
<div class="footer-item">
<p class="component-author">
By Neuromatch
</p>
</div>
<div class="footer-item">
</div>
<div class="footer-item">
<p class="last-updated">
Last updated on None.<br/>
</p>
</div>
<div class="footer-item">
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</div>
</div>
</div>
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>
</body>
</html>