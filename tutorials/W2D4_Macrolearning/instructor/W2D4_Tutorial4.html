
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="Docutils 0.18.1: http://docutils.sourceforge.net/" name="generator"/>
<title>Tutorial 4: Biological meta reinforcement learning — NeuroAI (instructor's version)</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css">
<link href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" rel="stylesheet" type="text/css">
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94" rel="preload"/>
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
<script>let toggleHintShow = 'Click to show';</script>
<script>let toggleHintHide = 'Click to hide';</script>
<script>let toggleOpenOnPrint = 'true';</script>
<script src="../../../_static/togglebutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
<script src="../../../_static/design-tabs.js"></script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script type="application/vnd.jupyter.widget-state+json">{"state": {"c4f55475388846c595456629acea6fdb": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b94191f61b034d4aaf9f289c9aa41c87": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_c4f55475388846c595456629acea6fdb", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "If you want to download the slides: https://osf.io/download/8hgj5/\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.IFrame at 0x7f03b0a03ac0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://mfr.ca-1.osf.io/render?url=https://osf.io/8hgj5/?direct%26mode=render%26action=download%26mode=render\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}], "tabbable": null, "tooltip": null}}, "88e89a932c254b50849c34ffde22c488": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "d3dd80f6fd774e58a4792413829a6a18": {"model_name": "ButtonStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ButtonStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "button_color": null, "font_family": null, "font_size": null, "font_style": null, "font_variant": null, "font_weight": null, "text_color": null, "text_decoration": null}}, "2e8cfd05d685421bb8ffb3542cd1fab7": {"model_name": "ButtonModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ButtonModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ButtonView", "button_style": "", "description": "Left", "disabled": false, "icon": "", "layout": "IPY_MODEL_88e89a932c254b50849c34ffde22c488", "style": "IPY_MODEL_d3dd80f6fd774e58a4792413829a6a18", "tabbable": null, "tooltip": null}}, "8d60c42e095040b393cde04fa516cb78": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "bf4aa4cd77784de7b600022b5db6ad16": {"model_name": "ButtonStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ButtonStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "button_color": null, "font_family": null, "font_size": null, "font_style": null, "font_variant": null, "font_weight": null, "text_color": null, "text_decoration": null}}, "16ea6d3d4c2d48a0bfaaa2dfd730e006": {"model_name": "ButtonModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ButtonModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ButtonView", "button_style": "", "description": "Right", "disabled": false, "icon": "", "layout": "IPY_MODEL_8d60c42e095040b393cde04fa516cb78", "style": "IPY_MODEL_bf4aa4cd77784de7b600022b5db6ad16", "tabbable": null, "tooltip": null}}, "79af6b561aca4f58825f999053a72a07": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "d45c80675770473bb4306f338fd42ccc": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_2e8cfd05d685421bb8ffb3542cd1fab7", "IPY_MODEL_16ea6d3d4c2d48a0bfaaa2dfd730e006"], "layout": "IPY_MODEL_79af6b561aca4f58825f999053a72a07", "tabbable": null, "tooltip": null}}, "e17836a576d848b1acf1307b3c48f426": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c85129dd32de4fb3857039ab32fcb846": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "ee84d9dd9b2d4197994461c0657d6a12": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_e17836a576d848b1acf1307b3c48f426", "placeholder": "\u200b", "style": "IPY_MODEL_c85129dd32de4fb3857039ab32fcb846", "tabbable": null, "tooltip": null, "value": "<h3>Start of the game!</h3>"}}, "ba17b1c0237d43da9bc83d808307093a": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "bc415a1deb4745e2b47a374c9ddeb04c": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "0af8c4d74d6842d9b688d941997e7412": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_ba17b1c0237d43da9bc83d808307093a", "placeholder": "\u200b", "style": "IPY_MODEL_bc415a1deb4745e2b47a374c9ddeb04c", "tabbable": null, "tooltip": null, "value": "<h3>Total reward: 0</h3>"}}, "7b70d24f8310487fbd5e1b8039950dd3": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "eabac5dc76eb4b20b31a2622afdfe6ad": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "81662ab920534b0887b6c7999989f299": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_7b70d24f8310487fbd5e1b8039950dd3", "placeholder": "\u200b", "style": "IPY_MODEL_eabac5dc76eb4b20b31a2622afdfe6ad", "tabbable": null, "tooltip": null, "value": "<h4>Objects:</h4>"}}, "09235e36373e414581b51b527f32ecac": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e6c7512041954cbfacc9d12975162371": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "46a183a9177546abb690abab297a6a73": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_09235e36373e414581b51b527f32ecac", "placeholder": "\u200b", "style": "IPY_MODEL_e6c7512041954cbfacc9d12975162371", "tabbable": null, "tooltip": null, "value": "<h4>Choose Left or Right:</h4>"}}, "c2d1b57ea79041b487c7d9f6f85eae60": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "384ee49a9ff64792a0127a2f2f9de237": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_c2d1b57ea79041b487c7d9f6f85eae60", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=Sr56qH1NCjI\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f02c1804f40>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/Sr56qH1NCjI?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDBoYFhsaGRoeHRsfIzIlISIiIDguLSgyMjI9MC0tMzc4U1BCNTpLOTYyRWFFS1NWW15bMkVlbWRYbFBZW1cBERISGRYZLxsbL1c9NzdXV1dXV1dXV1dXV1dXV1dXXVdXV1dXV1dXV1dXV1dXV1dXV1dXXVdXV1dXV1dXV1dXV//AABEIAWgB4AMBIgACEQEDEQH/xAAbAAEAAgMBAQAAAAAAAAAAAAAAAQUDBAYCB//EAEMQAAEEAAMDCQYEBAUEAgMAAAEAAgMRBBIhBTFRBhMUIkFSkZKhFmFxcoGyMjVj0RUjQrEzNGJzwVOi4fAkwkOCg//EABcBAQEBAQAAAAAAAAAAAAAAAAABAgP/xAAjEQEAAgMAAQMFAQAAAAAAAAAAARECEiExMkFRAxMiUmFC/9oADAMBAAIRAxEAPwD5+iIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hOiSd31CDCizdEk7vqE6JJ3fUIMKLN0STu+oToknd9Qgwos3RJO76hT0STu+oQWSIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiArTY2DZLnzVprZr3cSB2qrWfDYt0YIFEFBf/wLdTWG92/XQnhpoO1eW7GBc9uVnUbmsC70sBVjdsygECqIrf2cPcvDtqPJsgE8SSgtTslhflaGnQHrNreaA0viPHWl6/hMdvGhyVubv0s+FFVR2vITZ31V5ju4KBtWQXQq99E6oPW2MKyJwDfrpXZdEcQq5bGLxjpSC7s99/3WugIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgL02RzQ4A0HaH3ryiAr7ZOxYp4GyPL8xJ3HTQkKhXX8nP8AKM+LvuKsM5MXs3Bxk8w/ZPZuDjJ5h+yuVXjbEPSjhesJBxGh0ugfgqzctb2bg4yeYfsns3Bxk8w/ZbA21CcQ+AZi9gJcQNNBZF8Voe2GF7svlH7pxes/s3Bxk8w/ZPZuDjJ5h+y8YnlThopHRuEltNGmj91mj5QwOw78R1wxjspsakmt2vvTh149m4OMnmH7J7NwcZPMP2W9s3aMeKj5yO6uiCKIKy4vEthifI68rBZreiXKs9m4OMnmH7J7NwcZPMP2VhgMazERNlZeV11Y10Nf8KpdyuwwJGWXQ1+Efuh1m9m4OMnmH7J7NwcZPMP2WzitrxRYdmIfmyPrKK16wsafBeodqxPwxxLc3NgEkVrpvFIdans3Bxk8w/ZPZuDjJ5h+y8RcrMK5wB5xgO5zm6ei3BtiHpRwtkSe8aHS6B+CcOtb2bg4yeYfsns3Bxk8w/ZexyhgMc0lPywuDXdUXZNCtVL+UEDTAHZhzwDmkjQAmteCHWP2bg4yeYfsns3Bxk8w/ZbTNrRHESQdYPjbmcSOrWnb9VoHldhc1fzMvfyafv6Jw6y+zcHGTzD9k9m4OMnmH7Ldxm0Y4YOfNuj0Nt1sHcVJ2hH0fn7OTJnrtr4IXLR9m4OMnmH7J7NwcZPMP2XocooCITUn84kM6o7HZddeKwScrcM1xaRLYJB6o7PqnF6y+zcHGTzD9k9m4OMnmH7L0zlHARDQk/nOLW9UbwcuuvErZdtWMYoYWnc4Re7Tde9E61PZuDjJ5h+yezcHGTzD9lu7T2lHhYxJLdE5QGiySvMe1onYU4kZubAJIrXQ0RSFy1fZuDjJ5h+yezcHGTzD9l6fyiw4w7cR1ixzslACwd9EWtvH7QZh4edfmy2BoNdULlpezcHGTzD9k9m4OMnmH7Jg+UuGmkbGC9rnfhztoG9y2sDtWOeSWNgdmiNOsab608E4dans3Bxk8w/ZPZuDjJ5h+yt3vDWlxNACyfgq7Ze3IcU5zY8wLRdOFWPchcsPs3Bxk8w/ZPZuDjJ5h+yjG8p8NDIYzneWmnZG2Bx3kLLNyhw7IGT25zHuyjKNQRqQQapOL1j9m4OMnmH7J7NwcZPMP2TC8pcPKXhokGRjnm2jc0We1e28oYDh3YgZsjXBrhXWBO7S04nXj2bg4yeYfsns3Bxk8w/ZeJ+VWGjIBEmrWu0aNzgHDt4FbeytsxYvPzQd1KvMK33X9k4da/s3Bxk8w/ZPZuDjJ5h+yuUSi5U3s3Bxk8w/ZPZuDjJ5h+yuUSi5U3s3Bxk8w/ZPZuDjJ5h+yuUSi5U3s3Bxk8w/ZPZuDjJ5h+yuUSi5U3s3Bxk8w/ZYzsHDj+qTx/8ACu3blrsH9z/dSeNY9U8+woqHN84TfH/wsbdgX/RJ4hdFGFuwNXDLCcpu5h0iacq3k0T/AES+IWQcl/05fELuYGCrWB+2MM12UzMv08dyz9mf3lqPqRH+Ycd7MN7Wy+IT2dh7ed8f/C7mVrXNsUQdxHaquZq19uY/1K/dj9Yc4OT2H7TL4/8Ahehyewvel8f/AArhwXnLatT8pvHxDn9r7Gw8OGfJG55c0tHWOmpA4Lnl2PKePLg3D3j7mrjlvFnIXX8nP8oz4u+4rkF1/Jz/ACjPi77itw55eFouI2jg5J9qTiI1IwB7Na1Ab29i7decgu6F8a1VZiacTs3Bugxz2PNv5hznH3lllaeycZzcRHTXQda8giLuGt/+7l9CyNu8ovjWq8dHj7jPKFKXZzfLcgwwEdrib+i8cq5i+XD4aNhef8RzG73cB4B3iuqdG072g1xFpkbeahfGtVUtx2wp5Y58Th2s5h8oL4mP3NO8Ddw93YrDGR4xuExPSpI3N5vqhg7b+AXQlgu6F8a1UuAIoixwKUW5fk1tuCPDw4dznc4XEVlNW5xrX6qlwGK5t0w6W7D2/cIy7Nv19y78QMGoY2/lCjo7O4zyhSltyO2sYcRNhY42uxAYwSOaBWewDqOzQf8AcsOzpzHDj8M9pjOQvaw7xxHhl8F2zY2g2GtB4gIYmk2WtJ40lFvnRZJ0fC88/wD+K55rK0WzWnf8lb20sG6baU4hNPYxr2V25Wtql2/NNqsra4UKUiNoNhoB41qlGz5/hXl2z8aTvL4yfMsuMwvP/wAPius8IF8NSu65ptEZW0d+g1Tm26dVum7Td8Eo2cJsqKZ8+LjeCZujvZR3kjK0D37ljZtEMwLYWuyytkJdG6IODrqjroK8V9ADBd0L41qo5lmbNlbm40L8Uo2U+Kgc7ZLmvbTxDZFAUR1tw3blxmWbmOfvqf4H0q6+C+mleeabWXK3LwoUrSRLi8bFk/hbfcD4uB/5W9yoaOmYLQfj/wDsF0xjaatoNbrG74KXMaSCQCRusbkotyvK6MuxOEa05CTQI7CXCisOBw0kW12MllMr8p65+Q6arsHMaSCQCRuJG5MgvNQvjWvihbkuUs7pcbFCyMzCEZnRt/qJ1IP0rxWpgJ3MwuOwz2lhDc7Wu3jUAj7V3AYLuhZ7a1UGJpJJa0k7zSUW+a4nCyRYaJ1kxTdb3BzbFeH/ALouu5Wfl/1YrwxNqsra4VopcwEUQCOBCUtuGwzH9LwQxUlx5GOiIAqt7Wn60Fm2RtSLC4vGGYkBzyBQvc4rsjG01bWmt2m74KDAw6ljb+UKUWo+Ue1G9AzRn/H6reNdvpp9VRYGR+ExWGe+B0LaEby7+vi71B+i7oxNNAtbQ3abvgpewO/EAfiLVS3CwYkYZ+OjkcYpHnqkszXTiSKPYQVixhkOzY3SNDc05LaYG2MtXQA7bXfPia7VzWuI3WAVL2Ndo4Aj3i1KXZyWFxwfHiGnGunvDyUwxFv9O+1QuwsjMIJWkmKU5XjgWmxf/vFfSRCwbmNHwaFPNNrLlbl4Vp4JRs5fbgH8Iw57csf2roNlgdGhr/pt+0LZMbSKLQRwI0UgUqlpRERBERAREQEREHl+5eo8PcQI36/XUry/ctzBj+U36/3Kzk1i0AtqB6jEQ2bG9Y4lh0Y+UGMcImQsOUyk2fcNT/wqCLDRBpLnZiN6vtrRZmxnuuOvxFV/7wVHI4RuLWMzkjrWfBSZdcMV7yfxZyPYCTGNWg9nEfBbUz9VU7KniYC6wxp35jWq2otoQzPLI3hzgL3H04q3bnlFSyFyz4Vt6+CwZLNLew7aCIp+V4/+IfiPuauIXccsv8ofiPuauHC1ALr+Tn+UZ8XfcVyC6/k5/lGfF33FahjLwtEUIqwlERAREQEREBEUIJRQiCURQglFCIJRQiCUUIglFCIJRQiCUUIglFCIJRQiCUUIglFCIJRQiCUUIglFCIJRQiCUUIglFCIIfuW5gv8ACb9f7labty2sG7+UPr/crOTWL29eGR6r0Sq7F7YETsoGYrNW6LTEYfNE9rQC4tOW911p6rjpnva4tLCSDrX7qyxG2ZJGV+EHsHBVBgBN0T8Hn/gpOFmP1KYdpOlIjqJzwSRlaCTfZu+q2+T+y8V0qOV8XNsFg5tCbBFVvUQsymw2viSf7rPPjJCL5yQEbi2Qj+2isY1DM53LpywWvbHgODb1O4LkNm4/ENxDWPmdJFJoC78TDVizwKvC5xOpOh0KzPGo6x8s/wDKfUfc1cOF1HKBxOFdd3Y0JuusFy4WoQX0XkXC12zoyWtJzP1I/wBZXzpfSORH5dF8z/vcqLro0fcb5QnRo+43yhZVzm2sfNhsURF15J4g2Fjicudr6Jr5X2flQX3Ro+43yhOjR9xvlC5iHbz3Z54ySJ5mRR2x7wwNizuORupN5hQrdruVtBjJJcFM6RpY9oeLyOZmoaOAd1m3wO5BY9Gj7jfKE6NH3G+ULm8Ftyd2BE0Yj0MULWyEl+Yuaxzn0erd2Bqdx7aWzJtfERulheInTNfE1jwCGfzSQCW2TplOl66bkF30aPuN8oTo0fcb5QqU7blheW4jm8scoZLI0ECnR52OAJNa00izvXrZG25cQ+KN8bWSU90ze4BlyD4kPafoUFx0aPuN8oTo0fcb5Quaxk00OIx2JJif0eMc20tdpYJAHWoe/TX3KwkxeL53mGmASNjMr3FjspBcQ1oF32G3Xw0QWvRo+43yhOjR9xvlC56Tb+IfG+aJsQZHho8Q5rwS45g4loIIA0bvr6Ky2djZjPJDPzZIjZK0xggU4uGU2TZBbv7b3BBv9Gj7jfKE6NH3G+UKm/jE2bnaj5jpPR8lHP8Aj5vPmuvxf01u7Vki2xI6LCvysubEOidv0A5zUe/qD1QWvRo+43yhOjR9xvlC0NjYueeDnpebAeLY1gNiiRqSdb07NPeqaPbU0WCgcxzXlmFbK8OjfI52l9ZwoMBo9Yk3rpog6jo0fcb5QnRo+43yhVEm1pm4lrXBkcLi0ML43kPzAa84Oq02aDSNa36r1ybM5bPz0jHgTyAU0ggh5B3k9XgOz3oLXo0fcb5QnRo+43yhUX8ZkkjEZY3nWsl6QNQG82C3TWxmcWka7rWvjNoYh+ExAhMcbIcKC68xcS6Mu6pvq0O03ZQdL0aPuN8oTo0fcb5QufdtyYSOZGwvbEWNc0QyOL7a1zjnb1WUHbjd12Ws/wDF583O1HzHSej5KOf8fN5811+L+mt3aguejR9xvlCdGj7jfKFVY4z/AMSwzWSMEZikJaWk3TmZtxAuiKNaa77WnsnH4iOPCmQsdFNK+Mb84NvcHFxNEdWqrhqg6Ho0fcb5QnRo+43yhUEO2p5JBGDGRKyR0bxE8NaW1XWcRzgIO8UtjZE2IGymSWySXmA5lg69QEB1kkn36ILfo0fcb5QnRo+43yhc+7lO5zniJjSHhgwzjfXcS0PvXc3nG8Nzlkw23JpJwGxkxc86IgQyW0NJbn5z8B1H4ewHfogvOjR9xvlCdGj7jfKFVbX2vLBI+NjGve5jThx3nF2V4PuFtPwtaw2x0h0T2NBh5+NrDZBsxl7jodasCj2goL7o0fcb5QnRo+43yhc/sGZ7psPme4gwSk24myJgAfBbc+2JGxYt+VlwTNjbd6ghh19/XPogtejR9xvlCdGj7jfKFU/xaZuKLJQ2OPM4MaY3W8BpIc2T8BJr8FArHsTbU2IfHnj/AJcsecEQyNEZ0IaXu6r7B3it3vQXXRo+43yhOjR9xvlCpsbteeN+McGxmHCtBIo53kszAXdDWtaOi1ZtqzOieJWZgHQlr+alhHWla0tpxs1vsGj2hB0fRo+43yhOjR9xvlCoztfEgvlIh5lmJ5gtp2cgvDA67oEEjSta7Fp4aaeObEyExPlfiRh2EscA22tPePVA/pHb26oOo6NH3G+UJ0aPuN8oVG/a+JDhABDzwxAhLy12QgxGUOAuwd2ln10zxY3FPkeW8xzcUoieHAhzjTczg66b+LQEG636oLXo0fcb5QnRo+43yhUWC27NLK2o7ie97KEEgyBuYBxkPUdZbqBVX20V4we1MbL0Yf8AxgcTEZWnI7qZctgjN1rzDhWu9B0HRo+43yhOjR9xvlC513KOZ4jEbAHmASuHMySgkktyDJ+EW09Y8RosuI2xiqnkYyJjIImSuZI12c20ucywRlIrfR+CC96NH3G+UJ0aPuN8oVPs6Wd+0MQS9vNc1E7JlNgOz1WtA6amtdN1LXxG1HwTYoNsl+JjjZbXPDLha8kMbqdx0HaUF/0aPuN8oWF+z4z/AEN8oVV/GZzGwU1kpkc0ZsPIS9rQDnbFo4DUA2QBxOi9YDa+IxD4GsbEwPi5yQuBJ0flIbqN/v3e9Bvu2VEd8bD8WheP4HhrvmIr+QLRwG18S8YWSUQ83iXFgawODmkNc4GyaN5TpQq9619m7TxMkcTIBCwDCsmPOZ3akuGW8111d5J+qti2OxMP/wBCLyBSdi4c74Yz/wDoFXjbc8zS+BsTWswzJ3CQElxeHENBBFAZTrrv3K7wMxkgikNAvY1xrdqLSxpjYmH/AOjF5Ap/g0H/AEY/IFZIpaVCtGx4Buhj8gXv+Fxf9NnlC30QqHMcsMIyPZ0ha1oOZm4f6wvn6+kct/y6T5mfeF83RRfSORH5dF8z/vcvm6+kciPy6L5n/e5BfrBLhI3yRyOaC+O8h7uYUfRZ1TY3HlmJlc57xDhoBK5rAOuXFw1+AbxGpQbh2TAYua5umZy8USCHE2XAjUGydyyQYGKOIxMbTDdiySc28knUk8Vou27UQkMEpzPaxrWljsxduIIdXx1Q7eaGkOie2USCLmiW3mLc4N3lrLrd9nFBsnZGHJvmxdMGhIvIQWXxogUSvc+zYZOcL2AmQNDzZ1yklvwIJOoWmzbzXhgjhkfK5z282C225KzEm8tat3HXMFr47bb2xzSRslzNwxlET2NblIJBJs3pWo7QNLQWH8Hw/MuhMYdG85nhxLi4itSSbJ0G89i2I8JG2V8rWASPADncQ3cqTZ+13RscJhiJZszGhjuasueLAbkoAUCdTpS337XIjzHDytcHljmuytDaF3mJykcCD/yg2ZtnxSCUPYCJgBJqesBoF5xuzIcQQZWEkAgEOLTR3tJaRYPA6Kmxu33mN8sBpvRTK0OaCQ4Py6+qs5NsMbzgyuzsmbDk0sl1FpHuo38AeCDO7ZsJEjebFSRiJwFgFgsBum78R3cVlbhmCQyBvXLQwn/SCSB4kqv27jZoxHHhg0zvzOAduysFu8Tlb/8AsvOKxskkMc8U0cGGMfOPlc3MdQMoo6Deb7exBtfwjD89z3N9fNm/EcuaqzZby5q7ateW7Fw4l50R9cOzjrOoOO8ht0CbN0NVXYTH4rEuhjtuHf0ds0pyWbcSA0A7h1STeuoWcS4mObCmZwuVzonsb+A01zmyN7QTl1F9vuQWuHw7IoxGxuVgFALSk2BhXNa0xdVrBHQe4AtG4OAPWrsu6Wpj9oysxoYRIzDxxmV7m5KcARZN2co1GgBtZDyha1jnyQSx1CZmh2W3tbV1RNHUaHig2nbHw5kEhZ1rBrM7KS38Li28pIoakXoFngwUcb3yMbldIbdRNE8a3A+9aG09pyswE07IXskawlrXFtjTRxokV21drC/bE7cSGdHkcDBzhjBZbTmIJJutQBQBKCzGz4Q+V4jGaYASHvAChf0WDEbDw0lZ47pgZQc4AtG4OAPWrsu1rS8o4g1rmMfIDEJjRaMrDdfiIs6HQcPgtvF40AYdzXHLLI0AgA2CCdb3DTeNUCXY+He8PdHZFWMxp2X8OZt06uywVP8ACMPz3Pc3182b8Ry5qrNlvLmrtq1q4Tb7ZHR3BKxkr3MZI7LRc29KBJF5TRrsUYHlA2XmSYZYmTA829+WiWguI0JI0BIvggscTgo5XMc9tujNscCQRx1HZoNNxXkbPhDY25BljdnYLOjjev8A3HxVa3lPFkLzG8N5p0zDbTna0WdAbaaINGt/xWbHbSkGAnxDY3QvbG5zBJlJ0FgkAkfRBnw2xsPE8PZHTmghtucQ0He1oJoD3DRZ8Hgo4G5Im5W3eWyQPhe4e4aLQl2/GyUsLHFrXtjfJbaDnVQq8xFkAkDt9xXs7aaMQIXRvaXOc1jiW6loJ/DeYAgGiR/cIM8eycOwRBsTQInF0f8ApLrs+pUDZMAm57J182b8Ry5joXZby5vfVrSi5RZ44ZBhZ/57gIh1Ld1S6/xaCh2r0NtBxhNSRnPIx8Za0m2MLiCb91gjfYQWUuEjfJHI5gL47LD3bFH0WOPZkDGta2MBrZDI0C9HGyT6laOG5QscGukhlhY+IzMe/LRa0Au/CSQaN69iy4LbPOysidh5YjJGZGF+Wi0V3SaPWGiDagwEUZa5jAC1paNToHHMR46rDiNi4aWQyPjtzqLus4AkbiQDRIoa71qnbBZNiGOaXkTMihY0CyXRteRZod42ewL2NutIDWwyGYyGPmurYLRmJJvLWUg3faEGy3ZMAl50M6+YuHWOUOO9wbeUO1OtXqpwmyYIX542UaIHWJDQdSGgmmj3ClqDb4cYmxwSvkkz9QZQWGMhrw4k0NT2Wt/AYxuIibKwEB16O3gg04H3gghBJwcRMtsB57SS9Q7TLqPhotePYuHa1zRGSHFtlz3OPUOZoskkAHUDcrBEGqdnwljmZBldJzhFnV2YOvxAKiTZsLmyNdGCJH536nV2lOveDoN3BbaINKHZUEYblZ+B/OAlxJzEFpcSTbjRrW1EmyYHS866O32HHrGiRucW3lJFDUi9FvIg0WbIgbLzoZ1rLh1jlBd+JwbeUE2bIF6rLDgImc1lZXMsLI9T1WmrH/aPBbKIK6XYeGc1jTHQY3KMr3N6p1LSQes33Gws52fCRI3mxUrQx47C0DKB7tDWi2kQaowEQlbKG09rcoIJGg3Ajcas715n2ZDJzmZn+I4PcQSDmaAGuBGoIAGoW4iCvOxMPla3IRlJIIe4Ot34rcDmN0Ls60s2F2dDDl5tgblbkbROjbzV4raRBqs2dC1sTQwBsJzRiz1TRH9ifFRh9mwxVzbA2oxHvP4RZA9T4rbRBQbR5Pc5TYhEGCIRAODraBdbiM41/C7tHxV1hoRHGyMahjQ0X7hSyogIiICIiCg5b/l0nzM+8L5uvpHLf8uk+Zn3hfN0BfSORH5dF8z/AL3L5uvpHIj8ui+Z/wB7kF+qvE4KXpTpIzTZYhG9wIDmFpcWuAIIP4iKPuVoiDncRyfeBcbzzj5o3ucxrWBoZfWDdxOut3a2X7ADgS+UumMol5wsbVhuQNy7suXSt+t3auUQVI2KQI3Mmc2WPNTwxtEPrM3KBVaNrt0R+xA5sjXSyOMkBgc51E6kku+PW3blbLDipxFE+QgkMaXUPcLQaE2xGuLnCRzX5mOa4AdUsblGh32Cb+K8S7DLyx7sQ90rHOdme1rh1gBQadG0AKr377Kx7B2+cW97HRhhaMwINit1LZ2xtR2GyBmHkmc6z1dGtDRZLnHRq1nhOE1KY5RlFw1hyaZzPNc6+uZdDdC6c7NfxWV2zM20hiC2msiABv8AE+3C6/0tJF/6/cq+TlgOYZOzCTOjLOce401rRmy1Z0cb7Aujw8wkjY8AgPaHAEUdReqyrSxOx4ZpzLMOc6gY1p3Nokkj3mx4Bab+TfViYyd7Y4nueyPK1zQSSRod+W9L3K9RBVybKeXslbiHNmDObc/I0h7bsW2q0J0riVjj2W9suHbZdFCXSGR7re97g5u6tB1ifAAK3UoNLEbNZLI57ySHwmFzewtcbK0n8n87HNlnfJcJgYS0DK11WdN7jQ19yukQa+MwjZoZIXXlkYWEjfRFaLBhtnFknOvldI/muaJLQLAcXA6dutLfRBRDk0xrYwyUtLImxEljXWG7iMwNO1Ovv3KyxGBbIIRZHNPDx76BFHxW0iCuj2O1seHZndUEhkB01JzaHzeiiHYzGx4WPM4jD3V/1WxzNfo5WaIKOPk21sT4edOQxOibUbAQCKskC3EDT+9qyx2CE2HkgJIa9hYSN4sUtpEFQdhNE7pGyFoe8SObzbSbAAIDiLANCx4UscPJ1rJWPErsrJHSBuRtkvDgczqt1ZjX/Ku0QVsGyGsZhGB7iML+H/V1CzX6FeDsRhfnzu/xXyVQ3vZzZH0GqtEQVcuxmmKJll4hhdEGk1nDmBup7N3ZxWhsbB4g4mKSUTBsULo6l5veS3RuTfo3UmuzTeukUIKyfYrXvfIJHNkdK2VrgB1XNZze7tBbfisbdh1T2zPE4kdIZKGpc3KQW7suUAV7grhQgoP4JIyfDmGVzQxkxfKQ0lz5HNcbb7+sdN1BWWz9ndHDWtleWBptrgOs5zsxeTvuydN2q3kQEREBERAUKVCCUREBERAREQEREBERAREQEREBERBQct/y6T5mfeF83X0jlv8Al0nzM+8L5ugL6RyI/Lovmf8Ae5fN19I5Efl0XzP+9yC/REQEREBQ4WCDqFgxOOiiIEjw0nUDea7Tp2LLHIHtDmkFpFgjcQrU+UtWbBwzGCfIxrf5z26DsB0HwCzbdwDsVhZIWloL61ddUCCbog9ijY+6f/fk+5WK19TuSY+FVtTY4nZh4wGCOKRriwg0Wt7AAR62FaKUWGhERBClQpQEUIglERAREQEREBERAUKVCApUIglERAREQEREBERAREQERQglERAREQEREBERAREQEREBERAREQUHLf8ALpPmZ94XzdfSOW/5dJ8zPvC+boC+kciPy6L5n/e5fN19I5Efl0XzP+9yC/REQEREFTtFzmzgxOdnLKc1sWfS9CbIrW1sbJYWwt/mZ20MpyZTXv8AetfaTXOmDYtJAyy7nSy23oNxvW/h9VubNLTBGWDK3KKBN19e34rpl6WI8sGx90/+/J9ysVXbH3T/AO/J9ysVM/UuPhCwvxcbXZS4A/vuvgsyq8RdyAOcIyeuebsDQXrd/FcsppZmm7jcTzUbn1ddnx0WgdpukwmIeBkeyNxBHHKSCrLm7ZlfTr36aH6LW2dCw4ZrS0EOb1hW+9DfFTu0J21ZhsZLG2Mc3OHzOaxpxD2ubq1ziRkJO5u7TeFnwG1pp5WsDIwAH84bJ1ZIYzl+NXqrSbCxyM5t7GuZp1SLGm5IcLHHWSNrcrcoytAob6HuW2lZJtl4xL42x2yORsbjRvrNDi7N+EAZhodTRWszlDJR6jDmawxkZg3+ZIIxZcLLdQc1C1dPwMLpRKYmGQbnlovTdr9T4rGzZOGaHBsEQDxlcAwajgfd7kFbLjMUcTDG10ObLMHAOJYcvNlpI3g9bd2Xeq9YjaEsuFwk0WWMyvjJBs/i/p03hWkGCijy5I2Ny3lpoFZqLvEgX8EfgoXRcy6JhioDIWjLQ3abkFW/bbxPkDGvaXPY2rHWYwuPWOh1aQa3cd60sbygljbE5wpzZg2RgDmaOieRnzDRoIvMLFNJ7KV8Nl4fPn5iLPr1sgvUUfEaKYNmwRgBkMbaOYU0DWst+UkfBBp7Vmm5qBsb2NllkY0kXXfdXupp+iscO95BzhoIJHVdYIB0Puvh2LG7AQmNsZiYY2EFrcoppG6h2LLFC1gIY0NBJcaFWSbJ+JKDIiIgIihAUqEQSiIgIiICIiAiIgIiIChSiAiIgIiICIiAiIgIiICIiAiIgIiIKDlv+XSfMz7wvm6+kct/y6T5mfeF83QF9I5Efl0XzP8Avcvm6+kciPy6L5n/AHuQX6IiAoUqEFbjNmvmd13wuaD1Q+AOr62t+FhaxrSQSBWgofQdi08bjHxStADXMe2gC9rTmvsvfotyCTOxrqqxdA36jetTM1FsxVtLY+6f/fk+5WKrtj7p/wDfk+5WKufqMfCFWYj8UjsvUa7rjnCL0H9P/tqzO5aXRC52Yujc4HfzWun1XHLpk3VrbM/wI/lWyVrbM/wI/lV91920iItKKs2097ejlmaxI4mr7IpCLrsuvrSs1r4rGNiMYdf8x2UHhTXPs+6mlBTsnxBkjjec180/PzdZS9smYDs0LRv46rVweLljghtzy/mWNc9zdWuzU4OvQVxIP1V4NrQuALHteCQCQRpYLgfeKB3b1jwu24ZI2SXlY9geMxF6mg2t92a0QVGHxkz5GSSBwBbHm6rqFGe3AcaDezhpuUt2riDE1wfo9ztSzVgA6jXab3and7t+quP4vGZAxuoIa7NYoh+eq4nqHRe/4th8pdzraByn3Gs1eGvwQYppJP8A4z3Et74aLFlu7XXfpqtZm0Ji13WoAtOYtreHWN1A2Bv+F2rPEY6KIAySNaCLBJ7BvPwHHcvDtpQCQxmVgeLsE8BmPgNSszCU08NiZTK7QhrqLcwIt3Nt6p35OPbr8Ncs+KlbJGDQBq2t6291byBYrhqPesp2vhw3MZm1db9bAzEVv3EH4aqYNpRSTPiabLWtfY3EOuqP/u9K/pSvj2hMYw4OzW1pcclZLcAfSz9L3LNHjJSWhzsu7LUZOfrEH/tA3cb3LbhxuHDWhkjMtMoA9j9GfQ9i8t2pC7Lke1wc6rzAV1S+9d4oHd8VNZ+UqVeA/PG+iaDaaW6C5CDXA12rdwE75Gm327KCRzdZHG7Hvrhv8V5ftzDjKRIHAvDCR/SS0ubfbrl042F6btmAvLQ8UIxJn/pLTfb9PVWMaIhrR4/EO/8Ax72lwGXutIc0/F9V7io6XMW5hTyMxacp35Ca0ob/ANt6sunRc3zucZLq/feWvjelb7WN2Ow76YZGOEg0G+wbGvxII14FTWfkqflpMmkklDWykhr6zZK0Md6jdvUNxEury/K50UZALTluzmrQ1/5F6BWeEZGGB0VFrusHA3m00N9uizJrJTBgpS+Jrjd67xW41a2FClbaEREBERAUKVCCUREBERAREQEREBERAREQEREBERBQct/y6T5mfeF83X0jlv8Al0nzM+8L5ugL6RyI/Lovmf8Ae5fN19I5Efl0XzP+9yC/REQFClQgodp4qEz9XExRvZWbOLHVdYG8EG944UrTZgHR48t1lFWKPh2LBtF4a8Hn3ROLf6Yw6xfwPgtnZ73ugjMl5y0ZrFG/h2fBdMvTDEepr7H3T/78n3KxVdsfdP8A78n3KxUz9S4+EKslfUkhGcDeafWoyg6VwP1pWaq5Sx0zi50LHNcAMzbcdAbuwuOfgyWhWtsz/Aj+VbJWtsz/AAI/lV91920iItKLU2hgROGW4tyOLtBvtjmf/a/ottQgrhsgCVkmc2xsbarfzYeB484fBYG7DLY2ME5/lsDGnLva02A6iL99EX6K4RBT4fYAjLSJTmblo5RvaZCDX/8AQ+C8jYLsjGmYF7C458h62f8AGXdbUk636VortQgqtpbF5+JkQlLGNjMZbVgggC6FCxWm8anRaU+xZJZebdYw+aRxNjXnI3MNHfduJoihxOi6NEFZhNkc29r3PzOBJNNq7aG9pJ7OK9bN2X0ctyyFzRCyIgt35LAdfZvNhaxlkZiJcvOG5QcmS2ubzbbIdW+xx3/FYm4vEFjus8U5upYbILTYByUNQP6fda6aSxuyRcm42vDs7jq+xxDhlY34MG74rweTg5ui/OQK3Zcw5t8YBOp/rJvdwAWfDYnEOxADgWs7rmn8OS70bQOb/V7qXmfEYoSOa0HKHZA7L39Wu+DBofippK7MeA2ZM6XnZyWlrmFooWcrHt1okV1739nZuWcbFoOAk0cxzXBzA4EF7njT3FxHvHBYOexDjIHCxf4SwmqkAbXVA/DZ3njosb8TNJbM7yXNLi3m6DSJGgZTXWABPaVftym7fGzHdH5rnnZs+bNrW+8tXeXsrN9Vgg2DzZiyzEZDZIZTj1y/LYP4TmIIN6bqOqHnRM3M+QtY9zQ7IOsC1rhdDddixW7itnZM0jmu5wuJBHWLaB07NGn6EacSszjUWsZNyFhaxrXHMQKJAq/p2L2q+N+J6W8OazmcjaOY8X3Wm+sti+CwyukjfNTpLdICOroBlGt5T2itx/5WJmlmaWylUoxE7gzNn60erQwijlNk2Ph2iuC2dnvmMbQ4DMKDg6wAKFZTRzfXt4blIytLWClUrsXMM4Ln/jaMwj3AuogAt3183FOk4i2VddhLD1uuR1gGmurXd338JvBsuUVTzsrhqXl2duZpi0b/ADANDWumvbx0WCBkkRcRnGZ3XfzYLgM7heg10y77q02Nl6i0JppWwMezM916gsouBsCx2akH6Far8RiQ3WxTshcG78o/ENHaOPu7FdltcqVTGaVpOYllm3OZHZJEbewi6u9a7K0UYN0xHOZndd0djKKOZjQ527sPDTRTZNl0oVLBJKxkIBkNaObk1uwK/DRH1HGyrpaibWJtKIiqiIiAiLxLeV2X8VGvj2IPaLT2XLK+BpnaGyiw8N3WDVi+O9biAiIgIiIKDlv+XSfMz7wvm6+kct/y6T5mfeF83QF9I5Efl0XzP+9y+br6RyI/Lovmf97kF+oUqEEoiIKvacT3SAlk0keXRsUmQh17zq29K7dFuYJr2wsEht4aM2t+vas6LU5XFJXbV+x90/8AvyfcrFV2x90/+/J9ysVc/UmPhCr3vPOPDnStp1ANjsVQ7aKsHCwRxWA4NhN9bzu/dcsomfCzDJNK1jS5xoDeVrbJla6BoBstFH3LPi8OJYyx1gHtCxbPwDYGkAlxO8lSb2/idttoiLbQtXF4vm3wNy3zsmS73dRz79/4a+q2lr4zCNmDQS5pa7MxzTRaaIsfQkfVBpHbkbc2drxlMl5Wl1NjdlLjW5TJtpglaxrXuaS8F4aSOo0lwbQ6xsVQ99XSxv2AwkDnJAzI9rwHdZ/OODn2ffrurfpSyS7ChfmsvyHP1A6mgvBDyO3Wygj+OML42sY52aQxv0/AQ3Pr9K+iz4TasUwdzZcS1ofVVbTeUj40Vji2LE2qc/NznOZrGpy5CKAqi3SqWXZ+zI8MC2PNVBoBO4DcBX9zZ96CItpNLInOa5vOAdmgvQa/EqH7UYG5heXMGlxFDWxY47t29P4VH1es+mgAajc020buz17bUnZcZLi63ZiLv3XQ9+/edVj8mesrsdGGklwFNzFp/EB7xvCxv2kxtWHjQuPVOgBok+5Z+jjJlt26s19bxWn/AAlt1mcGFpDgDWazZvsr4UrNk2zHaUQLhZ0vWt9GiBxNmljxG0srSQwkhrjlIINggeGu9e/4ZHbvxU69AdxJux279V6OAaQcznuJBaSTrqQT8Nw3KfkdeItotoZgS7W8rD1adl14a/2U54IZCA1rHuIGjd+a69QV6Oz2XYc9pJN5XVduzEH6k7lOJwEcrszrvIWWDWh7fiOw+9X8qOvDdpROIAJ1qjWmosD6j+4UR7TY7Lvt1Cw05bLc1X8F7Gzow8OFjQaDdoKHv3f2Ws3ZZbI2nVE0g1Zs0zJqOPvv6dqn5HXpu1wY2uyOzHIS2jueasce3/0rahxbXuc1ubq2DppY3j4rwdnsygdYU1rQQdRlNtPxteo8G1shktxdRGvv1P8Abt3disbHWjDt+Mx53skaeucoaSQ2N1Odp2bvqa1W3iNoxRvYxxNuaXggWA1tZnE9gFha79hxEEZ5Wg5xo/8ApkNvZ8CRfEdhC2pMBG5wcRdRuirsyuqx/wBoWmmsNswPA0e52YUzIS7cXB1cKBN+6t+iYPbMckLJHW0u5uxRNGWg0eJCM2LG1rQ18gc11tcCARoW1uqqJ3i+3fqobsKIZAHSBrMnVzaO5s2wn36fVB6G24S3N16NZDkNPskDKdx3H6a7l7ftRnNwyN1ZI/LZ0y6OJJ+GWqWP+BxZMmaTK2ubBcCI63BoIrtrUHTRbB2dGY44zZaw2LO/Qg34lBr/AMdgofjBcW5WlhDjmBLSAewhrvCt6zwbSjkldG3PmbWa2EAEtDqN7jRG/wCG9a42HHlLc8hJDW5iQTlbeVlEUQMx3g77WSDZEUckbwXnm25WAuuhly79507CavWrQYsVtPDODhI0uazObMZIJZo8N4kbq+O+is7Nox81K8BwENh7S2iKaHbvgQVjdsSIl1l+V2am5uq0vNvI95PG6s1VrPLs6N7Z2uusR/ia/wCkM04aBBii2o3JhzK10b56AZV06rI9DqsGH5S4aV0TWF7jKA5tRuNAktBPAWCtjG7KZOyJr3SZonBzXtdlddVdjiCtNvJfDAQj+YWwkFjS/SwS4H3ansq+1Bhw/K3D82wykhxGZxYx7mtbnLASa0FjtW7Fygw78QMO0vLy9zAchylzBbgHbjSwDkthhG6Pr5Xx82et2ZzJ45iVrYbk29mPbiC9ojZJJI1rc2peKqiSBxJG/gEG0zb4OPdhebOQW0SX+KRrQ8sr5Tx7Fov5WPjGI53DU6FjXZWyh2r3ZWseaprtx7dFvDkvhQ8SBrhKJDJzod1ySSTZ4a7l4g5KYZkckWaZ0co6zHSEi7BzfNYGqDf2diZ35xPBzTmkUQ/M1wI3g6HT3hby0dnbMZh85a6R75CC98jy5xrQangt5BClQiCUREBERBQct/y6T5mfeF83X0jlv+XSfMz7wvm6AvpHIj8ui+Z/3uXzdfSORH5dF8z/AL3IL9EUIJREQFixM7Y43yO/CxpcfgNVlXl7A4FrgCCKIPagoeTO1WTOmYGlri90ovg4/wBwp5Xwjoxmc+TLF/8AjbKI2vLqa3M7TQE3vVlgNlQYYuMTMpdvNk/TXsW1LE17cr2hzTvDhYXT6k4zlePhnCJiOuK2psiaPC4VsmIlkxDssLLnysY5xvP2FxA07bXZ4eMsjY1zi9zWgFx3uIGp+q9Pia6szQcptti6PEcCva5tIUqFKAiKEEqFKhBKIiCEUqEBSiIIREQSoUogKERBKIiCEREBSoRAUqFKAihEBSoUoIUqFKCFKhSghSoUoIUqEQFKhSghSoUoCIiAiIgoOW/5dJ8zPvC+br6Ry3/LpPmZ94XzdAX0jkR+XRfM/wC9y+br6RyI/Lovmf8Ae5BfqFKICIiAiIghERAUoiCFKIgIiIChSoQSoUqEEqFKhAUqFKCEREEqFKIIREQSiIghERARFKCFKhSghERAUqFKCFKhSghSoUoIUqFKCEUoghSiIIREQSiIgIiIKDlv+XSfMz7wvm6+kct/y6T5mfeF83QF9I5Efl0XzP8Avcvm6+kciPy6L5n/AHuQX6hSoQSiIgIiIIREQFKhSghSoUoC4/GbSnIxEjJMQ3+fzcJDW80KIjBcSCaz3a69VUOwImhrS+VzGOzhjn9XNeayBv1117UB+2ailkEd5ZxAwZvxkuawndp1ieP4V52TicRLiMUXtYIWvyMp5JBaBdChvs2b3ivesjdhRB4dmkLWymVsZf1A8kkmviSdfotrB4FsJkLC6pHF5aTYBJJcRwslBWjlG3PGxzKuSRkhzaRhhe0OPzFhofHgtc7WxMs8RhiAaIHSvY+TKKc6oy45SbytcarS9+i35OT2Gc2VrmEiWXnX67zd18u/T3nitl+zo3GZ3WBmYGOIO4AECuG8oKt3KN7ojLDAHNZA2eXPJlyhzcwY3Q26hfYN3Fe8JjsTLjWtyMbE2Brnt50mjJqP6dSMrhVjQ37lmxHJ6B+YZpGse1rXsa+muDRTb+mnvW6zAtbO6ZpcHPADm31TW41xQVu1ttSRjEczE14w7Lkc5+WiRYDRRzECjrW8LH/F5ooz/LErMPkjmkdJlc55Dc2VtEEjMN5Gui3MVsKKV73OdIBI5rnsD6a5zaokfAD3aL27YsRkLyZMpeJDHm6heNziPoDW6xdIPW0dpjDvYHt6jmPcXA6gsAIAHaTZ8FX+0wEed0RGWLPKM34HF2Rke7UlwdwqverTGbPindE6QWYn52cL7L48fosA2HAIpYwHASyc64h3WzWHAg9lECkHnZG1jiHyMc1gLA05o5M7TmvS6GorX4haGJ2zPIITHGI4ZpgxkvOdctacznZaoNLWu7b1V3hMKIgRne8uNlz3WT2fAD3ABaWH2BDG5huRzY8wjY59tYHCiAPgSNUGPB7afJJBmgDYsTm5p3OW6g0uBc2qAIHYTvC1tr4yUYstPVw2Hi56Utlc1xBOl0Nayu6t0b14KxwOx4oHNcC9xYzm487rDG6dVvgNd+m9ZZtmRSc/nBPPsDH6/wBIBAA4bz4oK2Xb0sQdz2HDXcyZo2iWyaLW5HaDK4lzd1jetnaOOniwM0zomNla0lrRISPdrl3+6vqvQ2HEbL3SSOJZbnus0x2ZreAF6nj2rbxuEbPE6J95XVuNHQ2CD8Qgoum4xkzGZGPdDhs0wMxDSSaaS7LZdTHaVWp1XvE8qAGsMbGZjC2ZzZJclBwtrBQNu0PDsVn/AAqMtmBLyZmBj3F3WIALRr2bz9SvL9jRl+Zr5WW1rXNY8tDg38N1qPoQgnF7SyRwlkeeScgRsJy6luY5jrQABJ0K18Htpz5WQuiDZOcex9PsAMaHFwNCx1mjcN54LdxuAbNkJc9jozmY9hogkUfdqCVrfwKICPI6VjmZuu1/WdnIL8xN3ZAN70GjidrYiV0DcPGynTyN60hGZsVg/wBJoEj+w7bGRnKQOnDGNY5hl5onnOvd0XBlfhB7b963ItixMEGQvaYLDCHakOILg7jZAtItjRsJyvlDbcQznDlaX3mIA37zvuuxBGydoyYiLnnxNjiIzMPOZi4WaJFCrFHed6rcFtqfo4LYxK5sXSJTJJkDWvJcxgoGzlHhSvBgWDD9HFiMR82KOobWXfxpak2wYXk6yNa5rWPY19NeG6NDvpppVjeg1cRyhcGSSxQB0ULGulLpMpGZoflaKNkNI3kDWl6xO3JWumc3DtdDDI1jnmWnG8t5W1qQXcexbUuxIXSOcS/K9we+MOpjnNoAkfQabjW5a2A2AG9aZ73OMrpnMDzzeYuJaa7aGX3WLpBjx3SDimsjndzhe1wjaBzbIgacX2LJd1gNd+7cSr5YmYcNkfJbiXgAgnQZbquG8rMghSoUoIUqFKCERSghSoUoIUqEQSiIgIiIKDlv+XSfMz7wvm6+kct/y6T5mfeF83QF9I5Efl0XzP8Avcvm67Hk24jBsone7t/1FEmadsoXPZzxPimc8T4q0mzokXO5zxPimc8T4pRs6JFzuc8T4pnPE+KUbOhRc9nPE+KZzxPilGzoVK53OeJ8UznifFKNnQqVzuc8T4pnPE+KUbOiULns54nxTOeJ8Uo2dEi53OeJ8UznifFKNnRIudznifFM54nxSjZ0Shc9nPE+KZzxPilGzokXO5zxPimc8T4pRs6JQueznifFM54nxSjZ0Shc9nPE+KZzxPilGzoVK53OeJ8UznifFKNnRIudznifFM54nxSjZ0Shc9nPE+KZzxPilGzoUXPZzxPimc8T4pRs6FSudznifFM54nxSjZ0Klc7nPE+KZzxPilGzokXO5zxPimc8T4pRs6FSudznifFM54nxSjZ0SLnc54nxTOeJ8Uo2dEi53OeJ8UznifFKNnQoueznifFM54nxSjZ0Klc7nPE+KZzxPilGzoUXPZzxPimc8T4pRs6JFzuc8T4pnPE+KUbOiRc7nPE+KZzxPilGz3y3/LpPmZ94XzddhylcTg32Tvb2/wCoLj1FibF1/Jv/ACjPi77iuQXX8m/8oz4u+4qwStERFWBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQERa0uMAeWCi4Ns9YADd/wAG0Gpyk/yj/i37guQXW8oH5sETRF5DR3jrDRckpLcCv9kbahgw7Y358wJum2NSSqBFFp1ftLh/1PKntLh/1PKuURW0p1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKntJh/wBTyrlESynV+0uH/U8qe0uH/U8q5REsp1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKntLh/wBTyrlESynV+0uH/U8qe0uH/U8q5REsp1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKntLh/wBTyrlESynV+0uH/U8qe0uH/U8q5REsp1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKntLh/wBTyrlESynV+0uH/U8qe0uH/U8q5REsp1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKntLh/wBTyrlESynV+0uH/U8qe0uH/U8q5REsp1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKntLh/wBTyrlESynV+0uH/U8qe0uH/U8q5REsp1ftLh/1PKntLh/1PKuURLKdX7S4f9Typ7S4f9TyrlESynV+0uH/AFPKvMnKDCuFOa5w97Af/dw8FyyJZS+2ttiGbDujjDgSW1baGhBVCiKFCKs6XJ3vQJ0uTvegRVmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEFmirOlyd70CdLk73oEGFERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREH//Z\n"}}], "tabbable": null, "tooltip": null}}, "c8e8244fd88241eebefdf97a8aad2244": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "2667211906eb454bbb28666e4e713493": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "TabModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_384ee49a9ff64792a0127a2f2f9de237"], "layout": "IPY_MODEL_c8e8244fd88241eebefdf97a8aad2244", "selected_index": 0, "tabbable": null, "titles": ["Youtube"], "tooltip": null}}}, "version_major": 2, "version_minor": 0}</script>
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script crossorigin="anonymous" data-jupyter-widgets-cdn="https://cdn.jsdelivr.net/npm/" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@1.0.6/dist/embed-amd.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/W2D4_Macrolearning/instructor/W2D4_Tutorial4';</script>
<link href="../../../_static/ai-logo.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index">
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W2D4_Tutorial5.html" rel="next" title="Tutorial 5: Replay"/>
<link href="W2D4_Tutorial3.html" rel="prev" title="Tutorial 3: Meta-learning"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></link></link></link></link></link></link></link></head>
<body data-default-mode="" data-offset="180" data-spy="scroll" data-target="#bd-toc-nav">
<a class="skip-link" href="#main-content">Skip to main content</a>
<input class="sidebar-toggle" id="__primary" name="__primary" type="checkbox"/>
<label class="overlay overlay-primary" for="__primary"></label>
<input class="sidebar-toggle" id="__secondary" name="__secondary" type="checkbox"/>
<label class="overlay overlay-secondary" for="__secondary"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
</div>
<nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
<label class="sidebar-toggle primary-toggle" for="__primary">
<span class="fa-solid fa-bars"></span>
</label>
<div id="navbar-start">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/ai-logo.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/ai-logo.png"/>
</a>
</div>
<div class="col-lg-9 navbar-header-items">
<div class="mr-auto" id="navbar-center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D1_Generalization/chapter_title.html">
                        Generalization (W1D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D2_ComparingTasks/chapter_title.html">
                        Comparing Tasks (W1D2)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/chapter_title.html">
                        Comparing Artificial And Biological Networks (W1D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D5_Microcircuits/chapter_title.html">
                        Microcircuits (W1D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_Macrocircuits/chapter_title.html">
                        Macrocircuits (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_NeuroSymbolicMethods/chapter_title.html">
                        Neuro Symbolic Methods (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D3_Microlearning/chapter_title.html">
                        Microlearning (W2D3)
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Macrolearning (W2D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D5_Mysteries/chapter_title.html">
                        Mysteries (W2D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Project materials
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/impact_talks.html">
                        Impact Talks
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/mentorship_program.html">
                        Mentorship Program
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_features.html">
                        Career Features
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_panels.html">
                        Career Panels
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div id="navbar-end">
<div class="navbar-end-item navbar-persistent--container">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="navbar-persistent--mobile">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<label class="sidebar-toggle secondary-toggle" for="__secondary">
<span class="fa-solid fa-outdent"></span>
</label>
</div>
</nav>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D1_Generalization/chapter_title.html">
                        Generalization (W1D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D2_ComparingTasks/chapter_title.html">
                        Comparing Tasks (W1D2)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/chapter_title.html">
                        Comparing Artificial And Biological Networks (W1D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D5_Microcircuits/chapter_title.html">
                        Microcircuits (W1D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_Macrocircuits/chapter_title.html">
                        Macrocircuits (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_NeuroSymbolicMethods/chapter_title.html">
                        Neuro Symbolic Methods (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D3_Microlearning/chapter_title.html">
                        Microlearning (W2D3)
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Macrolearning (W2D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D5_Mysteries/chapter_title.html">
                        Mysteries (W2D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Project materials
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/impact_talks.html">
                        Impact Talks
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/mentorship_program.html">
                        Mentorship Program
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_features.html">
                        Career Features
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_panels.html">
                        Career Panels
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="sidebar-start-items sidebar-primary__section">
<div class="sidebar-start-items__item">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/ai-logo.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/ai-logo.png"/>
</a>
</div>
<div class="sidebar-start-items__item">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="sidebar-start-items__item"><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item navbar-nav active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Schedule/schedule_intro.html">Schedule</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/daily_schedules.html">General schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/shared_calendars.html">Shared calendars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/timezone_widget.html">Timezone widget</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../TechnicalHelp/tech_intro.html">Technical Help</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">Using jupyterbook</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">Using Google Colab</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">Using Kaggle</a></li>
</ul>
</input></li>
<li class="toctree-l2"><a class="reference internal" href="../../TechnicalHelp/Discord.html">Using discord</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">Quick links and policies</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Foundations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D1_Generalization/chapter_title.html">Generalization (W1D1)</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/instructor/W1D1_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/instructor/W1D1_Tutorial1.html">Tutorial 1: Generalization in AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/instructor/W1D1_Tutorial2.html">Tutorial 2: Generalization in Neuroscience</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/instructor/W1D1_Tutorial3.html">Tutorial 3: Generalization in Cognitive Science</a></li>
</ul>
</input></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D2_ComparingTasks/chapter_title.html">Comparing Tasks (W1D2)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/instructor/W1D2_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/instructor/W1D2_Tutorial1.html">Tutorial 1: Task definition, application, relations and impacts on generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/instructor/W1D2_Tutorial2.html">Tutorial 2: Contrastive learning for object recognition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/instructor/W1D2_Tutorial3.html">Tutorial 3: Reinforcement learning across temporal scales</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/chapter_title.html">Comparing Artificial And Biological Networks (W1D3)</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/instructor/W1D3_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/instructor/W1D3_Tutorial1.html">Tutorial 1: Generalization and representational geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/instructor/W1D3_Tutorial2.html">Tutorial 2: Computation as transformation of representational geometries</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/instructor/W1D3_Tutorial3.html">Tutorial 3: Representational geometry &amp; noise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_ComparingArtificialAndBiologicalNetworks/instructor/W1D3_Tutorial4.html">Tutorial 4: Statistical inference on representational geometries</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Architectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D5_Microcircuits/chapter_title.html">Microcircuits (W1D5)</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/instructor/W1D5_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/instructor/W1D5_Tutorial1.html">Tutorial 1: Sparsity and Sparse Coding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/instructor/W1D5_Tutorial2.html">Tutorial 2: Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/instructor/W1D5_Tutorial3.html">Tutorial 3: Attention</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D1_Macrocircuits/chapter_title.html">Macrocircuits (W2D1)</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/instructor/W2D1_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/instructor/W2D1_Tutorial1.html">Tutorial 1: Depth vs Width</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/chapter_title.html">Neuro Symbolic Methods (W2D2)</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/instructor/W2D2_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/instructor/W2D2_Tutorial1.html">Tutorial 1: Basic operations of vector symbolic algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/instructor/W2D2_Tutorial2.html">Tutorial 2: Learning with structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/instructor/W2D2_Tutorial3.html">Tutorial 3: Representations in continuous space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/further_reading.html">Suggested further readings</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D3_Microlearning/chapter_title.html">Microlearning (W2D3)</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/instructor/W2D3_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/instructor/W2D3_Tutorial1.html">Tutorial 1: Microlearning</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../chapter_title.html">Macrolearning (W2D4)</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="W2D4_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="W2D4_Tutorial1.html">Tutorial 1: The problem of changing data distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="W2D4_Tutorial2.html">Tutorial 2: Continual learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="W2D4_Tutorial3.html">Tutorial 3: Meta-learning</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Tutorial 4: Biological meta reinforcement learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="W2D4_Tutorial5.html">Tutorial 5: Replay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../further_reading.html">Suggested further readings</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Mysteries</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D5_Mysteries/chapter_title.html">Mysteries (W2D5)</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/instructor/W2D5_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/instructor/W2D5_Tutorial1.html">Tutorial 1: Consciousness</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/instructor/W2D5_Tutorial2.html">Tutorial 2: Ethics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/instructor/W2D5_Outro.html">Outro</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project Booklet</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/docs/project_guidance.html">Daily guide for projects</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../projects/docs/datasets_overview.html">Project materials</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/Macrocircuits.html">Macrocircuits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/Microlearning.html">Microlearning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/ComparingNetworks.html">Comparing Networks</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Professional Development</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/impact_talks.html">Impact Talks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/mentorship_program.html">Professional developemnt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/career_features.html">Career Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/career_panels.html">Career Panels</a></li>
</ul>
</div>
</nav>
</div>
</div>
<div class="sidebar-end-items sidebar-primary__section">
<div class="sidebar-end-items__item">
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content">
<div class="sbt-scroll-pixel-helper"></div>
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="sidebar-toggle primary-toggle btn btn-sm" data-placement="right" data-toggle="tooltip" for="__primary" title="Toggle primary sidebar">
<span class="fa-solid fa-bars"></span>
</label>
</div>
<div class="header-article__right">
<div class="dropdown dropdown-launch-buttons">
<button aria-expanded="false" aria-label="Launch interactive content" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-rocket"></i>
</button>
<ul class="dropdown-menu">
</ul>
</div>
<button class="btn btn-sm" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="btn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="dropdown dropdown-repository-buttons">
<button aria-expanded="false" aria-label="Source repositories" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fab fa-github"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/neuromatch/instructor-neuroai-course-content" target="_blank" title="Source repository">
<span class="btn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="btn__text-container">repository</span>
</a>

<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/neuromatch/instructor-neuroai-course-content/issues/new?title=Issue%20on%20page%20%2Ftutorials/W2D4_Macrolearning/instructor/W2D4_Tutorial4.html&amp;body=Your%20issue%20content%20here." target="_blank" title="Open an issue">
<span class="btn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="btn__text-container">open issue</span>
</a>

</li></li></ul>
</div>
<div class="dropdown dropdown-download-buttons">
<button aria-expanded="false" aria-label="Download this page" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-download"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W2D4_Macrolearning/instructor/W2D4_Tutorial4.ipynb" target="_blank" title="Download source file">
<span class="btn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="btn__text-container">.ipynb</span>
</a>

<li>
<button class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="btn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="btn__text-container">.pdf</span>
</button>

</li></li></ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" data-placement="left" data-toggle="tooltip" for="__secondary" title="Toggle secondary sidebar">
<span class="fa-solid fa-list"></span>
</label>
</div>
</div>
</div>
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 4: Biological meta reinforcement learning</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 4: Biological meta reinforcement learning
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-and-import-feedback-gadget">
     Install and import feedback gadget
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#imports">
     Imports
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-retrieval">
     Data retrieval
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu">
     Set device (GPU or CPU).
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-0-let-s-play-a-game">
   Section 0: Let’s play a game!
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-reinforcement-learning-task">
     Video 1: Reinforcement Learning Task
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-harlow-experiment-advantage-actor-critic-a2c-agent">
   Section 1: Harlow Experiment &amp; Advantage Actor Critic (A2C) Agent
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-reinforcement-learning-on-the-harlow-task">
     Video 2: Reinforcement Learning on the Harlow Task
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#submit-your-feedback">
     Submit your feedback
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
     Submit your feedback
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-baldwin-effect">
   Section 3: Baldwin Effect
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-baldwin-effect">
     Video 3: Baldwin Effect
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
     Submit your feedback
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-agent-s-rate-to-learn">
     Coding Exercise 1: Agent’s Rate to Learn
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
       Submit your feedback
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-genetic-algorithm">
     Coding Exercise 2: Genetic Algorithm
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id4">
       Submit your feedback
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-evolutionary-theories-in-code">
     Think!: Evolutionary Theories in Code
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id5">
       Submit your feedback
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-newbie-experienced-bird">
   Section 4: Newbie &amp; Experienced Bird
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#why-biology-needs-meta-learning">
     Why biology needs meta-learning
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id6">
       Submit your feedback
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-an-alternative-model-of-how-the-brain-solves-the-harlow-experiment">
   Section 5: An alternative model of how the brain solves the Harlow experiment
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-an-alternative-model">
     Video 4: An Alternative Model
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<article class="bd-article" role="main">
<p><a href="https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D4_Macrolearning/student/W2D4_Tutorial4.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W2D4_Macrolearning/student/W2D4_Tutorial4.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-4-biological-meta-reinforcement-learning">
<h1>Tutorial 4: Biological meta reinforcement learning<a class="headerlink" href="#tutorial-4-biological-meta-reinforcement-learning" title="Permalink to this heading">#</a></h1>
<p><strong>Week 2, Day 4: Macro-Learning</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Hlib Solodzhuk, Ximeng Mao, Grace Lindsay</p>
<p><strong>Content reviewers:</strong> Aakash Agrawal, Alish Dipani, Hossein Rezaei, Yousef Ghanbari, Mostafa Abdollahi, Hlib Solodzhuk, Ximeng Mao, Grace Lindsay</p>
<p><strong>Production editors:</strong> Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk</p>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing of tutorial: 60 minutes</em></p>
<p>In this tutorial, you will observe how meta learning may be occurring in the brain, specifically through reinforcement learning and the Baldwin effect.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "b94191f61b034d4aaf9f289c9aa41c87"}</script></div>
</div>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h1>
<section id="install-and-import-feedback-gadget">
<h2>Install and import feedback gadget<a class="headerlink" href="#install-and-import-feedback-gadget" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install and import feedback gadget</span>

<span class="c1"># !pip3 install vibecheck datatops --quiet</span>

<span class="c1"># from vibecheck import DatatopsContentReviewContainer</span>
<span class="c1"># def content_review(notebook_section: str):</span>
<span class="c1">#     return DatatopsContentReviewContainer(</span>
<span class="c1">#         "",  # No text prompt - leave this as is</span>
<span class="c1">#         notebook_section,</span>
<span class="c1">#         {</span>
<span class="c1">#             "url": "https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab",</span>
<span class="c1">#             "name": "sciencematch_sm", # change the name of the course : neuromatch_dl, climatematch_ct, etc</span>
<span class="c1">#             "user_key": "y1x3mpx5",</span>
<span class="c1">#         },</span>
<span class="c1">#     ).render()</span>

<span class="c1"># feedback_prefix = "W2D4_T4"</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Imports</span>

<span class="c1">#working with data</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1">#plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">logging</span>

<span class="c1">#interactive display</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">clear_output</span>
<span class="kn">from</span> <span class="nn">jupyter_ui_poll</span> <span class="kn">import</span> <span class="n">ui_events</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1">#modeling</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>

<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">'matplotlib.font_manager'</span><span class="p">)</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">True</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="plotting-functions">
<h2>Plotting functions<a class="headerlink" href="#plotting-functions" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting functions</span>

<span class="k">def</span> <span class="nf">plot_cumulative_rewards</span><span class="p">(</span><span class="n">rewards</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Plot the cumulative rewards over time.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - rewards (list): list containing the cumulative rewards at each time step.</span>
<span class="sd">    """</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">)),</span> <span class="n">rewards</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Time Step'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Cumulative Reward'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Cumulative Reward Over Time'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_boxplot_scores</span><span class="p">(</span><span class="n">scores</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Plots a boxplot of the given scores.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    scores (list): list of scores.</span>
<span class="sd">    """</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">''</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">''</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Score'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Distribution of Scores'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">plot_two_boxplot_scores</span><span class="p">(</span><span class="n">newbie_scores</span><span class="p">,</span> <span class="n">experienced_scores</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Plots two boxplots of the given scores.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    scores (list): list of scores.</span>
<span class="sd">    """</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">([</span><span class="n">newbie_scores</span><span class="p">,</span> <span class="n">experienced_scores</span><span class="p">],</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">'Newbie'</span><span class="p">,</span> <span class="s1">'Experienced'</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Agent'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Score'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Distribution of Scores'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions</span>

<span class="k">def</span> <span class="nf">generate_symbols</span><span class="p">():</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Generate random symbols for playing Harlow experiment.</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - symbols (list): list of symbols.</span>
<span class="sd">    """</span>
    <span class="n">symbols</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">symbol_types</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'circle'</span><span class="p">,</span> <span class="s1">'square'</span><span class="p">,</span> <span class="s1">'triangle'</span><span class="p">,</span> <span class="s1">'star'</span><span class="p">,</span> <span class="s1">'pentagon'</span><span class="p">,</span> <span class="s1">'hexagon'</span><span class="p">,</span> <span class="s1">'octagon'</span><span class="p">,</span> <span class="s1">'diamond'</span><span class="p">,</span> <span class="s1">'arrow'</span><span class="p">,</span> <span class="s1">'rectangle'</span><span class="p">]</span>
    <span class="n">symbol_types</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">symbol_types</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">symbol_type</span> <span class="ow">in</span> <span class="n">symbol_types</span><span class="p">:</span>
        <span class="n">color</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s1">'red'</span><span class="p">,</span> <span class="s1">'blue'</span><span class="p">,</span> <span class="s1">'green'</span><span class="p">,</span> <span class="s1">'yellow'</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">symbol_type</span> <span class="o">==</span> <span class="s1">'circle'</span><span class="p">:</span>
            <span class="n">symbol</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Circle</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">symbol_type</span> <span class="o">==</span> <span class="s1">'square'</span><span class="p">:</span>
            <span class="n">symbol</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">symbol_type</span> <span class="o">==</span> <span class="s1">'triangle'</span><span class="p">:</span>
            <span class="n">symbol</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Polygon</span><span class="p">([(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)],</span> <span class="n">closed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">symbol_type</span> <span class="o">==</span> <span class="s1">'star'</span><span class="p">:</span>
            <span class="n">symbol</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Polygon</span><span class="p">([(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>
                                  <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">)],</span> <span class="n">closed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">symbol_type</span> <span class="o">==</span> <span class="s1">'pentagon'</span><span class="p">:</span>
            <span class="n">symbol</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Polygon</span><span class="p">([(</span><span class="mf">0.5</span> <span class="o">+</span> <span class="mf">0.2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">i</span><span class="o">/</span><span class="mi">5</span><span class="p">),</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="mf">0.2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">i</span><span class="o">/</span><span class="mi">5</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)],</span> <span class="n">closed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">symbol_type</span> <span class="o">==</span> <span class="s1">'hexagon'</span><span class="p">:</span>
            <span class="n">symbol</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Polygon</span><span class="p">([(</span><span class="mf">0.5</span> <span class="o">+</span> <span class="mf">0.2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">i</span><span class="o">/</span><span class="mi">6</span><span class="p">),</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="mf">0.2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">i</span><span class="o">/</span><span class="mi">6</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)],</span> <span class="n">closed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">symbol_type</span> <span class="o">==</span> <span class="s1">'octagon'</span><span class="p">:</span>
            <span class="n">symbol</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Polygon</span><span class="p">([(</span><span class="mf">0.5</span> <span class="o">+</span> <span class="mf">0.2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">i</span><span class="o">/</span><span class="mi">8</span><span class="p">),</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="mf">0.2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">i</span><span class="o">/</span><span class="mi">8</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)],</span> <span class="n">closed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">symbol_type</span> <span class="o">==</span> <span class="s1">'diamond'</span><span class="p">:</span>
            <span class="n">symbol</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Polygon</span><span class="p">([(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)],</span> <span class="n">closed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">symbol_type</span> <span class="o">==</span> <span class="s1">'arrow'</span><span class="p">:</span>
            <span class="n">symbol</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Polygon</span><span class="p">([(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)],</span> <span class="n">closed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">symbol_type</span> <span class="o">==</span> <span class="s1">'rectangle'</span><span class="p">:</span>
            <span class="n">symbol</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
        <span class="n">symbols</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">symbol</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">symbols</span>

<span class="k">def</span> <span class="nf">run_dummy_agent</span><span class="p">(</span><span class="n">env</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Implement dummy agent strategy: chooses the last rewarded action.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - env (HarlowExperimentEnv): An environment.</span>
<span class="sd">    """</span>
    <span class="n">action</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">cumulative_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">rewards</span> <span class="o">=</span> <span class="p">[</span><span class="n">cumulative_reward</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_trials</span><span class="p">)):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">cumulative_reward</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cumulative_reward</span><span class="p">)</span>

        <span class="c1">#dummy agent</span>
        <span class="k">if</span> <span class="n">reward</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">action</span>
    <span class="k">return</span> <span class="n">rewards</span>

<span class="k">def</span> <span class="nf">game</span><span class="p">():</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Create interactive game which resembles one famous experiment!</span>
<span class="sd">    """</span>
    <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">symbols</span> <span class="o">=</span> <span class="n">generate_symbols</span><span class="p">()</span>
    <span class="n">message</span> <span class="o">=</span> <span class="s2">"Start of the game!"</span>

    <span class="n">left_button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"Left"</span><span class="p">)</span>
    <span class="n">right_button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"Right"</span><span class="p">)</span>
    <span class="n">button_box</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">HBox</span><span class="p">([</span><span class="n">left_button</span><span class="p">,</span> <span class="n">right_button</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">define_choice</span><span class="p">(</span><span class="n">button</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Change `choice` variable with respect to the pressed button.</span>
<span class="sd">        """</span>
        <span class="k">nonlocal</span> <span class="n">choice</span>
        <span class="n">display</span><span class="p">(</span><span class="n">widgets</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s2">"&lt;h3&gt;</span><span class="si">{</span><span class="n">button</span><span class="o">.</span><span class="n">description</span><span class="si">}</span><span class="s2">&lt;/h3&gt;"</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">button</span><span class="o">.</span><span class="n">description</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">button</span><span class="o">.</span><span class="n">description</span> <span class="o">==</span> <span class="s2">"Left"</span><span class="p">:</span>
            <span class="n">choice</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">choice</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">left_button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">define_choice</span><span class="p">)</span>
    <span class="n">right_button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">define_choice</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">first_symbol</span><span class="p">,</span> <span class="n">second_symbol</span> <span class="o">=</span> <span class="n">symbols</span><span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">index</span> <span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="n">index</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">location_of_first_symbol</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">display</span><span class="p">(</span><span class="n">widgets</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s2">"&lt;h3&gt;</span><span class="si">{</span><span class="n">message</span><span class="si">}</span><span class="s2">&lt;/h3&gt;"</span><span class="p">))</span>
            <span class="n">display</span><span class="p">(</span><span class="n">widgets</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s2">"&lt;h3&gt;Total reward: </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s2">&lt;/h3&gt;"</span><span class="p">))</span>
            <span class="n">display</span><span class="p">(</span><span class="n">widgets</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s2">"&lt;h4&gt;Objects:&lt;/h4&gt;"</span><span class="p">))</span>

            <span class="k">if</span> <span class="n">location_of_first_symbol</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">symbol_left</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">first_symbol</span><span class="p">)</span>
                <span class="n">symbol_right</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">second_symbol</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">symbol_left</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">second_symbol</span><span class="p">)</span>
                <span class="n">symbol_right</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">first_symbol</span><span class="p">)</span>

            <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>

                <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

                <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">symbol_left</span><span class="p">)</span>
                <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>

                <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">symbol_right</span><span class="p">)</span>
                <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>

                <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

            <span class="n">display</span><span class="p">(</span><span class="n">widgets</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="s2">"&lt;h4&gt;Choose Left or Right:&lt;/h4&gt;"</span><span class="p">))</span>
            <span class="n">display</span><span class="p">(</span><span class="n">button_box</span><span class="p">)</span>

            <span class="n">choice</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="k">with</span> <span class="n">ui_events</span><span class="p">()</span> <span class="k">as</span> <span class="n">poll</span><span class="p">:</span>
                <span class="k">while</span> <span class="n">choice</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                    <span class="n">poll</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
                    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span> <span class="o">&gt;</span> <span class="mi">60</span><span class="p">:</span>
                        <span class="k">return</span>

            <span class="k">if</span> <span class="n">choice</span> <span class="o">==</span> <span class="n">location_of_first_symbol</span><span class="p">:</span>
                <span class="n">total_reward</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">message</span> <span class="o">=</span> <span class="s2">"You received a reward of +1."</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">total_reward</span> <span class="o">-=</span> <span class="mi">1</span>
                <span class="n">message</span> <span class="o">=</span> <span class="s2">"You received a penalty of -1."</span>

    <span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">display</span><span class="p">(</span><span class="n">widgets</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s2">"&lt;h3&gt;Your total reward: </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s2">, congratulations! Do you have any idea what you should do to maximize the reward?&lt;/h3&gt;"</span><span class="p">))</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="data-retrieval">
<h2>Data retrieval<a class="headerlink" href="#data-retrieval" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Data retrieval</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">hashlib</span>

<span class="c1"># Variables for file and download URL</span>
<span class="n">fname</span> <span class="o">=</span> <span class="s2">"Evolution.pt"</span> <span class="c1"># The name of the file to be downloaded</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://osf.io/wmvh4/download"</span> <span class="c1"># URL from where the file will be downloaded</span>
<span class="n">expected_md5</span> <span class="o">=</span> <span class="s2">"d0a74898e56549f7c5206e4c8f373ced"</span> <span class="c1"># MD5 hash for verifying file integrity</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">fname</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Attempt to download the file</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span> <span class="c1"># Make a GET request to the specified URL</span>
    <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">ConnectionError</span><span class="p">:</span>
        <span class="c1"># Handle connection errors during the download</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"!!! Failed to download data !!!"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># No connection errors, proceed to check the response</span>
        <span class="k">if</span> <span class="n">r</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="n">requests</span><span class="o">.</span><span class="n">codes</span><span class="o">.</span><span class="n">ok</span><span class="p">:</span>
            <span class="c1"># Check if the HTTP response status code indicates a successful download</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"!!! Failed to download data !!!"</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span> <span class="o">!=</span> <span class="n">expected_md5</span><span class="p">:</span>
            <span class="c1"># Verify the integrity of the downloaded file using MD5 checksum</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"!!! Data download appears corrupted !!!"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If download is successful and data is not corrupted, save the file</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fid</span><span class="p">:</span>
                <span class="n">fid</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span> <span class="c1"># Write the downloaded content to a file</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="set-device-gpu-or-cpu">
<h2>Set device (GPU or CPU).<a class="headerlink" href="#set-device-gpu-or-cpu" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set device (GPU or CPU).</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Determines and sets the computational device for PyTorch operations based on the availability of a CUDA-capable GPU.</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - device (str): The device that PyTorch will use for computations ('cuda' or 'cpu'). This string can be directly used</span>
<span class="sd">    in PyTorch operations to specify the device.</span>
<span class="sd">    """</span>

    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
    <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is not enabled in this notebook. </span><span class="se">\n</span><span class="s2">"</span>
              <span class="s2">"If you want to enable it, in the menu under `Runtime` -&gt; </span><span class="se">\n</span><span class="s2">"</span>
              <span class="s2">"`Hardware accelerator.` and select `GPU` from the dropdown menu"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is enabled in this notebook. </span><span class="se">\n</span><span class="s2">"</span>
              <span class="s2">"If you want to disable it, in the menu under `Runtime` -&gt; </span><span class="se">\n</span><span class="s2">"</span>
              <span class="s2">"`Hardware accelerator.` and select `None` from the dropdown menu"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">device</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GPU is not enabled in this notebook. 
If you want to enable it, in the menu under `Runtime` -&gt; 
`Hardware accelerator.` and select `GPU` from the dropdown menu
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-random-seed">
<h2>Set random seed<a class="headerlink" href="#set-random-seed" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set random seed</span>

<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-0-let-s-play-a-game">
<h1>Section 0: Let’s play a game!<a class="headerlink" href="#section-0-let-s-play-a-game" title="Permalink to this heading">#</a></h1>
<p>First watch the video to understand our shift to reinforcement learning. Then try out your own reinforcement learning skills! Below you will play an interactive game where your task is to maximize the total reward you receive!</p>
<section id="video-1-reinforcement-learning-task">
<h2>Video 1: Reinforcement Learning Task<a class="headerlink" href="#video-1-reinforcement-learning-task" title="Permalink to this heading">#</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>The rules are simple: on each turn you are shown two distinct objects in two different hands (left or right), you shold pick a hand and after that you will immediately observe the reward for this particular choice. Good luck with maximizing your score! After playing, discuss in a group, whether you have any clues about underlying structure of the game and whether there exists the most optimal strategy to play this game.</p>
<p>Make sure you execute this cell to play the game!</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Make sure you execute this cell to play the game!</span>
<span class="n">game</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "ee84d9dd9b2d4197994461c0657d6a12"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "0af8c4d74d6842d9b688d941997e7412"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "81662ab920534b0887b6c7999989f299"}</script><img alt="../../../_images/f683d02ee002390d74dac69477b50d96d54d2e7949ab1459d54d19122b08c2e1.png" src="../../../_images/f683d02ee002390d74dac69477b50d96d54d2e7949ab1459d54d19122b08c2e1.png">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "46a183a9177546abb690abab297a6a73"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "d45c80675770473bb4306f338fd42ccc"}</script></img></div>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-1-harlow-experiment-advantage-actor-critic-a2c-agent">
<h1>Section 1: Harlow Experiment &amp; Advantage Actor Critic (A2C) Agent<a class="headerlink" href="#section-1-harlow-experiment-advantage-actor-critic-a2c-agent" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing to here from start of tutorial: 10 minutes</em></p>
<p>In this section we will introduce the reinforcement learning environment which replicates the 1940s Harlow experiment and will observe how different agents can learn to perform a single task.</p>
<section id="video-2-reinforcement-learning-on-the-harlow-task">
<h2>Video 2: Reinforcement Learning on the Harlow Task<a class="headerlink" href="#video-2-reinforcement-learning-on-the-harlow-task" title="Permalink to this heading">#</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</section>
<section id="submit-your-feedback">
<h2>Submit your feedback<a class="headerlink" href="#submit-your-feedback" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_harlow_experiment")</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Any RL system consists of the agent who tries to succeed the task by observing the state of the enviornment, executing an action, and receiving the outcome (reward).</p>
<p>First we will define the environment for this task.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">HarlowExperimentEnv</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">punishment</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Initialize Harlow Experiment environment."""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="n">reward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">punishment</span> <span class="o">=</span> <span class="n">punishment</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rewarded_digit</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">punished_digit</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">rewarded_digit</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">punished_digit</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">update_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Update state by selecting rewarded hand for random."""</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">rewarded_digit</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">punished_digit</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">punished_digit</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewarded_digit</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Reset environment by updating new rewarded and punished digits as well as create current state of the world (tuple of observations)."""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rewarded_digit</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">punished_digit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Evaluate agent's perfromance, return reward and next observation."""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">action</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewarded_digit</span><span class="p">:</span>
            <span class="n">feedback</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">feedback</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">punishment</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="n">feedback</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s evaluate a simple strategy for this task: an agent always chooses the side that was previously rewarded (meaning it stays with the same hand if it received reward and changes its action if it was punished). Do you think this agent uses information about the current state? How much cumulative reward do you expect this “dummy” agent to get?</p>
<p>Make sure you execute this cell to observe the plot!</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Make sure you execute this cell to observe the plot!</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">num_trials</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">HarlowExperimentEnv</span><span class="p">()</span>
<span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">rewards</span> <span class="o">=</span> <span class="n">run_dummy_agent</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>

<span class="n">plot_cumulative_rewards</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../../_images/1da2125bb881441da6a4c20531537f987c17b12b3dde4fde2af8cf65a0557337.png" src="../../../_images/1da2125bb881441da6a4c20531537f987c17b12b3dde4fde2af8cf65a0557337.png">
</img></div>
</div>
<p><strong>For now, simply run all the cells in this section without exploring the content. You can come back to look through the code if you have time after completing all the tutorials.</strong></p>
<p>The dummy agent’s stragey doesn’t use object identity, which is key to being able to consistently select the right action. Let’s see if we can do better than the dummy agent’s strategy. After defining the environment and observing the behaviour of the agent implementing such a simple policy, it is the right time to remind ourselves about more sophisticated agent architectures that are capable of learning the environment’s dynamics. For this we will use the Advantage Actor Critic (A2C).</p>
<p>The main idea behind A2C, as it name suggests, is that it consists of two networks, named actor and critic. Actor network learns the policy (mapping states to actions), while the critic network learns the value function (estimating the expected future rewards from a given state). In the most cases, they share the same “body” (i.e. model layers) and only the last linear projection to the output is specific to each of the networks. The “advantage” term comes from the training step: instead of raw rewards, in A2C we calculate the advantage function, which estimates how much better or worse an action is compared to the average action value for a given state.</p>
<p>The architecture of the agent is the following: it receives the previous state, previous reward &amp; chosen action as input, which is linearly projected to the <code class="docutils literal notranslate"><span class="pre">hidden_size</span></code> (this creates an embedding); then, its core consists of recurrent <code class="docutils literal notranslate"><span class="pre">LSTM</span></code> cells, their number is exactly <code class="docutils literal notranslate"><span class="pre">hidden_size</span></code>. Right after this RNN layer there are two distinct linear projections: one for the actor (output dimension coincides with the number of actions; for the Harlow experiment it is 2) and the latter for critic (outputs one value).</p>
<p>We don’t propose an exercise to code for the agent; when you have time, simply go through the cell below to understand the implementation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ActorCritic</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_inputs</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">num_actions</span> <span class="o">=</span> <span class="mi">2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Initialize Actor-Critic agent."""</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ActorCritic</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1">#num_actions is 2 because left/right hand</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="n">num_actions</span>

        <span class="c1">#num_inputs is 5 because one-hot encoding of action (2) + reward (1) + previous state (2)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_inputs</span> <span class="o">=</span> <span class="n">num_inputs</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>

        <span class="c1">#hyperparameters involved in training (important to keep assigned to the agent)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.00075</span> <span class="c1">#learning rate for optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discount_factor</span> <span class="o">=</span> <span class="mf">0.91</span> <span class="c1">#gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_value_estimate_cost</span> <span class="o">=</span> <span class="mf">0.4</span> <span class="c1">#beta_v</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">entropy_cost</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1">#beta_e</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">critic_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actor_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Implement forward pass through agent."""</span>
        <span class="c1">#at first, input goes through embedding</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

        <span class="c1">#then through RNNs (observe that we pass hidden states too!)</span>
        <span class="n">state</span><span class="p">,</span> <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">hidden_states</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1">#critic -&gt; value</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic_linear</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

        <span class="c1">#actor -&gt; policy</span>
        <span class="n">policy_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_linear</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">policy_logits</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_init_hidden_states</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Initialize hidden state with 0."""</span>
        <span class="c1">#initialize hidden state in RNNs</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>In the cell below we define the training procedure for the A2C agent as well as its evaluation afterwards. The function <code class="docutils literal notranslate"><span class="pre">train_evaluate_agent</span></code> performs <code class="docutils literal notranslate"><span class="pre">num_gradient_steps</span></code> gradient steps (by default 25) and for each of the steps, the agent is exposed to the enviornment’s states sequence of length <code class="docutils literal notranslate"><span class="pre">num_trials</span></code>  (by default 6, as in classical Harlow experiment). Each gradient step, it performs backpropagation of the loss for these 6 trials by calculating advantage and weighting actor and critic losses with the entropy of the policy (for more information, please refer to <a class="reference external" href="https://www.biorxiv.org/content/10.1101/295964v1.full.pdf">this resource</a>, p.14). After the training is complete, the evaluation phase starts, gathering rewards for <code class="docutils literal notranslate"><span class="pre">num_evaluation_trials</span></code> trials (by default 20).</p>
<p>Note: the evaluation is completed on the same task (i.e. the same set of two objects) as the model was trained on.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_evaluate_agent</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">agent</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">,</span> <span class="n">num_gradient_steps</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span> <span class="n">num_trials</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span> <span class="n">num_evaluation_trials</span> <span class="o">=</span> <span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Training and evaluation for agent in Harlow experiment environment.</span>
<span class="sd">    Evaluation goes only after all gradient steps.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - env (HarlowExperimentEnv): environment.</span>
<span class="sd">    - agent (ActorCritic): particular instance of Actor Critic agent to train.</span>
<span class="sd">    - optimizer_func (torch.Optim): optimizer to use for training.</span>
<span class="sd">    - num_gradient_steps (int, default = 25): number of gradient steps to perform.</span>
<span class="sd">    - num_trials (int, default = 6): number of times the agent is exposed to the environment per gradient step to be trained .</span>
<span class="sd">    - num_evaluation_trials (int, default = 20): number of times the agent is exposed to the environment to evaluate it (no training happend during this phase).</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - score (int): cumulative reward over all trials of evaluation.</span>
<span class="sd">    """</span>
    <span class="c1">#training</span>

    <span class="c1">#reset environment</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="c1">#define optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer_func</span><span class="p">(</span><span class="n">agent</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">agent</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_gradient_steps</span><span class="p">):</span>

      <span class="c1">#for storing variables for training</span>
      <span class="n">log_probs</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">entropy_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>

      <span class="c1">#start conditions</span>
      <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">get_init_hidden_states</span><span class="p">()</span>
      <span class="n">preceding_reward</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
      <span class="n">preceding_action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

      <span class="k">for</span> <span class="n">trial</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_trials</span><span class="p">):</span>

          <span class="c1">#state + reward + one-hot encoding of action</span>
          <span class="n">full_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">preceding_reward</span><span class="p">,</span> <span class="n">preceding_action</span><span class="p">),</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
          <span class="n">value</span><span class="p">,</span> <span class="n">policy_logits</span><span class="p">,</span> <span class="n">step_hidden_states</span> <span class="o">=</span> <span class="n">agent</span><span class="p">(</span><span class="n">full_state</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
          <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">step_hidden_states</span>
          <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

          <span class="c1">#sample action from policy</span>
          <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">policy_logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
          <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

          <span class="c1">#perform action to get reward and new state</span>
          <span class="n">new_state</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

          <span class="c1">#update preceding variables</span>
          <span class="n">preceding_reward</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">reward</span><span class="p">])</span>
          <span class="n">preceding_action</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
          <span class="n">state</span> <span class="o">=</span> <span class="n">new_state</span>

          <span class="c1">#for training</span>
          <span class="n">log_prob</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
          <span class="n">entropy</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>
          <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
          <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
          <span class="n">log_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">log_prob</span><span class="p">)</span>
          <span class="n">entropy_term</span> <span class="o">+=</span> <span class="n">entropy</span>

      <span class="c1">#calculataing loss</span>
      <span class="n">Qval</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="n">Qvals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">))):</span>
        <span class="n">Qval</span> <span class="o">=</span> <span class="n">rewards</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">agent</span><span class="o">.</span><span class="n">discount_factor</span> <span class="o">*</span> <span class="n">Qval</span>
        <span class="n">Qvals</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">Qval</span>
      <span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
      <span class="n">log_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">log_probs</span><span class="p">)</span>
      <span class="n">advantage</span> <span class="o">=</span> <span class="n">Qvals</span> <span class="o">-</span> <span class="n">values</span>
      <span class="n">actor_loss</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">log_probs</span> <span class="o">*</span> <span class="n">advantage</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
      <span class="n">critic_loss</span> <span class="o">=</span> <span class="n">advantage</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
      <span class="n">entropy_term</span> <span class="o">=</span> <span class="n">entropy_term</span> <span class="o">/</span> <span class="n">num_trials</span>

      <span class="c1">#loss incorporates actor/critic terms + entropy</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">actor_loss</span> <span class="o">+</span> <span class="n">agent</span><span class="o">.</span><span class="n">state_value_estimate_cost</span> <span class="o">*</span> <span class="n">critic_loss</span> <span class="o">-</span> <span class="n">agent</span><span class="o">.</span><span class="n">entropy_cost</span> <span class="o">*</span> <span class="n">entropy_term</span>

      <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1">#evaluation (on the same task after all gradient steps!)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1">#start conditions</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">get_init_hidden_states</span><span class="p">()</span>
    <span class="n">preceding_reward</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">preceding_action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_evaluation_trials</span><span class="p">):</span>

      <span class="c1">#state + reward + one-hot encoding of action</span>
      <span class="n">full_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">preceding_reward</span><span class="p">,</span> <span class="n">preceding_action</span><span class="p">),</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
      <span class="n">value</span><span class="p">,</span> <span class="n">policy_logits</span><span class="p">,</span> <span class="n">step_hidden_states</span> <span class="o">=</span> <span class="n">agent</span><span class="p">(</span><span class="n">full_state</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
      <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">step_hidden_states</span>
      <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

      <span class="c1">#sample action from policy</span>
      <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">policy_logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
      <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

      <span class="c1">#perform action to get reward and new state</span>
      <span class="n">new_state</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

      <span class="c1">#update preceding variables</span>
      <span class="n">preceding_reward</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">reward</span><span class="p">])</span>
      <span class="n">preceding_action</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
      <span class="n">state</span> <span class="o">=</span> <span class="n">new_state</span>

      <span class="c1">#add reward to the score of agent</span>
      <span class="n">score</span> <span class="o">+=</span> <span class="n">reward</span>

    <span class="k">return</span> <span class="n">score</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s see what is the score for the default A2C agent in this Harlow experiment (as the number of evaluation trials is 20, the maximum score to obtain is exactly 20).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">#define environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">HarlowExperimentEnv</span><span class="p">()</span>

<span class="c1">#define agent and optimizer</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ActorCritic</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">optimizer_func</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span>

<span class="c1">#calculate score</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">train_evaluate_agent</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">agent</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Score is </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Score is 12.
</pre></div>
</div>
</div>
</div>
<p>Can we think of a way to make the network better at learning the Harlow tasks?</p>
</section>
<section id="id1">
<h2>Submit your feedback<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_a2c_agent")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-3-baldwin-effect">
<h1>Section 3: Baldwin Effect<a class="headerlink" href="#section-3-baldwin-effect" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing to here from start of tutorial: 20 minutes</em></p>
<p>This section introduces the meta-nature of the Harlow experiment and how it can be related to concepts we learned in the previous meta-learning tutorial. It also discusses the Baldwin effect in evolutionary biology and proposes that you code its implementation.</p>
<section id="video-3-baldwin-effect">
<h2>Video 3: Baldwin Effect<a class="headerlink" href="#video-3-baldwin-effect" title="Permalink to this heading">#</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "2667211906eb454bbb28666e4e713493"}</script></div>
</div>
</section>
<section id="id2">
<h2>Submit your feedback<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_baldwin_effect")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="coding-exercise-1-agent-s-rate-to-learn">
<h2>Coding Exercise 1: Agent’s Rate to Learn<a class="headerlink" href="#coding-exercise-1-agent-s-rate-to-learn" title="Permalink to this heading">#</a></h2>
<p>As it was introduced in the video, the Baldwin effect argues that we don’t inherit the features/weights that make us good at specific tasks but rather the ability to learn quickly to gain the needed features in the context of the tasks we face during our own lifetime. In this way, evolution works like the outer loop in a meta-learning context.</p>
<p>In the next section we will implement this evolutionary approach to meta-learning. But first we need to write a function that lets us evaluate how well an agent can learn each instantiation of the Harlow task. This looks something like this:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp; [1] \: \theta \: \text{- network parameters} \\
&amp; [2] \: \text{Sample batch of tasks }\tau_i \sim p(\tau) \\
&amp; [3] \: \text{for all }\tau_i \text{ do} \\
&amp; [4] \: \quad\quad \theta_i \leftarrow \theta \\
&amp; [5] \: \quad\quad \text{for} \: k \: \text{in range(number of gradient steps)}  \\
&amp; [6] \: \quad\quad\quad\quad\text{Evaluate }\nabla_{\theta_i} \mathcal{L}_{\tau_i}(\theta_i) \\
&amp; [7] \: \quad\quad\quad\quad\text{Compute adapted parameters with gradient descent:} \: \: \theta_i \leftarrow \theta_i - \alpha \nabla_{\theta_i} \mathcal{L}_{\tau_i}(\theta_i) \\
&amp; [8] \: \quad\quad\text{end for} \\
&amp; [9] \: \quad\quad\text{Calculate score of updated agent on this task }f_i = \text{score}(\tau_i(\theta_i)) \\
&amp; [10] \: \text{end for} \\
&amp; [11] \: \text{Score of the agent for all tasks is} \: F = \sum_{i} f_i \\
\end{align*}\]</div>
<p>At first, we sample a bunch of tasks from the environment (different pairs of objects; line[2]). The crucial concept involved in this algorithm is preserved in line [4], where for each new task, we don’t start with updated parameters but the one we have before training and evaluating the agent. Then, we perform training for the defined number of gradient steps and evaluate the agent’s performance on this same task (we have defined this function in the second section of the tutorial, it basically covers lines [5] - [9]). To evaluate the agent’s ability to learn quickly, one task is not enough - it is exactly why we sampled a bunch of them and the general score for the agent is defined as sum of rewards for all tasks.</p>
<p>In the coding exercise you are invited to complete the implementation of the evaluation of a randomly created agent on 10 tasks (thus, the maximum score which can be obtained is: 10 (number of tasks) x 20 (number of evaluation trials per task) = 200). In the next section of the tutorial, we will provide the evolutionary framework in which we are going to learn “base” or “starting” weights.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">agent</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">,</span> <span class="n">num_tasks</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num_gradient_steps</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span> <span class="n">num_trials</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span> <span class="n">num_evaluation_trials</span> <span class="o">=</span> <span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Training and evaluation for agent in Harlow experiment environment for the bunch of tasks (thus measuring overall potential for agent's generalization across the tasks).</span>
<span class="sd">    Evaluation goes only after all gradient steps.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - env (HarlowExperimentEnv): environment.</span>
<span class="sd">    - agent (ActorCritic): particular instance of Actor Critic agent to train.</span>
<span class="sd">    - optimizer_func (torch.Optim): optimizer to use for training.</span>
<span class="sd">    - num_tasks (int, default = 10): number of tasks to evaluate agent on.</span>
<span class="sd">    - num_gradient_steps (int, default = 25): number of gradient steps to perform.</span>
<span class="sd">    - num_trials (int, default = 6): number of times the agent is exposed to the environment per gradient step to be trained .</span>
<span class="sd">    - num_evaluation_trials (int, default = 20): number of times the agent is exposed to the environment to evaluate it (no training happend during this phase).</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - scores (list): list of scores obtained during evaluation on the specific tasks.</span>
<span class="sd">    """</span>
    <span class="c1">###################################################################</span>
    <span class="c1">## Fill out the following then remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: complete evaluation function with Baldwin effect in mind."</span><span class="p">)</span>
    <span class="c1">###################################################################</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tasks</span><span class="p">):</span> <span class="c1">#lines[2-3]; notice that environment resets inside `train_evaluate_agent`</span>
      <span class="n">agent_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="c1">#line[4]; remember that we don't want to change agent's parameters!</span>
      <span class="n">score</span> <span class="o">=</span> <span class="n">train_evaluate_agent</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">,</span> <span class="n">num_gradient_steps</span><span class="p">,</span> <span class="n">num_trials</span><span class="p">,</span> <span class="n">num_evaluation_trials</span><span class="p">)</span>
      <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">scores</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="k">def</span> <span class="nf">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">agent</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">,</span> <span class="n">num_tasks</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num_gradient_steps</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span> <span class="n">num_trials</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span> <span class="n">num_evaluation_trials</span> <span class="o">=</span> <span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Training and evaluation for agent in Harlow experiment environment for the bunch of tasks (thus measuring overall potential for agent's generalization across the tasks).</span>
<span class="sd">    Evaluation goes only after all gradient steps.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - env (HarlowExperimentEnv): environment.</span>
<span class="sd">    - agent (ActorCritic): particular instance of Actor Critic agent to train.</span>
<span class="sd">    - optimizer_func (torch.Optim): optimizer to use for training.</span>
<span class="sd">    - num_tasks (int, default = 10): number of tasks to evaluate agent on.</span>
<span class="sd">    - num_gradient_steps (int, default = 25): number of gradient steps to perform.</span>
<span class="sd">    - num_trials (int, default = 6): number of times the agent is exposed to the environment per gradient step to be trained .</span>
<span class="sd">    - num_evaluation_trials (int, default = 20): number of times the agent is exposed to the environment to evaluate it (no training happend during this phase).</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - score (int): total score.</span>
<span class="sd">    - scores (list): list of scores obtained during evaluation on the specific tasks.</span>
<span class="sd">    """</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tasks</span><span class="p">):</span> <span class="c1">#lines[2-3]; notice that environment resets inside `train_evaluate_agent`</span>
      <span class="n">agent_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">agent</span><span class="p">)</span> <span class="c1">#line[4]; remember that we don't want to change agent's parameters!</span>
      <span class="n">score</span> <span class="o">=</span> <span class="n">train_evaluate_agent</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">agent_copy</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">,</span> <span class="n">num_gradient_steps</span><span class="p">,</span> <span class="n">num_trials</span><span class="p">,</span> <span class="n">num_evaluation_trials</span><span class="p">)</span>
      <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">scores</span>
</pre></div>
</div>
</div>
</div>
<p>Observe the box-plot of the scores as well as their sum. Not surprisingly, this random agent does not perform very well.</p>
<p>Make sure you execute this cell to observe the plot!</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Make sure you execute this cell to observe the plot!</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">#define environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">HarlowExperimentEnv</span><span class="p">()</span>

<span class="c1">#define agent and optimizer</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ActorCritic</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">optimizer_func</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span>

<span class="c1">#calculate score</span>
<span class="n">total_score</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">agent</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total score is </span><span class="si">{</span><span class="n">total_score</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
<span class="n">plot_boxplot_scores</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total score is 54.
</pre></div>
</div>
<img alt="../../../_images/a6b329a97f44213696782dfd17aaf080e1acc019c28eef243710aa077998be14.png" src="../../../_images/a6b329a97f44213696782dfd17aaf080e1acc019c28eef243710aa077998be14.png"/>
</div>
</div>
<section id="id3">
<h3>Submit your feedback<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_agents_rate_to_learn")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="coding-exercise-2-genetic-algorithm">
<h2>Coding Exercise 2: Genetic Algorithm<a class="headerlink" href="#coding-exercise-2-genetic-algorithm" title="Permalink to this heading">#</a></h2>
<p>Genetic algorithms (GA) mimic some of the evolutionary process while generating better and better (= more desired) individuals in the population. At first, we initialize a population which consists of randomly defined agents (so we have a list of <code class="docutils literal notranslate"><span class="pre">population_size</span></code> A2C agents which will in the very end evolve to the agents which quickly learn the new task from Harlow experiment environment). Each epoch (which is the classical term for machine learning) is defined as a generation in GA as we generate new individuals in the population. For each epoch, we choose top-score individuals from the population (of size <code class="docutils literal notranslate"><span class="pre">tournament_size</span></code>; should be big enough to preserve diversity and not too big for selecting top-score ones; it is exactly where selection takes place! and it is the only such place in the whole algorithm) and then we select a random batch of these high-performing individuals of size <code class="docutils literal notranslate"><span class="pre">parents_num</span></code>. From those, we create offspring of size <code class="docutils literal notranslate"><span class="pre">new_generation_new_individuals</span></code> which will replace random individuals from the population . We continue running generations until we are happy with the best-fit individual appearing in the population or until we are running out of time (reached maximum number of generations).</p>
<p>The funniest part happens at the place where we create offsprings - to simluate evoluntionary processes, we randomly select two parents (two agents) and for each of the layers in their networks, we randomly select which one will go to the child (simulating crossing over) and then we add Gaussian noise to each of the layers (simulating mutation).</p>
<p>The following cells consist of 3 functions:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">create_initial_population</span></code>, which creates a population and evaluates each individual by their score;</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_initial_population</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">optmizer_func</span><span class="p">,</span> <span class="n">population_size</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Creates an initial population of agents.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - env (HarlowExperimentEnv): environment.</span>
<span class="sd">    - optimizer_func (torch.Optim): optimizer to use for training.</span>
<span class="sd">    - population_size (int, default = 50): the size of the initial population.</span>
<span class="sd">    - hidden_size (int, default = 20): the size of LSTM layer in A2C agent.</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - population (list): initial population which consists of tuples (agent, score).</span>
<span class="sd">    - best_score (int): the best score for the individual in the population registered so far.</span>
<span class="sd">    """</span>
    <span class="n">population</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">total_score</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">best_score</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">population_size</span><span class="p">):</span>
        <span class="n">agent</span> <span class="o">=</span> <span class="n">ActorCritic</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">agent</span><span class="p">,</span> <span class="n">optmizer_func</span><span class="p">)</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">best_score</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>
        <span class="n">total_score</span> <span class="o">+=</span> <span class="n">score</span>
        <span class="n">population</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">agent</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Generation: 0, mean population score: </span><span class="si">{</span><span class="n">total_score</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">population_size</span><span class="si">}</span><span class="s2">, best score: </span><span class="si">{</span><span class="n">best_score</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">population</span><span class="p">,</span> <span class="n">best_score</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">create_new_agent</span></code>, which performs operations of crossing over and mutation on parents’ networks to create the offspring one;</p></li>
</ul>
<p>The first cell defines the noise constants to be used for each of the (hyper)parameters while mutating them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#for mutation of (hyper)parameters</span>
<span class="n">parameters_noise</span> <span class="o">=</span> <span class="mf">0.02</span>
<span class="n">learning_rate_noise</span> <span class="o">=</span> <span class="mf">0.00005</span>
<span class="n">discount_factor_noise</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">state_value_estimate_cost_noise</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">entropy_cost_noise</span> <span class="o">=</span> <span class="mf">0.001</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_new_agent</span><span class="p">(</span><span class="n">agent1</span><span class="p">,</span> <span class="n">agent2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Creates new agent using crossing over technique over layers of network and mutation of the parameters with Gaussian noise.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - agent1 (ActorCritic): first parent agent.</span>
<span class="sd">    - agent2 (ActorCritic): second parent agent.</span>

<span class="sd">    Outputs:</span>
<span class="sd">    - new_agent (ActorCritic): new agent which is offspring of the given two.</span>
<span class="sd">    """</span>
    <span class="c1">#creates agent as copy of the first one</span>
    <span class="n">new_agent</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">agent1</span><span class="p">)</span>

    <span class="c1">#evolving network parameters with crossing over (over separate layes) &amp; mutating (Gaussian noise)</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">new_agent</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>
                <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span>
            <span class="c1">#add noise</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">parameters_noise</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">parameters_noise</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">module</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="o">.</span><span class="n">data</span>
                <span class="n">module</span><span class="o">.</span><span class="n">weight_hh_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">weight_hh_l0</span><span class="o">.</span><span class="n">data</span>
                <span class="n">module</span><span class="o">.</span><span class="n">bias_ih_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">bias_ih_l0</span><span class="o">.</span><span class="n">data</span>
                <span class="n">module</span><span class="o">.</span><span class="n">bias_hh_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">bias_hh_l0</span><span class="o">.</span><span class="n">data</span>
            <span class="c1">#add noise</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight_ih_l0</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">parameters_noise</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight_hh_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight_hh_l0</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">parameters_noise</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias_ih_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias_ih_l0</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">parameters_noise</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias_hh_l0</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias_hh_l0</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">parameters_noise</span>

    <span class="c1">#evolving &amp; mutating hyperparameters</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">new_agent</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">learning_rate</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">learning_rate_noise</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">new_agent</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">),</span> <span class="mf">0.01</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">new_agent</span><span class="o">.</span><span class="n">discount_factor</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">discount_factor</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">discount_factor</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">discount_factor_noise</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">discount_factor</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">new_agent</span><span class="o">.</span><span class="n">discount_factor</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">),</span> <span class="mf">0.99</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">new_agent</span><span class="o">.</span><span class="n">state_value_estimate_cost</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">state_value_estimate_cost</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">state_value_estimate_cost</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">state_value_estimate_cost_noise</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">state_value_estimate_cost</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">new_agent</span><span class="o">.</span><span class="n">discount_factor</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="mf">0.7</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">new_agent</span><span class="o">.</span><span class="n">entropy_cost</span> <span class="o">=</span> <span class="n">agent2</span><span class="o">.</span><span class="n">entropy_cost</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">entropy_cost</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">entropy_cost_noise</span>
    <span class="n">new_agent</span><span class="o">.</span><span class="n">entropy_cost</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">new_agent</span><span class="o">.</span><span class="n">discount_factor</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">),</span> <span class="mf">0.05</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">new_agent</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">update_population</span></code>, which deletes random individuals at the end of the generation and evaluates and adds new ones.</p></li>
</ul>
<p>Your task is to complete this function!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update_population</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">,</span> <span class="n">population</span><span class="p">,</span> <span class="n">parents_population</span><span class="p">,</span> <span class="n">best_score</span><span class="p">,</span> <span class="n">new_generation_new_individuals</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Updates population with new individuals which are the result of crossing over and mutation of two parents agents.</span>
<span class="sd">    Removes the same amount of random agents from the population.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - env (HarlowExperimentEnv): environment.</span>
<span class="sd">    - optimizer_func (torch.Optim): optimizer to use for training.</span>
<span class="sd">    - population (list): current population which consists of tuples (agent, score).</span>
<span class="sd">    - parents_population (list) : parents individuals (part of current population) for creating new individuals.</span>
<span class="sd">    - best_score (int): the best score for the individual in the population registered so far.</span>
<span class="sd">    - new_generation_new_individuals (int, default = 5): the number of individuals to create (and the old ones to remove).</span>
<span class="sd">    """</span>
    <span class="c1">###################################################################</span>
    <span class="c1">## Fill out the following then remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: complete update of the population logic."</span><span class="p">)</span>
    <span class="c1">###################################################################</span>

    <span class="c1">#create new individuals</span>
    <span class="n">new_individuals</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_generation_new_individuals</span><span class="p">):</span>
        <span class="n">agent1</span><span class="p">,</span> <span class="n">agent2</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">new_agent</span> <span class="o">=</span> <span class="n">create_new_agent</span><span class="p">(</span><span class="n">agent1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">agent2</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">)</span>
        <span class="c1">#evaluate whether best score has increased</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">best_score</span><span class="p">)</span>
        <span class="n">new_individuals</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">new_agent</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>

    <span class="c1">#remove random old individuals</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_generation_new_individuals</span><span class="p">):</span>
        <span class="n">population</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">population</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">population</span> <span class="o">+</span> <span class="n">new_individuals</span><span class="p">,</span> <span class="n">best_score</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="k">def</span> <span class="nf">update_population</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">,</span> <span class="n">population</span><span class="p">,</span> <span class="n">parents_population</span><span class="p">,</span> <span class="n">best_score</span><span class="p">,</span> <span class="n">new_generation_new_individuals</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Updates population with new individuals which are the result of crossing over and mutation of two parents agents.</span>
<span class="sd">    Removes the same amount of random agents from the population.</span>

<span class="sd">    Inputs:</span>
<span class="sd">    - env (HarlowExperimentEnv): environment.</span>
<span class="sd">    - optimizer_func (torch.Optim): optimizer to use for training.</span>
<span class="sd">    - population (list): current population which consists of tuples (agent, score).</span>
<span class="sd">    - parents_population (list) : parents individuals (part of current population) for creating new individuals.</span>
<span class="sd">    - best_score (int): the best score for the individual in the population registered so far.</span>
<span class="sd">    - new_generation_new_individuals (int, default = 5): the number of individuals to create (and the old ones to remove).</span>
<span class="sd">    """</span>

    <span class="c1">#create new individuals</span>
    <span class="n">new_individuals</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_generation_new_individuals</span><span class="p">):</span>
        <span class="n">agent1</span><span class="p">,</span> <span class="n">agent2</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="n">parents_population</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">new_agent</span> <span class="o">=</span> <span class="n">create_new_agent</span><span class="p">(</span><span class="n">agent1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">agent2</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">new_agent</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">)</span>
        <span class="c1">#evaluate whether best score has increased</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">best_score</span><span class="p">)</span>
        <span class="n">new_individuals</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">new_agent</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>

    <span class="c1">#remove random old individuals</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_generation_new_individuals</span><span class="p">):</span>
        <span class="n">population</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">population</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">population</span> <span class="o">+</span> <span class="n">new_individuals</span><span class="p">,</span> <span class="n">best_score</span>
</pre></div>
</div>
</div>
</div>
<p>In order to get the desired results of the genetic algorithm, one should wait for the population to evolve enough :) Unfortunately, we don’t have that much time, thus in order to see the initial results we will only run for 1 generation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#selection - random</span>
<span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">#define environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">HarlowExperimentEnv</span><span class="p">()</span>

<span class="c1">#define agent and optimizer</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ActorCritic</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">optimizer_func</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span>

<span class="c1">#GA consts</span>
<span class="n">num_generations</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">tournament_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">parents_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">new_generation_new_individuals</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">mean_population_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#create population</span>
<span class="n">population</span><span class="p">,</span> <span class="n">best_score</span> <span class="o">=</span> <span class="n">create_initial_population</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">)</span>

<span class="k">for</span> <span class="n">generation</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_generations</span><span class="p">):</span>

  <span class="c1">#at first, select top individuals from population (of size tournament_size) (selectivy happens here)</span>
  <span class="n">sorted_population</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="n">tournament_population</span> <span class="o">=</span> <span class="n">sorted_population</span><span class="p">[:</span><span class="n">tournament_size</span><span class="p">]</span>

  <span class="c1">#random choice of parents from tournament population</span>
  <span class="n">parents_population</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="n">tournament_population</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">parents_size</span><span class="p">)</span>

  <span class="c1">#update population</span>
  <span class="n">population</span><span class="p">,</span> <span class="n">best_score</span> <span class="o">=</span> <span class="n">update_population</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">,</span> <span class="n">population</span><span class="p">,</span> <span class="n">parents_population</span><span class="p">,</span> <span class="n">best_score</span><span class="p">)</span>

  <span class="n">mean_population_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">agent_score</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">agent_score</span> <span class="ow">in</span> <span class="n">population</span><span class="p">]))</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Generation </span><span class="si">{</span><span class="n">generation</span><span class="si">}</span><span class="s2">, mean population score: </span><span class="si">{</span><span class="n">mean_population_scores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">, best score: </span><span class="si">{</span><span class="n">best_score</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Generation: 0, mean population score: 49.72, best score: 100
</pre></div>
</div>
</div>
</div>
<p>You should be able to see that the mean population score is <code class="docutils literal notranslate"><span class="pre">49.72</span></code> and the best score is <code class="docutils literal notranslate"><span class="pre">100</span></code>. If you change <code class="docutils literal notranslate"><span class="pre">num_generations</span></code> to 800 in the previous code cell, the plot for the mean score in the population will roughly take the following form.</p>
<p><img alt="Picture which depicts the plot of mean scores per generation." src="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D4_Macrolearning/static/evolution.png?raw=true"/></p>
<p>In the very start of the tutorial, we have downloaded the best agent we obtained from the training on 800 generations (you can get the same if you add extra infrastructure code to “catch” an agent as soon as its score reaches some threshold value; in this case, it can be even set up to 200). In the next section we are going to compare its performance with a randomly initialized agent and observe that, indeed, during evolutionary processes we developed agents with parameters that are able to learn more quickly.</p>
<section id="id4">
<h3>Submit your feedback<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_genetic_algorithm")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="think-evolutionary-theories-in-code">
<h2>Think!: Evolutionary Theories in Code<a class="headerlink" href="#think-evolutionary-theories-in-code" title="Permalink to this heading">#</a></h2>
<p>In this section we have observed how the Baldwin effect evolves individuals’ parameters so that they quickly learn. We would like to propose you to think about other evolutionary biology ideas. For example, what would this process look like if we took a <a class="reference external" href="https://en.wikipedia.org/wiki/Lamarckism">Lamarckian approach</a>? Discuss what should be changed in the implementation to use these ideas (simply put, what parts of code should be change to reflect their essence)?</p>
<p>Take time to think and then discuss as a group.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#to_remove explanation</span>

<span class="sd">"""</span>
<span class="sd">Discussion: What should be changed in the implementation approach (code base) to reflect Lamarckian evolution?</span>

<span class="sd">For Lamarckian evolution, we might want to change the base parameters of the agent each time it learns a new task; this way the learned benefits are inherited by the next generation."""</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<section id="id5">
<h3>Submit your feedback<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_evolutionary_theories_in_code")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-4-newbie-experienced-bird">
<h1>Section 4: Newbie &amp; Experienced Bird<a class="headerlink" href="#section-4-newbie-experienced-bird" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing to here from start of tutorial: 50 minutes</em></p>
<p>This section proposes comparison of the evolutionary trained (found) agent which performs the Harlow experiment with the previously-mentioned model which is initialized from scratch (and thus only trains on the given task but does not benefit from meta-learning).</p>
<p>Make sure you execute this cell to observe the plot!</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Make sure you execute this cell to observe the plot!</span>
<span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">#define environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">HarlowExperimentEnv</span><span class="p">()</span>

<span class="c1">#define newbie agent and optimizer</span>
<span class="n">newbie</span> <span class="o">=</span> <span class="n">ActorCritic</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">optimizer_func</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">RMSprop</span>

<span class="c1">#calculate newbie's score</span>
<span class="n">total_score</span><span class="p">,</span> <span class="n">newbie_scores</span> <span class="o">=</span> <span class="n">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">newbie</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total score of newbie agent is </span><span class="si">{</span><span class="n">total_score</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>

<span class="c1">#define experienced agent</span>
<span class="n">experienced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"Evolution.pt"</span><span class="p">)</span>

<span class="c1">#calculate experienced's score</span>
<span class="n">total_score</span><span class="p">,</span> <span class="n">experienced_scores</span> <span class="o">=</span> <span class="n">evaluate_individual</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">experienced</span><span class="p">,</span> <span class="n">optimizer_func</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total score of experienced agent is </span><span class="si">{</span><span class="n">total_score</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>

<span class="n">plot_two_boxplot_scores</span><span class="p">(</span><span class="n">newbie_scores</span><span class="p">,</span> <span class="n">experienced_scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total score of newbie agent is 54.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total score of experienced agent is 180.
</pre></div>
</div>
<img alt="../../../_images/2ca689296097c0a002a4c39685429b174d15f54dd7af16bd38ba4c64644543d0.png" src="../../../_images/2ca689296097c0a002a4c39685429b174d15f54dd7af16bd38ba4c64644543d0.png"/>
</div>
</div>
<section id="why-biology-needs-meta-learning">
<h2>Why biology needs meta-learning<a class="headerlink" href="#why-biology-needs-meta-learning" title="Permalink to this heading">#</a></h2>
<p>If aspects of the environment change with time, previously learnt hard-coded strategies might not work anymore. Still, as in the previous tutorial, these changes share similar features across the tasks. The Harlow experiment illustrates that though there is no direct instruction on how to obtain the maximum possible reward, and the environment’s state changes with each new pair of the objects, the agent is still able to capture the meta-structure of the experiment - the reward is associated with the object, not its relative placement. And only one trial is needed to identify which of two new objects is rewarded.</p>
<section id="id6">
<h3>Submit your feedback<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="c1"># content_review(f"{feedback_prefix}_newbie_experienced")</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-5-an-alternative-model-of-how-the-brain-solves-the-harlow-experiment">
<h1>Section 5: An alternative model of how the brain solves the Harlow experiment<a class="headerlink" href="#section-5-an-alternative-model-of-how-the-brain-solves-the-harlow-experiment" title="Permalink to this heading">#</a></h1>
<p>There are no code snippets or exercises in this section. However, you can watch the video to learn about an alternative approach to biological learning, one that shows how learning within a single brain can work on the Harlow experiment.</p>
<section id="video-4-an-alternative-model">
<h2>Video 4: An Alternative Model<a class="headerlink" href="#video-4-an-alternative-model" title="Permalink to this heading">#</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h1>
<p><em>Estimated timing of tutorial: 60 minutes</em></p>
<p>Here is a summary of what we’ve learned:</p>
<ol class="arabic simple">
<li><p>The Baldwin effect says that evolution will select organisms that are good at learning.</p></li>
<li><p>We can use evolutionary/genetic algorithms to replicate this process. This is the “outer loop” of a meta-learning problem</p></li>
<li><p>To be more biologically plausible, we can use reinforcement learning as the inner loop.</p></li>
<li><p>This process creates agents that can quickly find the rewarding object in a Harlow experiment.</p></li>
</ol>
</section>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tutorials/W2D4_Macrolearning/instructor"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</article>
<footer class="bd-footer-article">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W2D4_Tutorial3.html" id="prev-link" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 3: Meta-learning</p>
</div>
</a>
<a class="right-next" href="W2D4_Tutorial5.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Tutorial 5: Replay</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="toc-item">
<div class="tocsection onthispage">
<i class="fa-solid fa-list"></i> On this page
</div>
<nav class="page-toc" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 4: Biological meta reinforcement learning
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-and-import-feedback-gadget">
     Install and import feedback gadget
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#imports">
     Imports
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-retrieval">
     Data retrieval
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu">
     Set device (GPU or CPU).
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-0-let-s-play-a-game">
   Section 0: Let’s play a game!
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-reinforcement-learning-task">
     Video 1: Reinforcement Learning Task
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-harlow-experiment-advantage-actor-critic-a2c-agent">
   Section 1: Harlow Experiment &amp; Advantage Actor Critic (A2C) Agent
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-reinforcement-learning-on-the-harlow-task">
     Video 2: Reinforcement Learning on the Harlow Task
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#submit-your-feedback">
     Submit your feedback
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
     Submit your feedback
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-baldwin-effect">
   Section 3: Baldwin Effect
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-baldwin-effect">
     Video 3: Baldwin Effect
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
     Submit your feedback
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-agent-s-rate-to-learn">
     Coding Exercise 1: Agent’s Rate to Learn
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
       Submit your feedback
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-genetic-algorithm">
     Coding Exercise 2: Genetic Algorithm
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id4">
       Submit your feedback
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-evolutionary-theories-in-code">
     Think!: Evolutionary Theories in Code
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id5">
       Submit your feedback
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-newbie-experienced-bird">
   Section 4: Newbie &amp; Experienced Bird
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#why-biology-needs-meta-learning">
     Why biology needs meta-learning
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id6">
       Submit your feedback
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-an-alternative-model-of-how-the-brain-solves-the-harlow-experiment">
   Section 5: An alternative model of how the brain solves the Harlow experiment
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-an-alternative-model">
     Video 4: An Alternative Model
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<footer class="bd-footer-content">
<div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
<div class="footer-item">
<p class="component-author">
By Neuromatch
</p>
</div>
<div class="footer-item">
</div>
<div class="footer-item">
<p class="last-updated">
Last updated on None.<br/>
</p>
</div>
<div class="footer-item">
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</div>
</div>
</div>
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>
</body>
</html>