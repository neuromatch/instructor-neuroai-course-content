
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="Docutils 0.18.1: http://docutils.sourceforge.net/" name="generator"/>
<title>Tutorial 4: Representational geometry &amp; noise — NeuroAI (instructor's version)</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css">
<link href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" rel="stylesheet" type="text/css">
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94" rel="preload"/>
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
<script>let toggleHintShow = 'Click to show';</script>
<script>let toggleHintHide = 'Click to hide';</script>
<script>let toggleOpenOnPrint = 'true';</script>
<script src="../../../_static/togglebutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
<script src="../../../_static/design-tabs.js"></script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script type="application/vnd.jupyter.widget-state+json">{"state": {"eb5e119e88e84fc3a066a2f61cb719a0": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "50e47972d2594f4bb7cd45f858fada19": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_eb5e119e88e84fc3a066a2f61cb719a0", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "If you want to download the slides: https://osf.io/download/qmv5r/\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.IFrame at 0x7f15ccf95c70>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://mfr.ca-1.osf.io/render?url=https://osf.io/qmv5r/?direct%26mode=render%26action=download%26mode=render\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}], "tabbable": null, "tooltip": null}}}, "version_major": 2, "version_minor": 0}</script>
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script crossorigin="anonymous" data-jupyter-widgets-cdn="https://cdn.jsdelivr.net/npm/" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@1.0.6/dist/embed-amd.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/W1D3_ComparingArtificialAndBiologicalNetworks/instructor/W1D3_Tutorial4';</script>
<link href="../../../_static/ai-logo.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index">
<link href="../../../search.html" rel="search" title="Search"/>
<link href="../../W1D5_Microcircuits/chapter_title.html" rel="next" title="Microcircuits"/>
<link href="W1D3_Tutorial3.html" rel="prev" title="Tutorial 3: Statistical inference on representational geometries"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></link></link></link></link></link></link></link></head>
<body data-default-mode="" data-offset="180" data-spy="scroll" data-target="#bd-toc-nav">
<a class="skip-link" href="#main-content">Skip to main content</a>
<input class="sidebar-toggle" id="__primary" name="__primary" type="checkbox"/>
<label class="overlay overlay-primary" for="__primary"></label>
<input class="sidebar-toggle" id="__secondary" name="__secondary" type="checkbox"/>
<label class="overlay overlay-secondary" for="__secondary"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
</div>
<nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
<label class="sidebar-toggle primary-toggle" for="__primary">
<span class="fa-solid fa-bars"></span>
</label>
<div id="navbar-start">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/ai-logo.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/ai-logo.png"/>
</a>
</div>
<div class="col-lg-9 navbar-header-items">
<div class="mr-auto" id="navbar-center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D1_Generalization/chapter_title.html">
                        Generalization (W1D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D2_ComparingTasks/chapter_title.html">
                        Comparing Tasks (W1D2)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Comparing Artificial And Biological Networks (W1D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D5_Microcircuits/chapter_title.html">
                        Microcircuits (W1D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_Macrocircuits/chapter_title.html">
                        Macrocircuits (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_NeuroSymbolicMethods/chapter_title.html">
                        Neuro Symbolic Methods (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D3_Microlearning/chapter_title.html">
                        Microlearning (W2D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D4_Macrolearning/chapter_title.html">
                        Macrolearning (W2D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D5_Mysteries/chapter_title.html">
                        Mysteries (W2D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Project materials
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/impact_talks.html">
                        Impact Talks
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/mentorship_program.html">
                        Mentorship Program
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_features.html">
                        Career Features
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_panels.html">
                        Career Panels
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div id="navbar-end">
<div class="navbar-end-item navbar-persistent--container">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="navbar-persistent--mobile">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<label class="sidebar-toggle secondary-toggle" for="__secondary">
<span class="fa-solid fa-outdent"></span>
</label>
</div>
</nav>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D1_Generalization/chapter_title.html">
                        Generalization (W1D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D2_ComparingTasks/chapter_title.html">
                        Comparing Tasks (W1D2)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Comparing Artificial And Biological Networks (W1D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D5_Microcircuits/chapter_title.html">
                        Microcircuits (W1D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_Macrocircuits/chapter_title.html">
                        Macrocircuits (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_NeuroSymbolicMethods/chapter_title.html">
                        Neuro Symbolic Methods (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D3_Microlearning/chapter_title.html">
                        Microlearning (W2D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D4_Macrolearning/chapter_title.html">
                        Macrolearning (W2D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D5_Mysteries/chapter_title.html">
                        Mysteries (W2D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Project materials
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/impact_talks.html">
                        Impact Talks
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/mentorship_program.html">
                        Mentorship Program
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_features.html">
                        Career Features
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/professional_development/career_panels.html">
                        Career Panels
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="sidebar-start-items sidebar-primary__section">
<div class="sidebar-start-items__item">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/ai-logo.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/ai-logo.png"/>
</a>
</div>
<div class="sidebar-start-items__item">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="sidebar-start-items__item"><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item navbar-nav active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Schedule/schedule_intro.html">Schedule</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/daily_schedules.html">General schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/shared_calendars.html">Shared calendars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/timezone_widget.html">Timezone widget</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../TechnicalHelp/tech_intro.html">Technical Help</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">Using jupyterbook</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">Using Google Colab</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">Using Kaggle</a></li>
</ul>
</input></li>
<li class="toctree-l2"><a class="reference internal" href="../../TechnicalHelp/Discord.html">Using discord</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">Quick links and policies</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Foundations</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D1_Generalization/chapter_title.html">Generalization (W1D1)</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/instructor/W1D1_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/instructor/W1D1_Tutorial1.html">Tutorial 1: Generalization in AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/instructor/W1D1_Tutorial2.html">Tutorial 2: Generalization in Neuroscience</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/instructor/W1D1_Tutorial3.html">Tutorial 3: Generalization in Cognitive Science</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_Generalization/further_reading.html">References</a></li>
</ul>
</input></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D2_ComparingTasks/chapter_title.html">Comparing Tasks (W1D2)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/instructor/W1D2_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/instructor/W1D2_Tutorial1.html">Tutorial 1: Task definition, application, relations and impacts on generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/instructor/W1D2_Tutorial2.html">Tutorial 2: Contrastive learning for object recognition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/instructor/W1D2_Tutorial3.html">Tutorial 3: Reinforcement learning across temporal scales</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ComparingTasks/further_reading.html">References</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../chapter_title.html">Comparing Artificial And Biological Networks (W1D3)</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="W1D3_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="W1D3_Tutorial1.html">Tutorial 1: Generalization and representational geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="W1D3_Tutorial2.html">Tutorial 2: Computation as transformation of representational geometries</a></li>
<li class="toctree-l2"><a class="reference internal" href="W1D3_Tutorial3.html">Tutorial 3: Statistical inference on representational geometries</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Tutorial 4: Representational geometry &amp; noise</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Architectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D5_Microcircuits/chapter_title.html">Microcircuits (W1D5)</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/instructor/W1D5_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/instructor/W1D5_Tutorial1.html">Tutorial 1: Sparsity and Sparse Coding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/instructor/W1D5_Tutorial2.html">Tutorial 2: Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_Microcircuits/instructor/W1D5_Tutorial3.html">Tutorial 3: Attention</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D1_Macrocircuits/chapter_title.html">Macrocircuits (W2D1)</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/instructor/W2D1_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/instructor/W2D1_Tutorial1.html">Tutorial 1: Depth vs width</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/instructor/W2D1_Tutorial2.html">Tutorial 2: Double descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/instructor/W2D1_Tutorial3.html">Tutorial 3: Neural network modularity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_Macrocircuits/further_reading.html">Suggested further readings</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/chapter_title.html">Neuro Symbolic Methods (W2D2)</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/instructor/W2D2_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/instructor/W2D2_Tutorial1.html">Tutorial 1: Basic operations of vector symbolic algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/instructor/W2D2_Tutorial2.html">Tutorial 2: Learning with structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/instructor/W2D2_Tutorial3.html">Tutorial 3: Representations in continuous space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_NeuroSymbolicMethods/further_reading.html">Suggested further readings</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D3_Microlearning/chapter_title.html">Microlearning (W2D3)</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/instructor/W2D3_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/instructor/W2D3_Tutorial1.html">Tutorial 1: Microlearning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_Microlearning/further_reading.html">Suggested further readings</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D4_Macrolearning/chapter_title.html">Macrolearning (W2D4)</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/instructor/W2D4_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/instructor/W2D4_Tutorial1.html">Tutorial 1: The problem of changing data distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/instructor/W2D4_Tutorial2.html">Tutorial 2: Continual learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/instructor/W2D4_Tutorial3.html">Tutorial 3: Meta-learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/instructor/W2D4_Tutorial4.html">Tutorial 4: Biological meta reinforcement learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/instructor/W2D4_Tutorial5.html">Tutorial 5: Replay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_Macrolearning/further_reading.html">Suggested further readings</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Mysteries</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D5_Mysteries/chapter_title.html">Mysteries (W2D5)</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/instructor/W2D5_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/instructor/W2D5_Tutorial1.html">Tutorial 1: Consciousness</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/instructor/W2D5_Tutorial2.html">Tutorial 2: Ethics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D5_Mysteries/instructor/W2D5_Outro.html">Outro</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project Booklet</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/docs/project_guidance.html">Daily guide for projects</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../projects/docs/datasets_overview.html">Project materials</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/Macrocircuits.html">Macrocircuits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/Microlearning.html">Microlearning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/project-notebooks/ComparingNetworks.html">Comparing Networks</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Professional Development</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/impact_talks.html">Impact Talks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/mentorship_program.html">Professional developemnt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/career_features.html">Career Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/professional_development/career_panels.html">Career Panels</a></li>
</ul>
</div>
</nav>
</div>
</div>
<div class="sidebar-end-items sidebar-primary__section">
<div class="sidebar-end-items__item">
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content">
<div class="sbt-scroll-pixel-helper"></div>
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="sidebar-toggle primary-toggle btn btn-sm" data-placement="right" data-toggle="tooltip" for="__primary" title="Toggle primary sidebar">
<span class="fa-solid fa-bars"></span>
</label>
</div>
<div class="header-article__right">
<div class="dropdown dropdown-launch-buttons">
<button aria-expanded="false" aria-label="Launch interactive content" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-rocket"></i>
</button>
<ul class="dropdown-menu">
</ul>
</div>
<button class="btn btn-sm" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="btn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="dropdown dropdown-repository-buttons">
<button aria-expanded="false" aria-label="Source repositories" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fab fa-github"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/neuromatch/instructor-neuroai-course-content" target="_blank" title="Source repository">
<span class="btn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="btn__text-container">repository</span>
</a>

<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/neuromatch/instructor-neuroai-course-content/issues/new?title=Issue%20on%20page%20%2Ftutorials/W1D3_ComparingArtificialAndBiologicalNetworks/instructor/W1D3_Tutorial4.html&amp;body=Your%20issue%20content%20here." target="_blank" title="Open an issue">
<span class="btn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="btn__text-container">open issue</span>
</a>

</li></li></ul>
</div>
<div class="dropdown dropdown-download-buttons">
<button aria-expanded="false" aria-label="Download this page" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-download"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W1D3_ComparingArtificialAndBiologicalNetworks/instructor/W1D3_Tutorial4.ipynb" target="_blank" title="Download source file">
<span class="btn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="btn__text-container">.ipynb</span>
</a>

<li>
<button class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="btn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="btn__text-container">.pdf</span>
</button>

</li></li></ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" data-placement="left" data-toggle="tooltip" for="__secondary" title="Toggle secondary sidebar">
<span class="fa-solid fa-list"></span>
</label>
</div>
</div>
</div>
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 4: Representational geometry &amp; noise</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 4: Representational geometry &amp; noise
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#import-dependencies">
     Import dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-simulate-neural-data-and-visualize-noise-distributions">
   Section 1: Simulate neural data and visualize noise distributions
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1">
     Coding Exercise 1
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-distances-and-discriminability-between-a-pair-of-stimuli">
   Section 2: Distances and discriminability between a pair of stimuli
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2">
     Coding exercise 2
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#discussion">
     Discussion
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-cross-validated-distances-prevent-the-inflation-of-distance-estimates-by-noise">
   Section 3: Cross-validated distances prevent the inflation of distance estimates by noise
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-the-johnson-lindenstrauss-lemma">
   Section 4: The Johnson-Lindenstrauss Lemma
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3">
     Coding exercise 3
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
     Discussion
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
     Summary
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<article class="bd-article" role="main">
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-4-representational-geometry-noise">
<h1>Tutorial 4: Representational geometry &amp; noise<a class="headerlink" href="#tutorial-4-representational-geometry-noise" title="Permalink to this heading">#</a></h1>
<p><strong>Week 1, Day 3: Comparing Artificial And Biological Networks</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Wenxuan Guo</p>
<p><strong>Content reviewers:</strong> Samuele Bolotta, Yizhou Chen, RyeongKyung Yoon, Ruiyi Zhang, Lily Chamakura, Hlib Solodzhuk</p>
<p><strong>Production editors:</strong> Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk, Patrick Mineault</p>
<p>Acknowledgments: the tutorial outline was written by Heiko Schütt. The content was greatly improved by discussions with Heiko, Hlib, and Alish, and the insightful illustrations presented in the paper by Walther et al. (2016)</p>
<p><a href="https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D3_ComparingArtificialAndBiologicalNetworks/student/W1D3_Tutorial4.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W1D3_ComparingArtificialAndBiologicalNetworks/student/W1D3_Tutorial4.ipynb" target="_parent"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this heading">#</a></h1>
<p>Estimated timing of tutorial: 45 minutes.</p>
<p>By completing this tutorial, you will gain insights into:</p>
<ol class="arabic simple">
<li><p>Generating neural data with varied noise distributions. This section will guide you through the process of creating neural data, introducing variability in noise distributions. This step will illustrate how different noise levels can affect data representation and subsequent analyses.</p></li>
<li><p>Understanding distance metrics - Euclidean and Mahalanobis. Each metric offers unique insights into the geometry of the data.</p></li>
<li><p>Exploring the relationship between distance metrics and binary classification performance. This part of the tutorial emphasizes the relationship between distance measurements and the performance of binary classification tasks on a given pair of stimuli. Understanding this relationship will help us develop more accurate and robust classification models.</p></li>
<li><p>Addressing positively biased estimators through cross-validation. We will explore the concept of positively biased estimators that arise when computing distances based on noisy pattern estimates. You will learn how cross-validation techniques can be employed to correct this bias and obtain a more accurate estimate of the underlying noise-free distance.</p></li>
<li><p>Using random projections to achieve unbiased distance estimates (Johnson–Lindenstrauss Lemma). This section introduces the Johnson–Lindenstrauss lemma, which suggests that random projections maintain the integrity of distance estimates in a lower-dimensional space. This concept is crucial for reducing dimensionality while preserving the relational structure of the data.</p></li>
</ol>
<p>Throughout this tutorial, we will adhere to the notational conventions established by <a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/26707889/">Walther et al. (2016)</a> for all discussed distance measures.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "50e47972d2594f4bb7cd45f858fada19"}</script></div>
</div>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h1>
<section id="install-dependencies">
<h2>Install dependencies<a class="headerlink" href="#install-dependencies" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install dependencies</span>

<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>-q<span class="w"> </span>numpy<span class="w"> </span>xarray<span class="w"> </span>scipy<span class="w"> </span>scikit-learn<span class="w"> </span>matplotlib<span class="w"> </span>seaborn<span class="w"> </span>tqdm<span class="w"> </span>rsatoolbox
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="import-dependencies">
<h2>Import dependencies<a class="headerlink" href="#import-dependencies" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Import dependencies</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">xarray</span> <span class="k">as</span> <span class="nn">xr</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="kn">import</span> <span class="n">LinearDiscriminantAnalysis</span>

<span class="kn">import</span> <span class="nn">rsatoolbox.data</span> <span class="k">as</span> <span class="nn">rsd</span>
<span class="kn">import</span> <span class="nn">rsatoolbox.rdm</span> <span class="k">as</span> <span class="nn">rsr</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">squareform</span>

<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.axes_grid1</span> <span class="kn">import</span> <span class="n">make_axes_locatable</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>
<span class="c1"># @markdown</span>

<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">'matplotlib.font_manager'</span><span class="p">)</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">True</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina' # perfrom high definition rendering for images and plots
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions</span>
<span class="c1"># @markdown</span>

<span class="k">def</span> <span class="nf">compute_classifier_acc</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">neural_data</span><span class="p">,</span> <span class="n">cov</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Compute the accuracy of a classifier for all combinations of stimulus pairs in the neural data.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - neural_data (xarray.DataArray): neural data with dimensions "stim" and "neuron".</span>

<span class="sd">    Returns:</span>
<span class="sd">    - acc (xarray.DataArray): Accuracy matrix with dimensions "stim1" and "stim2".</span>
<span class="sd">    """</span>
    <span class="n">n_stimuli</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">neural_data</span><span class="o">.</span><span class="n">stim</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
    <span class="n">coords</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"stim1"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_stimuli</span><span class="p">),</span> <span class="s2">"stim2"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_stimuli</span><span class="p">)}</span>
    <span class="n">acc_init</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_stimuli</span><span class="p">,</span> <span class="n">n_stimuli</span><span class="p">])</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">np2xr</span><span class="p">(</span><span class="n">acc_init</span><span class="p">,</span> <span class="n">coords</span><span class="p">)</span>
    <span class="n">whitening_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">cov</span><span class="p">))</span>
    <span class="n">whitened_data</span> <span class="o">=</span> <span class="n">neural_data</span><span class="o">.</span><span class="n">values</span> <span class="o">@</span> <span class="n">whitening_matrix</span>
    <span class="n">neural_data</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">(</span><span class="n">whitened_data</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">neural_data</span><span class="o">.</span><span class="n">dims</span><span class="p">,</span> <span class="n">coords</span><span class="o">=</span><span class="n">neural_data</span><span class="o">.</span><span class="n">coords</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i_stim_idx</span><span class="p">,</span> <span class="n">j_stim_idx</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">combinations</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_stimuli</span><span class="p">),</span><span class="mi">2</span><span class="p">)):</span>
        <span class="n">i_stim_pattern</span> <span class="o">=</span> <span class="n">neural_data</span><span class="o">.</span><span class="n">sel</span><span class="p">({</span><span class="s2">"stim"</span><span class="p">:</span><span class="n">i_stim_idx</span><span class="p">})</span> <span class="c1"># xarray cannot select two non-unique indices at the same time</span>
        <span class="n">j_stim_pattern</span> <span class="o">=</span> <span class="n">neural_data</span><span class="o">.</span><span class="n">sel</span><span class="p">({</span><span class="s2">"stim"</span><span class="p">:</span><span class="n">j_stim_idx</span><span class="p">})</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">i_stim_pattern</span><span class="p">,</span> <span class="n">j_stim_pattern</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="s2">"stim"</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">stim</span><span class="o">.</span><span class="n">values</span>

        <span class="n">cv</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)):</span>
            <span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">])</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">])</span>
            <span class="n">acc</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i_stim_idx</span><span class="p">,</span> <span class="n">j_stim_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">pred</span><span class="o">==</span><span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]))</span>
        <span class="n">acc</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i_stim_idx</span><span class="p">,</span> <span class="n">j_stim_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i_stim_idx</span><span class="p">,</span> <span class="n">j_stim_idx</span><span class="p">]</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">acc</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">j_stim_idx</span><span class="p">,</span> <span class="n">i_stim_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i_stim_idx</span><span class="p">,</span> <span class="n">j_stim_idx</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">acc</span>

<span class="k">def</span> <span class="nf">np2xr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">coords</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Convert numpy arrays to labelled xarrays.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - data (numpy.ndarray): The data array.</span>
<span class="sd">    - coords (dict): A dictionary mapping dimension names to coordinate arrays.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - xarray.DataArray: The labelled xarray.</span>
<span class="sd">    """</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">coords</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">xarray</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">DataArray</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span> <span class="n">coords</span><span class="o">=</span><span class="n">coords</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xarray</span>

<span class="k">def</span> <span class="nf">generate_activity_patterns</span><span class="p">(</span><span class="n">n_stimuli</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Generate a stimulus x neural response matrix with reasonable Euclidean distances between different stimuli.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - n_stimuli (int): The number of stimuli.</span>
<span class="sd">    - n_neurons (int): The number of neurons.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - numpy.ndarray: The generated activity patterns of shape (n_stimuli, n_neurons).</span>
<span class="sd">    """</span>
    <span class="n">activity_patterns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_stimuli</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">n_neurons</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># scale the neural response for each stimulus to make the stimuli discriminable for the 100-neuron case</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_stimuli</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
        <span class="n">activity_patterns</span> <span class="o">*=</span> <span class="n">scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">activity_patterns</span>

<span class="k">def</span> <span class="nf">repeat_first_row</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""repeat the activity patterns for the first stimuli"""</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">arr</span><span class="p">,</span><span class="n">arr</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="k">def</span> <span class="nf">generate_activity_patterns_wrapper</span><span class="p">(</span><span class="n">n_stimuli</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""a wrapper for generating the activity patterns for a set of stimuli and labeling the data with xarray"""</span>
    <span class="n">activity_patterns</span> <span class="o">=</span> <span class="n">generate_activity_patterns</span><span class="p">(</span><span class="n">n_stimuli</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_neurons</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">get_correlated_covariance</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">find_contour_direction</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.06</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
        <span class="n">activity_patterns</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">activity_patterns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">v</span>
        <span class="n">l</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">activity_patterns</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">activity_patterns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">l</span><span class="p">])</span>
    <span class="n">activity_patterns</span> <span class="o">=</span> <span class="n">repeat_first_row</span><span class="p">(</span><span class="n">activity_patterns</span><span class="p">)</span>
    <span class="c1"># convert to xarray</span>
    <span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="s2">"stim"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_stimuli</span><span class="p">),</span> <span class="s2">"neuron"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)}</span>
    <span class="n">activity_patterns</span> <span class="o">=</span> <span class="n">np2xr</span><span class="p">(</span><span class="n">activity_patterns</span><span class="p">,</span> <span class="n">coords</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">activity_patterns</span>

<span class="k">def</span> <span class="nf">get_isotropic_covariance</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Generate an isotropic covariance matrix.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - n_neurons (int): The number of neurons.</span>
<span class="sd">    - noise_std (float): The standard deviation of the noise.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - numpy.ndarray: The isotropic covariance matrix of shape (n_neurons, n_neurons).</span>
<span class="sd">    """</span>
    <span class="n">noise_std</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">n_neurons</span><span class="o">==</span><span class="mi">2</span> <span class="k">else</span> <span class="mf">15.0</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise_std</span><span class="o">**</span><span class="mi">2</span>

<span class="k">def</span> <span class="nf">get_correlated_covariance</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Generate a correlated covariance matrix using a Radial Basis Function (RBF) kernel.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - n_neurons (int): The number of neurons.</span>
<span class="sd">    - length_scale (float): The length scale parameter for the RBF kernel.</span>
<span class="sd">    - noise_amplitude (float, optional): The amplitude of the noise. Default is 1.0.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - numpy.ndarray: The correlated covariance matrix of shape (n_neurons, n_neurons).</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">n_neurons</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="mf">1.4</span> <span class="c1"># make the neurons correlated</span>
    <span class="k">elif</span> <span class="n">n_neurons</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">sklearn.gaussian_process.kernels</span> <span class="kn">import</span> <span class="n">RBF</span>
        <span class="n">noise_amplitude</span> <span class="o">=</span> <span class="mf">50.0</span>
        <span class="n">neuron_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">neuron_idx</span><span class="p">)</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">cov</span><span class="o">*</span><span class="n">noise_amplitude</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span> <span class="o">*</span> <span class="mi">60</span>
    <span class="k">return</span> <span class="n">cov</span>

<span class="k">def</span> <span class="nf">find_contour_direction</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""find the ellipse direction for a particular covariance matrix."""</span>
    <span class="n">eigenvalues</span><span class="p">,</span> <span class="n">eigenvectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">eigenvalues</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">eigenvalues</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">v0</span><span class="o">=</span><span class="n">eigenvectors</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">v0</span>

<span class="k">def</span> <span class="nf">add_correlated_noise</span><span class="p">(</span><span class="n">activity_patterns</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">repetitions</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Add correlated noise to the activity patterns.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - activity_patterns (numpy.ndarray): The activity patterns of shape (n_stimuli, n_neurons).</span>
<span class="sd">    - cov (numpy.ndarray): The covariance matrix of shape (n_neurons, n_neurons).</span>
<span class="sd">    - repetitions (int, optional): The number of repetitions. Default is 5.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - numpy.ndarray: The activity patterns with added correlated noise of shape</span>
<span class="sd">      (n_stimuli * repetitions, n_neurons).</span>
<span class="sd">    """</span>

    <span class="n">n_stimuli</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="n">activity_patterns</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">activity_patterns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">activity_patterns</span><span class="p">,</span> <span class="n">repetitions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">),</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_stimuli</span> <span class="o">*</span> <span class="n">repetitions</span><span class="p">)</span>
    <span class="n">activity_patterns</span> <span class="o">+=</span> <span class="n">noise</span>

    <span class="k">return</span> <span class="n">activity_patterns</span>

<span class="k">def</span> <span class="nf">generate_noisy_activity_patterns_wrapper</span><span class="p">(</span><span class="n">activity_patterns</span><span class="p">,</span> <span class="n">repetitions</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Generate noisy activity patterns by adding isotropic and correlated noise to the given activity patterns.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - activity_patterns (numpy.ndarray): The original activity patterns of shape (n_stimuli, n_neurons).</span>
<span class="sd">    - repetitions (int): The number of measurement repetitions.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - isotropic_noised_data (xarray.DataArray): The activity patterns with added isotropic noise.</span>
<span class="sd">    - isotropic_cov (numpy.ndarray): The isotropic covariance matrix.</span>
<span class="sd">    - corr_noised_data (xarray.DataArray): The activity patterns with added correlated noise.</span>
<span class="sd">    - correlated_cov (numpy.ndarray): The correlated covariance matrix.</span>
<span class="sd">    """</span>
    <span class="n">n_stimuli</span><span class="p">,</span> <span class="n">n_neurons</span> <span class="o">=</span> <span class="n">activity_patterns</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">isotropic_cov</span> <span class="o">=</span> <span class="n">get_isotropic_covariance</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
    <span class="n">correlated_cov</span> <span class="o">=</span> <span class="n">get_correlated_covariance</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">length_scale</span><span class="o">=</span><span class="n">n_neurons</span><span class="o">/</span><span class="mi">20</span><span class="p">)</span>

    <span class="n">isotropic_noised_data</span> <span class="o">=</span> <span class="n">add_correlated_noise</span><span class="p">(</span><span class="n">activity_patterns</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">isotropic_cov</span><span class="p">,</span> <span class="n">repetitions</span> <span class="o">=</span> <span class="n">repetitions</span><span class="p">)</span>
    <span class="n">corr_noised_data</span> <span class="o">=</span> <span class="n">add_correlated_noise</span><span class="p">(</span><span class="n">activity_patterns</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">correlated_cov</span><span class="p">,</span> <span class="n">repetitions</span> <span class="o">=</span> <span class="n">repetitions</span><span class="p">)</span>

    <span class="n">coords</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"stim"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_stimuli</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repetitions</span><span class="p">),</span> <span class="s2">"neuron"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)}</span>
    <span class="n">isotropic_noised_data</span> <span class="o">=</span> <span class="n">np2xr</span><span class="p">(</span><span class="n">isotropic_noised_data</span><span class="p">,</span> <span class="n">coords</span><span class="p">)</span>
    <span class="n">corr_noised_data</span> <span class="o">=</span> <span class="n">np2xr</span><span class="p">(</span><span class="n">corr_noised_data</span><span class="p">,</span> <span class="n">coords</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">isotropic_noised_data</span><span class="p">,</span> <span class="n">isotropic_cov</span><span class="p">,</span> <span class="n">corr_noised_data</span><span class="p">,</span> <span class="n">correlated_cov</span>

<span class="k">def</span> <span class="nf">calc_rdm</span><span class="p">(</span><span class="n">neural_data</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">'euclidean'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize_by_channels</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Calculate the representational dissimilarity matrix (RDM) from neural data.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - neural_data (xarray.DataArray): Neural data with dimensions "stim" and "neuron".</span>
<span class="sd">    - method (str): Dissimilarity measure to use for calculating the RDM. Default is 'euclidean'.</span>
<span class="sd">    - noise (float or None): Noise level to add to the dissimilarities. Default is None.</span>
<span class="sd">    - normalize_by_channels (bool): rsatoolbox normalize (divide) the distances by the number of channels.</span>
<span class="sd">                                    set to False if raw squared euclidean distance is desired.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - rdm (pyrsa.rdm.rdms.RDMs): representational dissimilarity matrix.</span>
<span class="sd">    """</span>

    <span class="n">dataset</span> <span class="o">=</span> <span class="n">rsd</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">measurements</span><span class="o">=</span><span class="n">neural_data</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                          <span class="n">obs_descriptors</span><span class="o">=</span><span class="p">{</span><span class="s2">"stim"</span><span class="p">:</span> <span class="n">neural_data</span><span class="o">.</span><span class="n">stim</span><span class="o">.</span><span class="n">values</span><span class="p">},</span>
                          <span class="n">channel_descriptors</span><span class="o">=</span><span class="p">{</span><span class="s2">"neuron"</span><span class="p">:</span> <span class="n">neural_data</span><span class="o">.</span><span class="n">neuron</span><span class="o">.</span><span class="n">values</span><span class="p">})</span>
    <span class="n">rdm</span> <span class="o">=</span> <span class="n">rsr</span><span class="o">.</span><span class="n">calc_rdm</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span> <span class="n">descriptor</span><span class="o">=</span><span class="s1">'stim'</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">normalize_by_channels</span><span class="p">:</span>
        <span class="n">n_neurons</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">neural_data</span><span class="o">.</span><span class="n">neuron</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">rdm</span><span class="o">.</span><span class="n">dissimilarities</span> <span class="o">*=</span> <span class="n">n_neurons</span>
    <span class="k">return</span> <span class="n">rdm</span>

<span class="k">def</span> <span class="nf">vectorize_matrix</span><span class="p">(</span><span class="n">matrix</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Extract the upper triangular part of a symmetric matrix.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - matrix (xarray.DataArray): a symmetric matrix.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - numpy.ndarray: Vectorized values.</span>
<span class="sd">    """</span>
    <span class="n">n</span><span class="o">=</span><span class="n">matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">matrix</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">triu_indices</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="plotting-functions">
<h2>Plotting functions<a class="headerlink" href="#plotting-functions" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting functions</span>
<span class="c1"># @markdown</span>

<span class="c1"># visualize noise distributions</span>
<span class="k">def</span> <span class="nf">visualize_2d_noise</span><span class="p">(</span><span class="n">clean_dataset</span><span class="p">,</span> <span class="n">isotropic_cov</span><span class="p">,</span> <span class="n">correlated_cov</span><span class="p">,</span> <span class="n">isotropic_noised_data</span><span class="p">,</span> <span class="n">correlated_noised_data</span><span class="p">):</span>
    <span class="n">noise_dists</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"isotropic"</span><span class="p">,</span> <span class="s2">"correlated"</span><span class="p">]</span>
    <span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">noise_dists</span><span class="p">),</span> <span class="mi">2</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">135</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="s1">'constrained'</span><span class="p">)</span>
    <span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">stim_idx</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">marker_types</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"o"</span><span class="p">,</span> <span class="s2">"X"</span><span class="p">,</span> <span class="s2">"d"</span><span class="p">]</span>

    <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span>
    <span class="n">my_cmap</span> <span class="o">=</span> <span class="n">cmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">cmap</span><span class="o">.</span><span class="n">N</span><span class="p">))</span>
    <span class="n">my_cmap</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">cmap</span><span class="o">.</span><span class="n">N</span><span class="p">)</span>
    <span class="n">my_cmap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">(</span><span class="n">my_cmap</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i_noise</span><span class="p">,</span> <span class="n">noise_dist</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">noise_dists</span><span class="p">):</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">isotropic_cov</span> <span class="k">if</span> <span class="n">noise_dist</span><span class="o">==</span><span class="s1">'isotropic'</span> <span class="k">else</span> <span class="n">correlated_cov</span>
        <span class="n">r</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">r</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="mf">0.025</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">r</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="mf">0.025</span><span class="p">)</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">))</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i_stim</span><span class="p">,</span><span class="n">stim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clean_dataset</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">dict</span><span class="p">(</span><span class="n">stim</span><span class="o">=</span><span class="n">stim_idx</span><span class="p">)]):</span>
            <span class="n">zorder</span><span class="o">=</span><span class="mi">2</span> <span class="k">if</span> <span class="n">i_stim</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">stim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">+</span><span class="n">X</span><span class="p">,</span> <span class="n">stim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">+</span><span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">my_cmap</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="n">zorder</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">stim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">stim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">"darkorange"</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="n">marker_types</span><span class="p">[</span><span class="n">i_stim</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">clean_dataset</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i_stim</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">rf</span><span class="s2">"$s_</span><span class="si">{</span><span class="n">i_stim</span><span class="si">}</span><span class="s2">$"</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span><span class="n">y</span><span class="o">+</span><span class="mf">0.2</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">"darkorange"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i_stim</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                <span class="n">cs</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">stim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">+</span><span class="n">X</span><span class="p">,</span> <span class="n">stim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">+</span><span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">my_cmap</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">stim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">stim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">"darkorange"</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="n">marker_types</span><span class="p">[</span><span class="n">i_stim</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">clean_dataset</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">dx1</span><span class="p">,</span> <span class="n">dy1</span> <span class="o">=</span> <span class="n">clean_dataset</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">clean_dataset</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">dx2</span><span class="p">,</span> <span class="n">dy2</span> <span class="o">=</span> <span class="n">clean_dataset</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">clean_dataset</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">dx</span><span class="o">=</span><span class="n">dx1</span><span class="o">*</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="n">dy1</span><span class="o">*</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"dimgray"</span><span class="p">,</span> <span class="n">head_width</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">dx</span><span class="o">=</span><span class="n">dx2</span><span class="o">*</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="n">dy2</span><span class="o">*</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"dimgray"</span><span class="p">,</span> <span class="n">head_width</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>


        <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">noise_dist</span><span class="si">}</span><span class="se">\n</span><span class="s2">noise"</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
                <span class="n">xycoords</span><span class="o">=</span><span class="s1">'axes fraction'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'baseline'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

        <span class="c1"># noised_data</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">isotropic_noised_data</span> <span class="k">if</span> <span class="n">noise_dist</span><span class="o">==</span><span class="s1">'isotropic'</span> <span class="k">else</span> <span class="n">correlated_noised_data</span>
        <span class="n">stim_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">dict</span><span class="p">(</span><span class="n">stim</span><span class="o">=</span><span class="mi">0</span><span class="p">)]</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">stim_data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">stim_data</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">"darkblue"</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="n">marker_types</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'none'</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i_col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_cols</span><span class="p">):</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span> <span class="n">i_col</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"neuron 1"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span> <span class="n">i_col</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"neuron 2"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>

    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">"distance between two stimulus pairs"</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">),</span>
                    <span class="n">xycoords</span><span class="o">=</span><span class="s1">'axes fraction'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'baseline'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">r</span><span class="s2">"noisy samples of neural response to $s_0$"</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">),</span>
                    <span class="n">xycoords</span><span class="o">=</span><span class="s1">'axes fraction'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'baseline'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>


    <span class="c1"># we only plot the colorbar for the whole plot</span>
    <span class="c1"># because we set the covariance matrices for both isotropic and correlated noise such that their maximum probability density is around 0.16</span>
    <span class="n">cbar</span><span class="o">=</span><span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span><span class="n">fraction</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.04</span><span class="p">)</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">'probability density'</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">visualize_100d_noise</span><span class="p">(</span><span class="n">isotropic_cov</span><span class="p">,</span> <span class="n">correlated_cov</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="s1">'row'</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
    <span class="n">noise_dists</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"isotropic"</span><span class="p">,</span> <span class="s2">"correlated"</span><span class="p">]</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">5</span>

    <span class="k">for</span> <span class="n">i_noise</span><span class="p">,</span> <span class="n">noise_dist</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">noise_dists</span><span class="p">):</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">isotropic_cov</span> <span class="k">if</span> <span class="n">noise_dist</span><span class="o">==</span><span class="s1">'isotropic'</span> <span class="k">else</span> <span class="n">correlated_cov</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>

        <span class="c1"># plot the covariance matrix</span>
        <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i_noise</span><span class="p">])</span>
        <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s1">'right'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">'5%'</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i_noise</span><span class="p">]</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'bone'</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">'vertical'</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">i_noise</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">noise_dist</span><span class="o">+</span><span class="s2">" noise"</span><span class="p">)</span>

        <span class="c1"># plot the noise samples</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">noise</span><span class="p">:</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i_noise</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i_noise</span><span class="p">]</span><span class="o">.</span><span class="n">set_box_aspect</span><span class="p">(</span><span class="mf">0.8</span><span class="p">)</span>

        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i_noise</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"neuron index"</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i_noise</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"neuron index"</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i_noise</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"neuron index"</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i_noise</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"noise amplitude"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">"covariance</span><span class="se">\n</span><span class="s2">matrix"</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">xycoords</span><span class="o">=</span><span class="s1">'axes fraction'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'baseline'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2"> samples</span><span class="se">\n</span><span class="s2">of noise"</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">xycoords</span><span class="o">=</span><span class="s1">'axes fraction'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'baseline'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_accuracy_against_distance</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="n">rdm_euclidean</span><span class="p">,</span> <span class="n">rdm_mahalanobis</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="s1">'col'</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i_noise</span><span class="p">,</span> <span class="p">(</span><span class="n">noise_type</span><span class="p">,</span> <span class="n">acc_val</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">acc</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="k">for</span> <span class="n">i_dist</span><span class="p">,</span> <span class="n">distance</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s2">"Euclidean"</span><span class="p">,</span> <span class="s2">"Mahalanobis"</span><span class="p">]):</span>
            <span class="n">rdm</span> <span class="o">=</span> <span class="n">rdm_euclidean</span> <span class="k">if</span> <span class="n">distance</span> <span class="o">==</span> <span class="s1">'Euclidean'</span> <span class="k">else</span> <span class="n">rdm_mahalanobis</span>
            <span class="c1"># make sure the rdm matrix and accuracy matrix organize the stimuli in the same order</span>
            <span class="k">assert</span> <span class="n">rdm</span><span class="o">.</span><span class="n">pattern_descriptors</span><span class="p">[</span><span class="s1">'stim'</span><span class="p">]</span> <span class="o">==</span> <span class="n">acc_val</span><span class="o">.</span><span class="n">stim1</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">rdm</span><span class="o">.</span><span class="n">dissimilarities</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">vectorize_matrix</span><span class="p">(</span><span class="n">acc_val</span><span class="p">)</span>
            <span class="n">sns</span><span class="o">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span> <span class="n">i_dist</span><span class="p">],</span> <span class="n">ci</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scatter_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">'alpha'</span><span class="p">:</span><span class="mf">0.7</span><span class="p">},</span> <span class="n">color</span><span class="o">=</span><span class="sa">f</span><span class="s2">"C</span><span class="si">{</span><span class="n">i_dist</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
            <span class="n">r</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span> <span class="n">i_dist</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">'r=</span><span class="si">{:.2f}</span><span class="s1">, p=</span><span class="si">{:.2g}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.9</span><span class="p">),</span> <span class="n">xycoords</span><span class="o">=</span><span class="s1">'axes fraction'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'baseline'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i_dist</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">"squared </span><span class="si">{</span><span class="n">distance</span><span class="si">}</span><span class="s2"> distance"</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i_dist</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">noise_type</span> <span class="o">+</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">noise"</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">xycoords</span><span class="o">=</span><span class="s1">'axes fraction'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'baseline'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

        <span class="n">ax</span><span class="p">[</span><span class="n">i_noise</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"decoding accuracy"</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">fig</span>

<span class="k">def</span> <span class="nf">plot_estimated_distance</span><span class="p">(</span><span class="n">ground_truth_rdm</span><span class="p">,</span> <span class="n">noisy_rdm_euclidean</span><span class="p">,</span> <span class="n">noisy_rdm_crossclidean</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">6.5</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="s1">'row'</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="s1">'row'</span><span class="p">,</span><span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">noise_dist</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s1">'isotropic'</span><span class="p">,</span> <span class="s1">'correlated'</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">rdm</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">noisy_rdm_euclidean</span><span class="p">,</span> <span class="n">noisy_rdm_crossclidean</span><span class="p">]):</span>
            <span class="n">ylabel</span><span class="o">=</span><span class="s2">"squared Euclidean"</span> <span class="k">if</span> <span class="n">j</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="s2">"cross-validated squared Euclidean distance"</span>
            <span class="c1"># check the order of the stimuli in both RDMs is matched (note: rsatoolbox automatically sort stimuli based on values)</span>
            <span class="k">assert</span> <span class="n">rdm</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">][</span><span class="n">noise_dist</span><span class="p">]</span><span class="o">.</span><span class="n">pattern_descriptors</span><span class="p">[</span><span class="s1">'stim'</span><span class="p">]</span> <span class="o">==</span> <span class="n">ground_truth_rdm</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">.</span><span class="n">pattern_descriptors</span><span class="p">[</span><span class="s1">'stim'</span><span class="p">]</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">ground_truth_rdm</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">.</span><span class="n">dissimilarities</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
                            <span class="n">rdm</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">][</span><span class="n">noise_dist</span><span class="p">]</span><span class="o">.</span><span class="n">dissimilarities</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
                            <span class="n">color</span><span class="o">=</span><span class="sa">f</span><span class="s2">"C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">20</span>
                        <span class="p">)</span>
            <span class="n">max_dist</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">rdm</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">][</span><span class="n">noise_dist</span><span class="p">]</span><span class="o">.</span><span class="n">dissimilarities</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">100</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">100</span><span class="p">),</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'dashed'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"estimated squared Euclidean distance</span><span class="se">\n</span><span class="s2">(from noisy patterns)"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"ground truth euclidean distance</span><span class="se">\n</span><span class="s2">(no noise)"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_dist</span><span class="o">+</span><span class="mi">3</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_dist</span><span class="o">+</span><span class="mi">3</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

            <span class="n">title</span><span class="o">=</span><span class="s2">"squared Euclidean"</span> <span class="k">if</span> <span class="n">j</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="s2">"cross-validated squared Euclidean"</span>

            <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                <span class="c1"># ax[i,j].annotate(noise_dist, xy=(0.5, 1.05),</span>
                <span class="c1">#             xycoords='axes fraction', ha='center', va='baseline',fontsize=9)</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">noise_dist</span><span class="si">}</span><span class="se">\n</span><span class="s2">noise"</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
                    <span class="n">xycoords</span><span class="o">=</span><span class="s1">'axes fraction'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'baseline'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">plot_distance_after_projection</span><span class="p">(</span><span class="n">true_dist</span><span class="p">,</span> <span class="n">projected_dist</span><span class="p">,</span> <span class="n">n_neurons_list</span><span class="p">,</span> <span class="n">n_dims_list</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mf">2.5</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n_neurons</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_neurons_list</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">n_neurons</span> <span class="o">==</span> <span class="mi">100</span><span class="p">:</span>
            <span class="n">projected_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">projected_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span>
            <span class="n">true_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">true_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">n_dims_list</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">projected_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"squared euclidean distance</span><span class="se">\n</span><span class="s2">after random projection"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"dimensionality"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'major'</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">true_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">"dashed"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">n_dims_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">true_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="s1">'true euclidean distance'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'right'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'top'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">title</span> <span class="o">=</span> <span class="s2">"two neurons"</span> <span class="k">if</span> <span class="n">n_neurons</span> <span class="o">==</span> <span class="mi">2</span> <span class="k">else</span> <span class="s2">"100 neurons"</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-1-simulate-neural-data-and-visualize-noise-distributions">
<h1>Section 1: Simulate neural data and visualize noise distributions<a class="headerlink" href="#section-1-simulate-neural-data-and-visualize-noise-distributions" title="Permalink to this heading">#</a></h1>
<a class="reference internal image-reference" href="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D3_ComparingArtificialAndBiologicalNetworks/static/response_matrix.png?raw=true"><img alt="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D3_ComparingArtificialAndBiologicalNetworks/static/response_matrix.png?raw=true" src="https://github.com/neuromatch/NeuroAI_Course/blob/main/tutorials/W1D3_ComparingArtificialAndBiologicalNetworks/static/response_matrix.png?raw=true" style="width: 600px;"/></a>
<p>We will start by generating two neural datasets in response to a set of stimuli, represented as a stimulus-response matrix (stimuli x neurons). The first dataset will be low-dimensional, containing only two neurons, to help with illustration and visualization. The second dataset will be high-dimensional, containing 100 neurons. Each will have 10 stimuli.</p>
<p>The mean activity pattern of each stimulus (each row of the matrix) is generated by randomly sampling from a uniform distribution. To ensure that the differences between the mean activity of different stimuli are distinct for later illustration, we scale each activity pattern by a constant for the 100-neuron dataset. This is because the distances in a high-dimensional space tend to be similarly far apart. The implementations can be found above in the <code class="docutils literal notranslate"><span class="pre">generate_activity_patterns</span></code> function.</p>
<p>Then, we add two types of additive noise to the mean activity patterns. The first type of noise is independent and isotropic across neurons (<strong>isotropic</strong>) and stimuli (<strong>homoscedastic</strong>). The second type of noise is independent and isotropic across stimuli (<strong>homoscedastic</strong>) but correlated across neurons (<strong>nonisotropic</strong>). <em>Note that we are not focused on simulating biologically plausible activity patterns</em>. The noise we add may lead to negative response values in the neural data.</p>
<p>We will provide various visualizations of the noise to help build intuitions. If you are curious about the implementations, please refer to the <code class="docutils literal notranslate"><span class="pre">get_isotropic_covariance</span></code> and <code class="docutils literal notranslate"><span class="pre">get_correlated_covariance</span></code> functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_stimuli</span><span class="o">=</span><span class="mi">10</span>
<span class="n">n_neurons_list</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>

<span class="n">clean_dataset</span><span class="o">=</span><span class="p">{}</span>
<span class="k">for</span> <span class="n">n_neurons</span> <span class="ow">in</span> <span class="n">n_neurons_list</span><span class="p">:</span>
    <span class="n">clean_dataset</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_activity_patterns_wrapper</span><span class="p">(</span><span class="n">n_stimuli</span><span class="o">=</span><span class="n">n_stimuli</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To simulate neuronal stochasticity, we introduce isotropic or correlated noise to the clean activity patterns and repeatedly obtain noisy neuronal responses to the same stimulus (analogous to obtaining repeated measurements to the same stimulus for an experiment).</p>
<section id="coding-exercise-1">
<h2>Coding Exercise 1<a class="headerlink" href="#coding-exercise-1" title="Permalink to this heading">#</a></h2>
<p>How would you implement isotropic or correlated Gaussian noise for two neurons? Create a covariance matrix for each type of noise:</p>
<ul class="simple">
<li><p>For the isotropic Gaussian, let the variance of each neuron be 1.</p></li>
<li><p>For the correlated Gaussian, let the variance of each neuron be 1 and the covariance be 0.6.</p></li>
</ul>
<p><strong>Hint</strong>: Let our covariance matrix be <span class="math notranslate nohighlight">\(\Sigma\)</span>. The diagonal entry <span class="math notranslate nohighlight">\(\Sigma_{i,i}\)</span> represents the variance of element <span class="math notranslate nohighlight">\(i\)</span>, and the off-diagonal entry <span class="math notranslate nohighlight">\(\Sigma_{i,j}\)</span> (where <span class="math notranslate nohighlight">\(i\neq j\)</span>) represents the covariance between two elements <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>. As a result, isotropic Gaussian noise can be represented by a diagonal matrix (where off-diagonal entries are 0). The correlated covariance matrix can be represented by a symmetric non-diagonal matrix (<span class="math notranslate nohighlight">\(\Sigma_{i,j}=\Sigma_{j,i})\)</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#################################################</span>
<span class="c1">## TODO for students: fill in the missing variables ##</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise"</span><span class="p">)</span>
<span class="c1">#################################################</span>
<span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">isotropic_cov_2d</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">correlated_cov_2d</span> <span class="o">=</span> <span class="o">...</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">isotropic_cov_2d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
<span class="n">correlated_cov_2d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.6</span><span class="p">],[</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">1.0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<p>We have implemented the covariance matrices for you. Run the following code block to generate 100 noisy neural responses to the 10 stimuli for different correlation structures.</p>
<p>Generate data</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Generate data</span>

<span class="n">repetitions</span><span class="o">=</span><span class="mi">100</span>

<span class="n">isotropic_noised_data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">isotropic_cov</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1"># covariance matrix for the isotropic noise</span>
<span class="n">correlated_noised_data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">correlated_cov</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">n_neurons</span> <span class="ow">in</span> <span class="n">n_neurons_list</span><span class="p">:</span>
    <span class="n">coords</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"stim"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_stimuli</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repetitions</span><span class="p">),</span> <span class="s2">"neuron"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)}</span>

    <span class="c1"># add isotropic noise</span>
    <span class="n">isotropic_cov</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_isotropic_covariance</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
    <span class="n">isotropic_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">add_correlated_noise</span><span class="p">(</span><span class="n">clean_dataset</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span>
                                                            <span class="n">cov</span><span class="o">=</span><span class="n">isotropic_cov</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span>
                                                            <span class="n">repetitions</span> <span class="o">=</span> <span class="n">repetitions</span><span class="p">)</span>
    <span class="n">isotropic_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">np2xr</span><span class="p">(</span><span class="n">isotropic_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">coords</span><span class="p">)</span>

    <span class="c1"># add correlated noise</span>
    <span class="n">correlated_cov</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_correlated_covariance</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
    <span class="n">correlated_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">add_correlated_noise</span><span class="p">(</span><span class="n">clean_dataset</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span>
                                                             <span class="n">cov</span><span class="o">=</span><span class="n">correlated_cov</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span>
                                                             <span class="n">repetitions</span> <span class="o">=</span> <span class="n">repetitions</span><span class="p">)</span>
    <span class="n">correlated_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">np2xr</span><span class="p">(</span><span class="n">correlated_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">coords</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Let’s visualize the effect of the noise distribution on the distances between the stimuli using the two-neuron dataset.</p>
<p>We can represent the noise distribution using a contour plot centered around the mean stimulus response. The contour plot represents a three-dimensional surface on a two-dimensional plane. In this case, the two dimensions represent the responses of the two neurons, and the contours indicate the probability density of the noise distribution. Darker colors indicate higher probability density. As we move further away from the mean response for a particular stimulus, the probability density decreases, meaning that the likelihood of observing a neural response at that point is lower.</p>
<p>We have generated the clean activity patterns such that the Euclidean distances between stimulus pairs [<span class="math notranslate nohighlight">\(s_0\)</span>, <span class="math notranslate nohighlight">\(s_1\)</span>] and [<span class="math notranslate nohighlight">\(s_0\)</span>, <span class="math notranslate nohighlight">\(s_2\)</span>] are the same (see the arrows in the left panels). However, depending on the noise distribution, the discriminability of the stimulus pairs is different:</p>
<ul class="simple">
<li><p><strong>Isotropic noise</strong> (first row): the likelihood of observing the mean neural response of <span class="math notranslate nohighlight">\(s_1\)</span> and <span class="math notranslate nohighlight">\(s_2\)</span>, given that the stimulus shown is <span class="math notranslate nohighlight">\(s_0\)</span>, is the same. The discriminability between a pair of stimuli is precisely defined by the Euclidean distance (Kriegeskorte &amp; Diedrichsen, 2019).</p></li>
<li><p><strong>Correlated noise</strong> (second row): even though the Euclidean distance between the two stimulus pairs is the same, the discriminability between <span class="math notranslate nohighlight">\(s_0\)</span> and <span class="math notranslate nohighlight">\(s_1\)</span> is lower than between <span class="math notranslate nohighlight">\(s_0\)</span> and <span class="math notranslate nohighlight">\(s_2\)</span>. This is because the direction of the noise aligns with the signal direction for <span class="math notranslate nohighlight">\(s_0\)</span> and <span class="math notranslate nohighlight">\(s_1\)</span> (the line connecting their mean responses). As a result, the mean stimulus response of <span class="math notranslate nohighlight">\(s_1\)</span> lies within the colored contours of stimulus <span class="math notranslate nohighlight">\(s_0\)</span> (the probability density lies roughly between 0.06 and 0.08), while the mean stimulus response of <span class="math notranslate nohighlight">\(s_2\)</span> lies outside the contours (which represent the regions where the probability density is close to 0). Namely, when the stimulus shown is <span class="math notranslate nohighlight">\(s_0\)</span>, the likelihood of observing a neural response that coincides with the mean response of <span class="math notranslate nohighlight">\(s_1\)</span> is much higher than <span class="math notranslate nohighlight">\(s_2\)</span>. As we will see later, the discriminability depends on the Mahalanobis distance that takes into account the noise covariances between the neurons.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">visualize_2d_noise</span><span class="p">(</span><span class="n">clean_dataset</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">isotropic_cov</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">correlated_cov</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">isotropic_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">correlated_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/27f2cb7274fe176701d44016a73ff74f9df3421216219b5a00c9414dc7520c25.png" src="../../../_images/27f2cb7274fe176701d44016a73ff74f9df3421216219b5a00c9414dc7520c25.png">
</img></div>
</div>
<p>Let’s create covariance matrices for the 100 neuron dataset. For isotropic noise, the covariance between different neurons remains 0, resulting in a diagonal covariance matrix. To create a correlated covariance matrix, we imagine that the neurons are spatially arranged in a line, and their correlation decays with distance:</p>
<div class="math notranslate nohighlight">
\[\Sigma_{i,j}=\exp\Big(-\dfrac{||i-j||^2_2}{2l^2}\Big)\]</div>
<p>Here <span class="math notranslate nohighlight">\(||i-j||_2\)</span> represents the Euclidean distance between indices <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, and <span class="math notranslate nohighlight">\(l\)</span> is a length scale parameter. Assuming that the matrix indices indicate the neurons’ positions in the brain, neighboring neurons tend to be correlated. To ensure that the correlated covariance matrix is well-conditioned and not singular, we added a small constant value to its diagonal entries.</p>
<p>Note: we intentionally set the noise magnitude to be large so that decoding the neural responses would not be perfect. This allows us to better illustrate the relationship between decoding accuracy and the distances between stimuli in Section 2.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">visualize_100d_noise</span><span class="p">(</span><span class="n">isotropic_cov</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">correlated_cov</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/d1ef87f22e1477fa80abd6fe2be132e905877ca2d2f646f858fb40569fceb895.png" src="../../../_images/d1ef87f22e1477fa80abd6fe2be132e905877ca2d2f646f858fb40569fceb895.png"/>
</div>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-2-distances-and-discriminability-between-a-pair-of-stimuli">
<h1>Section 2: Distances and discriminability between a pair of stimuli<a class="headerlink" href="#section-2-distances-and-discriminability-between-a-pair-of-stimuli" title="Permalink to this heading">#</a></h1>
<p>As we alluded to earlier, for a pair of stimuli, there is a strong dependence between their distance and discriminability (defined by the performance of a binary classifier on the stimulus pair). Moreover, matching the type of distance computed (Euclidean vs. Mahalanobis) and the noise distribution (isotropic vs. correlated) is important. <be></be></p>
<p>Let’s briefly review how to compute the Euclidean and Mahalanobis distance. Let the activity patterns of stimuli <span class="math notranslate nohighlight">\(j\)</span> and <span class="math notranslate nohighlight">\(k\)</span> be <span class="math notranslate nohighlight">\(\mathbf{b_j}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b_k}\)</span> respectively.</p>
<ul class="simple">
<li><p>The <em>squared</em> Euclidean distance is $<span class="math notranslate nohighlight">\(d^2_{\text{Euclidean}}=||\mathbf{b_i}-\mathbf{b_j}||^2=(\mathbf{b_i} - \mathbf{b_j})(\mathbf{b_i} - \mathbf{b_j})^T\)</span>$</p></li>
<li><p>The <em>squared</em> mahalanobis distance is $<span class="math notranslate nohighlight">\(d^2_{\text{Mahalanobis}}=(\mathbf{b_i} - \mathbf{b_j})\Sigma^{-1}(\mathbf{b_i} - \mathbf{b_j})^T\)</span><span class="math notranslate nohighlight">\( where \)</span>\Sigma<span class="math notranslate nohighlight">\( is the covariance matrix across the neurons. Taking the inverse of the covariance matrix makes the noise approximately independent and identically distributed. Intuitively, the noisier a neuron is, the more we down-weight its response.
Note: If we have repeated measurements for some stimulus \)</span>j<span class="math notranslate nohighlight">\( (\)</span>\mathbf{b_j^1}, \mathbf{b_j^2}, …, \mathbf{b_j^n}<span class="math notranslate nohighlight">\(), we take the average and compute \)</span>\mathbf{b_j}=\dfrac{1}{n}\sum_{i=1}^n \mathbf{b_j^i}$</p></li>
</ul>
<p>Let’s first train a binary classifier for each pair of stimuli and calculate the decoding accuracy. We will use the <strong>Fisher Linear Discriminant Analysis</strong>.</p>
<p>To classify two stimuli <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, the Fisher discriminant decision criterion is a threshold on the dot product <span class="math notranslate nohighlight">\(\mathbf{wb}^T &gt; c\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{w}=(\mathbf{b_i}-\mathbf{b_j})_{\text{train}}\Sigma_{\text{train}}^{-1}\)</span> is the weight vector and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> is the stimulus pattern we want to classify.</p>
<p>Execute this cell below to calculate the classifier performance on the noisy data (generated by adding either isotropic or correlated noise). <strong>Notice that execution of this cell will take up to 3 minutes.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">LinearDiscriminantAnalysis</span><span class="p">()</span>
<span class="n">acc</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">n_neurons</span> <span class="ow">in</span> <span class="n">n_neurons_list</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Fitting for </span><span class="si">{</span><span class="n">n_neurons</span><span class="si">}</span><span class="s2"> neurons"</span><span class="p">)</span>
    <span class="n">acc</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">=</span><span class="p">{}</span>
    <span class="n">acc</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">][</span><span class="s1">'isotropic'</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_classifier_acc</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">isotropic_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="n">isotropic_cov</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">])</span>
    <span class="n">acc</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">][</span><span class="s1">'correlated'</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_classifier_acc</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">correlated_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="n">correlated_cov</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting for 2 neurons
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting for 100 neurons
</pre></div>
</div>
</div>
</div>
<p>Let’s calculate the <em>squared</em> Euclidean and Mahalanobis distances between the <strong>clean neural activity</strong> patterns to study the relationship between these distances and classification accuracy.</p>
<section id="coding-exercise-2">
<h2>Coding exercise 2<a class="headerlink" href="#coding-exercise-2" title="Permalink to this heading">#</a></h2>
<p>In this coding exercise, you’ll compute the <em>squared</em> Euclidean and Mahalanobis distance for <em>one pair</em> of stimuli in the 2-neuron dataset.</p>
<p>You might be wondering why we are calculating the Mahalanobis distance for clean neural patterns, given that they are inherently noiseless. The reason is that our binary decoders are trained to classify noisy data. By computing the Mahalanobis distance between the clean neural activity patterns, we take the covariances into account, which allows us to better predict decoding accuracy (as you will see below). Consider the clean neural activity patterns as the mean neural response obtained from repeated measurements. If we collect many noisy measurements, our mean neural response will converge to the clean neural pattern.</p>
<p>The equations are provided again below:
$<span class="math notranslate nohighlight">\(d^2_{\text{Euclidean}}=||\mathbf{b_j}-\mathbf{b_k}||^2=(\mathbf{b_i} - \mathbf{b_j})(\mathbf{b_i} - \mathbf{b_j})^T\)</span>$</p>
<p>$<span class="math notranslate nohighlight">\(d^2_{\text{Mahalanobis}}=(\mathbf{b_i} - \mathbf{b_j})\Sigma^{-1}(\mathbf{b_i} - \mathbf{b_j})^T\)</span><span class="math notranslate nohighlight">\( where \)</span>\Sigma$ is the covariance matrix across the neurons.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">stimulus_idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="mi">1</span> <span class="c1"># choose two stimuli</span>
<span class="c1">#################################################</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: fill in the missing variables"</span><span class="p">)</span>
<span class="c1">#################################################</span>
<span class="n">b_j</span> <span class="o">=</span> <span class="n">clean_dataset</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">stimulus_idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span> <span class="c1"># select the stimulus response</span>
<span class="n">b_k</span> <span class="o">=</span> <span class="n">clean_dataset</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">stimulus_idx</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="c1"># compute the squared euclidean and mahalanobis distance, and then divide the distance by the number of neurons (2)</span>
<span class="n">euclidean_dist</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">mahalanobis_dist</span> <span class="o">=</span> <span class="p">((</span><span class="n">b_j</span><span class="o">-</span><span class="n">b_k</span><span class="p">)</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">correlated_cov</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">])</span> <span class="o">@</span> <span class="p">(</span><span class="n">b_j</span><span class="o">-</span><span class="n">b_k</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_neurons</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#to_remove solution</span>
<span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">stimulus_idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="mi">1</span> <span class="c1"># choose two stimuli</span>
<span class="n">b_j</span> <span class="o">=</span> <span class="n">clean_dataset</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">stimulus_idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span> <span class="c1"># select the stimulus response</span>
<span class="n">b_k</span> <span class="o">=</span> <span class="n">clean_dataset</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">stimulus_idx</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="c1"># compute the squared euclidean and mahalanobis distance, and then divide the distance by the number of neurons (2)</span>
<span class="n">euclidean_dist</span> <span class="o">=</span> <span class="p">((</span><span class="n">b_j</span><span class="o">-</span><span class="n">b_k</span><span class="p">)</span> <span class="o">@</span> <span class="p">(</span><span class="n">b_j</span><span class="o">-</span><span class="n">b_k</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_neurons</span>
<span class="n">mahalanobis_dist</span> <span class="o">=</span> <span class="p">((</span><span class="n">b_j</span><span class="o">-</span><span class="n">b_k</span><span class="p">)</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">correlated_cov</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">])</span> <span class="o">@</span> <span class="p">(</span><span class="n">b_j</span><span class="o">-</span><span class="n">b_k</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_neurons</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="discussion">
<h2>Discussion<a class="headerlink" href="#discussion" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>For isotropic gaussian noise, what is the relationship between Euclidean and Mahalanobis distance?
<strong>Hint</strong>: Check the equations above. In the special case of an identity covariance matrix, i.e., <span class="math notranslate nohighlight">\(\Sigma=I\)</span>, what is the inverse of <span class="math notranslate nohighlight">\(\Sigma\)</span>?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#to_remove explanation</span>

<span class="sd">"""</span>
<span class="sd">Discussion: For isotropic gaussian noise, what is the relationship between Euclidean and Mahalanobis distance?</span>

<span class="sd">For isotropic Gaussian noise, the Euclidean distance and Mahalanobis distance are equivalent up to a constant factor. When the covariance matrix is an identity matrix, the Euclidean and Mahalanobis distances are exactly equal.</span>
<span class="sd">"""</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<p>The distances for all stimulus pairs in the 2-neuron and 100-neuron datasets are computed below. The<code class="docutils literal notranslate"><span class="pre">calc_rdm</span></code> function is a wrapper around the <code class="docutils literal notranslate"><span class="pre">rsatoolbox.data.Dataset</span></code> and <code class="docutils literal notranslate"><span class="pre">rsatoolbox.rdm.calc_rdm</span></code> modules in the <a class="reference external" href="https://github.com/rsagroup/rsatoolbox">rsatoolbox</a> package. The rsatoolbox automatically computes distances for all possible pairs of stimuli. Namely, if our <code class="docutils literal notranslate"><span class="pre">clean_dataset</span></code> is an array of <span class="math notranslate nohighlight">\(k\)</span> stimuli by <span class="math notranslate nohighlight">\(n\)</span> neurons, then <code class="docutils literal notranslate"><span class="pre">rsatoolbox.rdm.calc_rdm</span></code> computes <span class="math notranslate nohighlight">\(k(k-1)/2\)</span> distances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rdm_euclidean</span><span class="p">,</span> <span class="n">rdm_mahalanobis</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">n_neurons</span> <span class="ow">in</span> <span class="n">n_neurons_list</span><span class="p">:</span>
    <span class="n">rdm_euclidean</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">calc_rdm</span><span class="p">(</span><span class="n">clean_dataset</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="s1">'euclidean'</span><span class="p">)</span>
    <span class="n">rdm_mahalanobis</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">calc_rdm</span><span class="p">(</span><span class="n">clean_dataset</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="s1">'mahalanobis'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">correlated_cov</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]))</span> <span class="c1"># plotting decoding accuracy from isotropic noise data</span>
</pre></div>
</div>
</div>
</div>
<p>Verify that the distances you just computed correspond to the ones calculated by rsatoolbox. Note that the <code class="docutils literal notranslate"><span class="pre">calc_rdm</span></code> function normalizes the distance by the number of channels (e.g. divides the distance by 2 for the 2-neuron dataset), so please divide your distance by the number of neurons (2) as well.</p>
<p>You can obtain the distances by accessing the <code class="docutils literal notranslate"><span class="pre">dissimilarities</span></code> property in the namespace (<code class="docutils literal notranslate"><span class="pre">rdm_euclidean[n_neurons].dissimilarities</span></code>). The <code class="docutils literal notranslate"><span class="pre">dissimilarities</span></code> are ordered by the <code class="docutils literal notranslate"><span class="pre">pattern_descriptors</span></code>. If the pattern descriptor shows [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], then the <span class="math notranslate nohighlight">\(9(9-1)/2=45\)</span> distances are ordered as <span class="math notranslate nohighlight">\(d_{0,1}\)</span>, <span class="math notranslate nohighlight">\(d_{0,2}\)</span>, <span class="math notranslate nohighlight">\(d_{0,3}\)</span>,…, <span class="math notranslate nohighlight">\(d_{i,i+1}\)</span>, <span class="math notranslate nohighlight">\(d_{i,i+2}\)</span>, …, <span class="math notranslate nohighlight">\(d_{8,9}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rdm_euclidean</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="c1"># access dissimilarities by rdm_euclidean[2].dissimilarities</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>rsatoolbox.rdm.RDMs(
dissimilarity_measure = 
squared euclidean
dissimilarities = 
[[2.         2.         0.42450561 0.90263363 0.2066341  0.20877183
  0.03490559 0.24996255 0.         1.17157288 1.21002444 1.28491752
  2.4559779  2.25334373 2.03897099 0.84171204 2.         0.58566622
  0.24149079 3.27482695 3.15357638 2.41142996 1.16326452 2.
  0.09246359 1.14389872 1.09435388 0.64374725 0.20234335 0.42450561
  1.88670987 1.82227196 1.22264242 0.51408899 0.90263363 0.00535601
  0.07466089 0.58492372 0.2066341  0.07300732 0.51594203 0.20877183
  0.30328451 0.03490559 0.24996255]]
descriptors = 
{}
rdm_descriptors = 
{'index': [0]}
pattern_descriptors = 
{'stim': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}
</pre></div>
</div>
</div>
</div>
<p>For each pair of stimuli, we can plot the decoding accuracy and the distance between them. We will generate four plots for each dataset, two noise distributions (isotropic or correlated) <span class="math notranslate nohighlight">\(\times\)</span> two distance measures (Euclidean or mahalanobis).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># change to 100 to visualize the relationship between distance and decoding accuracy for the 100-neuron dataset</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plot_accuracy_against_distance</span><span class="p">(</span><span class="n">acc</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">rdm_euclidean</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">rdm_mahalanobis</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">n_neurons</span><span class="si">}</span><span class="s2"> neurons"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0.98, '2 neurons')
</pre></div>
</div>
<img alt="../../../_images/2dd0b25e9fdbda6b568914485e71fbf5cf74cae8cf8367a4f843f422928646ee.png" src="../../../_images/2dd0b25e9fdbda6b568914485e71fbf5cf74cae8cf8367a4f843f422928646ee.png"/>
</div>
</div>
<p>Notice that:</p>
<ul class="simple">
<li><p>For a decoder trained to classify data with isotropic noise, the Euclidean distance predicts decoding accuracy better (higher correlation). The Mahalanobis distance predictions are less accurate because it uses the correlated covariance, which doesn’t reflect the isotropic noise.</p></li>
<li><p>For a decoder trained to classify data with correlated noise, the Mahalanobis distance that takes into account the correct noise covariance predicts decoding accuracy better.</p></li>
</ul>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-3-cross-validated-distances-prevent-the-inflation-of-distance-estimates-by-noise">
<h1>Section 3: Cross-validated distances prevent the inflation of distance estimates by noise<a class="headerlink" href="#section-3-cross-validated-distances-prevent-the-inflation-of-distance-estimates-by-noise" title="Permalink to this heading">#</a></h1>
<p>If we calculate the Euclidean distance between the <strong>noisy</strong> activity patterns of each pair of stimuli, we will observe that it’s higher than in the no-noise condition. This is especially visible in the 100-neuron dataset.</p>
<p>To understand this positive bias of distances, imagine two activity patterns that are in truth identical. With the addition of the noise, the estimated distance between the noisy data will always be larger than 0. The noise makes the patterns dissimilar and inflates the distance (Walther et al. 2016). This effect is particularly pronounced in high-dimensional data.</p>
<p>Let’s first calculate the squared Euclidean distances between the noisy activity patterns of each stimulus pair.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">noisy_rdm_euclidean</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">n_neurons</span> <span class="ow">in</span> <span class="n">n_neurons_list</span><span class="p">:</span>
    <span class="n">noisy_rdm_euclidean</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">noisy_rdm_euclidean</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">][</span><span class="s1">'isotropic'</span><span class="p">]</span> <span class="o">=</span> <span class="n">calc_rdm</span><span class="p">(</span><span class="n">isotropic_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="s1">'euclidean'</span><span class="p">)</span>
    <span class="n">noisy_rdm_euclidean</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">][</span><span class="s1">'correlated'</span><span class="p">]</span> <span class="o">=</span> <span class="n">calc_rdm</span><span class="p">(</span><span class="n">correlated_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="s1">'euclidean'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>To obtain an unbiased estimate, we can split the data into independent sets and cross-validate the difference between patterns across the two sets (Allefeld and Haynes, 2014; Nili et al. 2014).</p>
<p>The cross-validated squared Euclidean distance–the so-called <em>crossclidian</em>–between two activity patterns <span class="math notranslate nohighlight">\(\mathbf{b_i}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b_j}\)</span> can be computed as: $<span class="math notranslate nohighlight">\(d^2_{\text{Euclidean, cross-validated}}=(\mathbf{b_i} - \mathbf{b_j})_\text{train}(\mathbf{b_i} - \mathbf{b_j})_\text{test}^T\)</span>$
where we partition the repeated measurements of the activity patterns into a training and testing set before computing the difference vectors independently.</p>
<p><code class="docutils literal notranslate"><span class="pre">rsatoolbox</span></code> has an implementation of the cross-validated distance. The general distance measure is called <em>crossnobis</em>, short for <em>cross-validated mahalanobis distance</em>.
$<span class="math notranslate nohighlight">\(d^2_{\text{Mahalanobis, cross-validated}}=(\mathbf{b_i} - \mathbf{b_j})_\text{train}\Sigma_{\text{train}}^{-1}(\mathbf{b_i} - \mathbf{b_j})_\text{test}^T\)</span>$
If we assume the covariance noise structure is an identity matrix, then the crossnobis distance is equivalent to the cross-validated Euclidean distance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">noisy_rdm_crossclidean</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">n_neurons</span> <span class="ow">in</span> <span class="n">n_neurons_list</span><span class="p">:</span>
    <span class="n">noisy_rdm_crossclidean</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">noisy_rdm_crossclidean</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">][</span><span class="s1">'isotropic'</span><span class="p">]</span> <span class="o">=</span> <span class="n">calc_rdm</span><span class="p">(</span><span class="n">isotropic_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="s1">'crossnobis'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">noisy_rdm_crossclidean</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">][</span><span class="s1">'correlated'</span><span class="p">]</span> <span class="o">=</span> <span class="n">calc_rdm</span><span class="p">(</span><span class="n">correlated_noised_data</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="s1">'crossnobis'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s now plot the squared Euclidean distance and the cross-validated squared Euclidean distance against the true Euclidean distance for the 100-neuron dataset. Points falling on the diagonal line indicate an unbiased estimate of the distance; points above the diagonal line indicate an overestimation of the distance, and vice versa.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_estimated_distance</span><span class="p">(</span><span class="n">rdm_euclidean</span><span class="p">,</span> <span class="n">noisy_rdm_euclidean</span><span class="p">,</span> <span class="n">noisy_rdm_crossclidean</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/c88a89becc3cd2fe69195814960dfba7f8096680c0161986d4096a1c047918ae.png" src="../../../_images/c88a89becc3cd2fe69195814960dfba7f8096680c0161986d4096a1c047918ae.png"/>
</div>
</div>
<p>In section 2, we used the Fisher Linear discriminant analysis (LDA) to decode stimuli and calculated decoding accuracy. The weight vector of the Fisher linear discriminant <span class="math notranslate nohighlight">\(\mathbf{w}=(\mathbf{b_i}-\mathbf{b_j})_{\text{train}}\Sigma_{\text{train}}^{-1}\)</span>. Do you notice any similarity with the cross-validated Mahalanobis distance <span class="math notranslate nohighlight">\((\mathbf{b_i} - \mathbf{b_j})_\text{train}\Sigma_{\text{train}}^{-1}(\mathbf{b_i} - \mathbf{b_j})_\text{test}^T\)</span>?
In fact, if the test dataset only consists of one observation from each of the two classes (<span class="math notranslate nohighlight">\(\mathbf{b_i^{\textbf{test}}}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b_j}^{\textbf{test}}\)</span>) and we subtract the mean pattern from both the training and the test dataset, then both observations in the test set will be correctly classified if <span class="math notranslate nohighlight">\((\mathbf{b_i} - \mathbf{b_j})_\text{train}\Sigma_{\text{train}}^{-1}(\mathbf{b_i} - \mathbf{b_j})_\text{test}^T&gt;0\)</span>.
The cross-validated Mahalanobis distance is closely related to the linear discriminant (hence termed <em>linear discriminant contrast</em>, or <em>LDC</em>). In LDA, the discriminant makes binary classifications on each stimulus  and suffers from discretization and saturation of the classification accuracy. LDC, on the other hand, provides a continuous quantification of the discriminability between stimulus classes, avoiding the limitations of discretization and saturation (Walther et al. 2016).</p>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-4-the-johnson-lindenstrauss-lemma">
<h1>Section 4: The Johnson-Lindenstrauss Lemma<a class="headerlink" href="#section-4-the-johnson-lindenstrauss-lemma" title="Permalink to this heading">#</a></h1>
<p>The Johnson-Lindenstrauss Lemma says that random projections approximately preserve Euclidean distances with some distortion. The distortion <span class="math notranslate nohighlight">\(\epsilon\)</span> is bounded by the number of points in the original space, <span class="math notranslate nohighlight">\(N\)</span>, and the number of dimensions after the projection, <span class="math notranslate nohighlight">\(m\)</span>.</p>
<p>We will see that we can embed points in a high-dimensional space into a reasonably low dimension.</p>
<p>We choose one pair of stimuli for illustration purposes. After we project the data onto a dimension <span class="math notranslate nohighlight">\(m\)</span> (where <span class="math notranslate nohighlight">\(m=2, 4, 8,\ldots, 512\)</span>), we calculate the Euclidean distance between the stimulus pair in the projected space and compare it with the distance in the original space.</p>
<section id="coding-exercise-3">
<h2>Coding exercise 3<a class="headerlink" href="#coding-exercise-3" title="Permalink to this heading">#</a></h2>
<p>Generate a random projection matrix <span class="math notranslate nohighlight">\(A\)</span> from the original space to the <span class="math notranslate nohighlight">\(d\)</span> dimensional space inside the for loop. The entries of <span class="math notranslate nohighlight">\(A\)</span> can be filled with random normal variables.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">stim_idx</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># change stimulus index to visualize another pair of stimuli</span>
<span class="n">m_dims_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">true_dist</span><span class="p">,</span> <span class="n">projected_dist</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n_neurons</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_neurons_list</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">clean_dataset</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">.</span><span class="n">sel</span><span class="p">({</span><span class="s2">"stim"</span><span class="p">:</span> <span class="n">stim_idx</span><span class="p">})</span>
    <span class="c1"># Let's first recalculate the ground truth euclidean rdm again, without normalization by the number of neurons this time.</span>
    <span class="n">true_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">calc_rdm</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">'euclidean'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize_by_channels</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">dissimilarities</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">projected_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">m_dims</span> <span class="ow">in</span> <span class="n">m_dims_list</span><span class="p">:</span>
        <span class="c1">#################################################</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: fill in the missing variables"</span><span class="p">)</span>
        <span class="c1">#################################################</span>
        <span class="n">A</span> <span class="o">=</span> <span class="o">...</span>
        <span class="n">A</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m_dims</span><span class="p">)</span>
        <span class="n">transformed_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span> <span class="o">@</span> <span class="n">A</span><span class="p">)</span>
        <span class="n">transformed_data</span> <span class="o">=</span> <span class="n">np2xr</span><span class="p">(</span><span class="n">transformed_data</span><span class="p">,</span> <span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="s1">'stim'</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">stim</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="s1">'neuron'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">m_dims</span><span class="p">)})</span>
        <span class="n">rdm</span> <span class="o">=</span> <span class="n">calc_rdm</span><span class="p">(</span><span class="n">transformed_data</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">'euclidean'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize_by_channels</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">projected_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rdm</span><span class="o">.</span><span class="n">dissimilarities</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">projected_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">projected_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">])</span>

<span class="n">plot_distance_after_projection</span><span class="p">(</span><span class="n">true_dist</span><span class="p">,</span> <span class="n">projected_dist</span><span class="p">,</span> <span class="n">n_neurons_list</span><span class="p">,</span> <span class="n">m_dims_list</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="n">stim_idx</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># change stimulus index to visualize another pair of stimuli</span>
<span class="n">m_dims_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">true_dist</span><span class="p">,</span> <span class="n">projected_dist</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n_neurons</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_neurons_list</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">clean_dataset</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">.</span><span class="n">sel</span><span class="p">({</span><span class="s2">"stim"</span><span class="p">:</span> <span class="n">stim_idx</span><span class="p">})</span>
    <span class="c1"># Let's first recalculate the ground truth euclidean rdm again, without normalization by the number of neurons this time.</span>
    <span class="n">true_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">calc_rdm</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">'euclidean'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize_by_channels</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">dissimilarities</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">projected_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">m_dims</span> <span class="ow">in</span> <span class="n">m_dims_list</span><span class="p">:</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">m_dims</span><span class="p">))</span>
        <span class="n">A</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m_dims</span><span class="p">)</span>
        <span class="n">transformed_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span> <span class="o">@</span> <span class="n">A</span><span class="p">)</span>
        <span class="n">transformed_data</span> <span class="o">=</span> <span class="n">np2xr</span><span class="p">(</span><span class="n">transformed_data</span><span class="p">,</span> <span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="s1">'stim'</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">stim</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="s1">'neuron'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">m_dims</span><span class="p">)})</span>
        <span class="n">rdm</span> <span class="o">=</span> <span class="n">calc_rdm</span><span class="p">(</span><span class="n">transformed_data</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">'euclidean'</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize_by_channels</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">projected_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rdm</span><span class="o">.</span><span class="n">dissimilarities</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">projected_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">projected_dist</span><span class="p">[</span><span class="n">n_neurons</span><span class="p">])</span>

<span class="n">plot_distance_after_projection</span><span class="p">(</span><span class="n">true_dist</span><span class="p">,</span> <span class="n">projected_dist</span><span class="p">,</span> <span class="n">n_neurons_list</span><span class="p">,</span> <span class="n">m_dims_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/80a1d6096088907a411217733333c50b63381224a87886c187d84927aec619c6.png" src="../../../_images/80a1d6096088907a411217733333c50b63381224a87886c187d84927aec619c6.png"/>
</div>
</div>
<p>Notice that the distance in the transformed space is close to the original distance for relatively small <span class="math notranslate nohighlight">\(k\)</span>.</p>
</section>
<section id="id1">
<h2>Discussion<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Does the amount of distortion after projection depend on the dimension <span class="math notranslate nohighlight">\(d\)</span> of the original space? Observe the dimension <span class="math notranslate nohighlight">\(k\)</span> that preserves Euclidean distance up to a small distortion for both the 2-neuron and 100-neuron datasets.</p></li>
<li><p>What is the distance between two identical stimuli after random projection?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#to_remove explanation</span>

<span class="sd">"""</span>
<span class="sd">Discussion: 1. Does the amount of distortion after projection depend on the dimension $d$ of the original space? Observe the dimension $k$ that preserves Euclidean distance up to a small distortion for both the 2-neuron and 100-neuron datasets.</span>

<span class="sd">2. What is the distance between two identical stimuli after random projection?</span>

<span class="sd">1. No. Empirically, the dimension that preserves Euclidean distance up to a small distortion for the 100-neuron dataset is similar to the 2-neuron dataset. Theoretically, the distortion bound is independent of the original dimension (https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma).</span>

<span class="sd">2. The distance is always 0.</span>
<span class="sd">"""</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h2>
<p>In this tutorial, we have learned:</p>
<ol class="arabic simple">
<li><p>The differences between the (squared) Euclidean and Mahalanobis distance measures. The Mahalanobis distance takes into account the noise covariances between neurons, while the Euclidean distance assumes isotropic noise.</p></li>
<li><p>Representational distance reflects discriminability (decodability) between stimulus pairs (Kriegeskorte &amp; Diedrichsen, 2019).</p>
<ul class="simple">
<li><p>If we assume additive Gaussian noise that is independent and identically distributed across neurons (isotropic) and stimuli (homoscedastic), then the Euclidean distance in the multivariate response space precisely defines the discriminability of a pair of stimuli in the representation.</p></li>
<li><p>If we assume that the noise is correlated across neurons (nonisotropic) and i.i.d across stimuli (homoscedastic), then the Mahalanobis distance defines the discriminability.</p></li>
</ul>
</li>
<li><p>Cross-validated distance estimators (cross-validated Euclidean or Mahalanobis distance) can remove the positive bias introduced by noise.</p></li>
<li><p>The Johnson–Lindenstrauss Lemma shows that random projections preserve the Euclidean distance with some distortions. Crucially, the distortion does not depend on the dimensionality of the original space.</p></li>
</ol>
</section>
</section>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tutorials/W1D3_ComparingArtificialAndBiologicalNetworks/instructor"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</article>
<footer class="bd-footer-article">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W1D3_Tutorial3.html" id="prev-link" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 3: Statistical inference on representational geometries</p>
</div>
</a>
<a class="right-next" href="../../W1D5_Microcircuits/chapter_title.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Microcircuits</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="toc-item">
<div class="tocsection onthispage">
<i class="fa-solid fa-list"></i> On this page
</div>
<nav class="page-toc" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 4: Representational geometry &amp; noise
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#import-dependencies">
     Import dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-simulate-neural-data-and-visualize-noise-distributions">
   Section 1: Simulate neural data and visualize noise distributions
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1">
     Coding Exercise 1
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-distances-and-discriminability-between-a-pair-of-stimuli">
   Section 2: Distances and discriminability between a pair of stimuli
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2">
     Coding exercise 2
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#discussion">
     Discussion
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-cross-validated-distances-prevent-the-inflation-of-distance-estimates-by-noise">
   Section 3: Cross-validated distances prevent the inflation of distance estimates by noise
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-the-johnson-lindenstrauss-lemma">
   Section 4: The Johnson-Lindenstrauss Lemma
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3">
     Coding exercise 3
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
     Discussion
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
     Summary
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<footer class="bd-footer-content">
<div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
<div class="footer-item">
<p class="component-author">
By Neuromatch
</p>
</div>
<div class="footer-item">
</div>
<div class="footer-item">
<p class="last-updated">
Last updated on None.<br/>
</p>
</div>
<div class="footer-item">
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</div>
</div>
</div>
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>
</body>
</html>